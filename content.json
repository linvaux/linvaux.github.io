{"meta":{"title":"写bug的大耳朵图图","subtitle":"","description":"","author":"Wick","url":"https://linvaux.github.io","root":"/"},"pages":[{"title":"categories","date":"2024-07-25T14:43:59.000Z","updated":"2024-07-29T01:30:53.059Z","comments":true,"path":"categories/index.html","permalink":"https://linvaux.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于我","date":"2024-08-04T12:21:57.000Z","updated":"2024-08-07T02:13:08.065Z","comments":true,"path":"about/index.html","permalink":"https://linvaux.github.io/about/index.html","excerpt":"","text":"关于我你好，我是Wick, 目前在国内某互联网大厂担任高级测试开发工程师。工作了快8年了，主要从事Java开发，Python开发，测试平台开发，性能测试等工作，技能树也点的乱七八糟的，不过都还凑合能用。 关于博客这是我的个人博客，用于记录一些学习笔记和心得体会。 交个朋友 邮箱：&#x6c;&#x69;&#110;&#118;&#x61;&#x75;&#x78;&#64;&#x6f;&#117;&#116;&#x6c;&#x6f;&#x6f;&#107;&#x2e;&#x63;&#111;&#109; 微信：wicktu"},{"title":"友情链接","date":"2024-09-21T00:59:08.949Z","updated":"2024-09-21T00:59:08.949Z","comments":true,"path":"links/index.html","permalink":"https://linvaux.github.io/links/index.html","excerpt":"","text":""},{"title":"tags","date":"2024-07-25T14:43:48.000Z","updated":"2024-07-29T01:30:53.172Z","comments":true,"path":"tags/index.html","permalink":"https://linvaux.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Github Pages使用Hexo搭建个人博客","slug":"Github-Pages使用Hexo搭建个人博客","date":"2024-08-24T13:59:39.000Z","updated":"2024-09-21T00:59:08.923Z","comments":true,"path":"posts/a7b6bddb/","permalink":"https://linvaux.github.io/posts/a7b6bddb/","excerpt":"","text":"前言我的个人博客之前是托管在 https://geeknote.net/wick 上，但是因为一些体验问题，我决定迁移到Github Pages上。Github Pages是Github提供的一个静态网站托管服务，可以用来搭建个人博客、项目文档等。Hexo是一个基于Node.js的静态博客框架，可以快速生成静态网页，并且支持Markdown语法。 准备工作安装Node.jsHexo是基于Node.js的，所以我们需要先安装Node.js。可以从Node.js官网下载安装包，然后按照提示进行安装。 安装GitGit是一个分布式版本控制系统，可以用来管理代码。可以从Git官网下载安装包，然后按照提示进行安装。 安装Hexo打开命令行工具，输入以下命令安装Hexo： 1npm install -g hexo-cli 初始化Hexo在命令行中输入以下命令，初始化Hexo： 1hexo init &lt;folder&gt; 其中，&lt;folder&gt;是你想要创建的博客文件夹的名称。例如，我想要创建一个名为myblog的博客文件夹，那么就输入以下命令： 1hexo init myblog 然后进入该文件夹： 1cd myblog 安装依赖在命令行中输入以下命令，安装Hexo的依赖： 1npm install Github创建博客仓库在Github上创建一个仓库，用于存放Hexo生成的静态网页，在创建仓库时要注意： 仓库名称必须为&lt;username&gt;.github.io，其中&lt;username&gt;是你的Github用户名。例如，我的Github用户名是linvaux，那么我就创建了一个名为linvaux.github.io的仓库。 仓库类型必须为Public。 Github Profiles中配置好sshKey。 安装主题&amp;插件Hexo支持很多主题，你可以根据自己的喜好选择。我选择的是Pure主题，也可以在Hexo官网找到很多主题，安装Pure主题的命令如下： 1git clone https://github.com/cofess/hexo-theme-pure.git themes/pure 安装插件Hexo支持很多插件，你可以根据自己的需求选择。我安装了以下几个插件： hexo-wordcount: 支持文章字数统计，阅读时长预估。 hexo-neat: 用于压缩HTML、CSS、JS文件，优化网站加载速度。 hexo-abbrlink: 生成文章短链，不然默认是根据文章创建时间和标题生成的，不但长，而且如果文件名为中文，复制的URL是URL编码后的URL，不方便分享。 hexo-deployer-git: 用于将Hexo生成的静态网页部署到Github Pages上。 配置主题在博客根目录下找到Hexo的配置文件_config.yml中，可以配置主题，例如： 12# 此处主题名称要填写 themes文件夹下的主题名称，刚才安装主题的时候我们已经把主题名称改为了pure，所以这里要填写puretheme: pure 配置插件hexo-deployer-git在博客根目录下找到Hexo的配置文件_config.yml中，可以配置hexo-deployer-git插件，下面直接给出我的配置： 12345# 其中，`repo`是你的Github仓库地址，`branch`是你的Github仓库分支。deploy: type: git repo: https://github.com/linvaux/linvaux.github.io.git branch: main hexo-abbrlink在博客根目录下找到Hexo的配置文件_config.yml中，可以配置hexo-abbrlink插件，下面直接给出我的配置： 12345678910111213# permalink 是hexo的一个配置项，用于设置文章的永久链接格式，默认是 :year/:month/:day/:title/，这里我们使用 :abbrlink/，这样生成的链接会更短，更易于分享。permalink: posts/:abbrlink/abbrlink: alg: crc32 rep: hex drafts: false auto_category: enable: true depth: over_write: false auto_title: true auto_date: false force: false hexo-neat在博客根目录下找到Hexo的配置文件_config.yml中，可以配置hexo-neat插件，下面直接给出我的配置： 12345678910111213141516# hexo-neatneat_enable: trueneat_html: enable: true exclude: neat_css: enable: true exclude: - &#x27;*.min.css&#x27;neat_js: enable: true mangle: true output: compress: exclude: - &#x27;*.min.js&#x27; hexo-wordcounthexo-wordcount插件配置在 themes&#x2F;pure&#x2F;_config.yml 中，pure默认带了这个配置，直接启用即可： 12345# wordcountpostCount: enable: true wordcount: true # 文章字数统计 min2read: true # 阅读时长预计 部署博客 在博客根目录下输入以下命令，生成静态网页： 12# 也可以使用 hexo g 命令hexo generate 在博客根目录下输入以下命令，将生成的静态网页部署到Github Pages上： 12# 也可以使用 hexo d 命令hexo deploy 进入刚才创建的Github仓库，点击Settings，找到GitHub Pages，选择main分支，点击Save。可以参考下图： 打开浏览器，输入https://&lt;username&gt;.github.io，就可以看到你的博客了。 常见问题使用pure主题，点击左边”about”, “tags” 等发现404直接使用如下命令生成静态网页： 12# 其他页面类似hexo new page &quot;about&quot; 如何在本地预览在博客根目录下输入以下命令，启动本地服务器： 12# 也可以使用 hexo s 命令hexo server 然后在浏览器中输入http://localhost:4000，就可以看到你的博客了。 如何更新博客在博客根目录下输入以下命令，更新博客： 1234# 也可以使用 hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 命令hexo cleanhexo generatehexo deploy 如何备份博客hexo博客的备份其实很简单，只需要在博客目录下直接执行 git init 命令，然后添加远程仓库地址，最后执行 git push 命令即可。但是要注意，我们使用了 git clone 来安装主题，使用 git add 时可能会提示包含git子仓库，直接把主题下的 .git 文件夹删除即可。 参考 Hexo文档 Hexo主题 Hexo插件","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://linvaux.github.io/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Jmeter源码系列(5)-JmeterEngine-Jmeter的执行引擎","slug":"Jmeter源码系列-5-JmeterEngine-Jmeter的执行引擎","date":"2024-08-04T04:41:26.000Z","updated":"2024-09-21T01:53:16.823Z","comments":true,"path":"posts/fbd833ae/","permalink":"https://linvaux.github.io/posts/fbd833ae/","excerpt":"","text":"导读在前面的几篇文章中，笔者主要分析了Jmeter在Non-Gui模式下的启动过程，知道了jmeter在启动过程中会根据启动参数做各种初始化动作，最后通过以下代码来开始测试: 12345678910111213141516171819202122232425if (!remoteStart) &#123; JMeterEngine engine = new StandardJMeterEngine(); clonedTree.add(clonedTree.getArray()[0], new ListenToTest(org.apache.jmeter.JMeter.ListenToTest.RunMode.LOCAL, false, reportGenerator)); engine.configure(clonedTree); Instant now = Instant.now(); println(&quot;Starting standalone test @ &quot; + formatLikeDate(now) + &quot; (&quot; + now.toEpochMilli() + &#x27;)&#x27;); engines.add(engine); engine.runTest();&#125; else &#123; java.util.StringTokenizer st = new java.util.StringTokenizer(remoteHostsString.trim(), &quot;,&quot;);//$NON-NLS-1$ List&lt;String&gt; hosts = new ArrayList&lt;&gt;(); while (st.hasMoreElements()) &#123; hosts.add(((String) st.nextElement()).trim()); &#125; ListenToTest testListener = new ListenToTest(org.apache.jmeter.JMeter.ListenToTest.RunMode.REMOTE, remoteStop, reportGenerator); clonedTree.add(clonedTree.getArray()[0], testListener); DistributedRunner distributedRunner = new DistributedRunner(this.remoteProps); distributedRunner.setStdout(System.out); // NOSONAR distributedRunner.setStdErr(System.err); // NOSONAR distributedRunner.init(hosts, clonedTree); engines.addAll(distributedRunner.getEngines()); testListener.setStartedRemoteEngines(engines); distributedRunner.start();&#125;startUdpDdaemon(engines); 在上面的代码中可以看到，如果是本地执行，则创建一个 StandardJMeterEngine 实例，并调用其 configure 和 runTest 方法来执行测试计划。如果是远程执行，则创建一个 DistributedRunner 实例，并调用其 init 和 start 方法来启动远程引擎并执行测试计划。 JMeterEngineJMeterEngine是Jmeter的执行引擎，它负责执行测试计划，并管理测试计划中的各种组件，如线程组、采样器、监听器等。 JMeterEngine接口定义了以下方法： void configure(HashTree testPlan)：配置测试计划，将测试计划中的各种组件添加到执行引擎中。 void runTest() throws JMeterEngineException：运行测试计划。 default void stopTest() &#123;stopTest(true);&#125;：立即停止测试计划。 void stopTest(boolean now): 停止测试计划，如果now为true，则立即停止测试计划，否则等待测试计划完成。 void reset()：重置执行引擎，清除所有测试计划中的组件。 void setProperties(Properties p): 设置执行引擎的属性。 void exit(): 退出执行引擎。 boolean isActive(): 判断执行引擎是否正在运行。 JMeterEngine接口的实现类有StandardJMeterEngine和ClientJMeterEngine，其实大家在看Jmeter源代码时，可能会发现还有一个EmulatorEngine类实现了JMeterEngine, 这个类其实位于org.apache.jmeter.engine.DistributedRunnerTest.EmulatorEngine 是一个用于测试的类，并非是Jmeter的正式实现。 StandardJMeterEngineStandardJMeterEngine 是 JMeter 的标准引擎实现，主要用于在单独的 JMeter 服务器或本地机器上执行性能测试。类定义如下 1public class StandardJMeterEngine implements JMeterEngine, Runnable StandardJMeterEngine 除了实现 JmeterEngine 接口外，还实现了 Runnable 接口，因此它可以被提交到一个线程池中执行。接下来，我们可以从engine.configure(clonedTree) 和 engine.runTest() 为入口来分析 StandardJMeterEngine 的执行过程。 configure123456789101112131415@Overridepublic void configure(HashTree testTree) &#123; // Is testplan serialised? SearchByClass&lt;TestPlan&gt; testPlan = new SearchByClass&lt;&gt;(TestPlan.class); testTree.traverse(testPlan); Object[] plan = testPlan.getSearchResults().toArray(); if (plan.length == 0) &#123; throw new IllegalStateException(&quot;Could not find the TestPlan class!&quot;); &#125; TestPlan tp = (TestPlan) plan[0]; serialized = tp.isSerialized(); tearDownOnShutdown = tp.isTearDownOnShutdown(); active = true; test = testTree;&#125; configure方法执行过程如下： 从testTree中查找TestPlan对象，如果找不到，则抛出异常。testTree.traverse(testPlan) 的作用是遍历 HashTree 对象中的内容，并根据提供的 SearchByClass 对象对每个节点进行检查或搜索。其实HashTree#traverse使用了访问者模式，SearchByClass类实现了HashTreeTraverser接口，通过实现此接口，类可以轻松遍历 HashTree 对象，并通过某些事件的回调获得通知。 获取TestPlan对象的serialized和tearDownOnShutdown属性，并设置到StandardJMeterEngine对象中。 设置StandardJMeterEngine对象的active属性为true，表示引擎已经准备好执行测试计划。 将testTree赋值给StandardJMeterEngine对象的test属性，以便在执行测试计划时使用。 runTest123456789101112131415@Overridepublic void runTest() throws JMeterEngineException &#123; if (host != null)&#123; Instant now = Instant.now(); String nowAsString = formatLikeDate(now); System.out.println(&quot;Starting the test on host &quot; // NOSONAR Intentional + host + &quot; @ &quot; + nowAsString + &quot; (&quot; + now.toEpochMilli() + &#x27;)&#x27;); &#125; try &#123; runningTest = EXECUTOR_SERVICE.submit(this); &#125; catch (Exception err) &#123; stopTest(); throw new JMeterEngineException(err); &#125;&#125; runTest方法执行过程如下： 如果StandardJMeterEngine对象的host属性不为null，则打印一条日志，记录测试开始的时间和主机信息。 调用EXECUTOR_SERVICE.submit(this)方法将StandardJMeterEngine对象提交到一个线程池中执行。EXECUTOR_SERVICE是一个线程池，用于执行StandardJMeterEngine对象的run方法。线程池定义如下 123456789101112// 线程安全的计数器，用于在创建线程时生成唯一的线程名private static final AtomicInteger THREAD_COUNTER = new AtomicInteger(0);/** * 执行器服务，用于执行“启动测试”、“停止测试”等管理任务。使用 ExecutorService 允许从线程传播异常。线程保持alive时间设置为 1 秒，因此线程会提前释放，因此应用程序可以更快地关闭。 */private static final ExecutorService EXECUTOR_SERVICE = new ThreadPoolExecutor( 0, Integer.MAX_VALUE, 1L, TimeUnit.SECONDS, new java.util.concurrent.SynchronousQueue&lt;&gt;(), (runnable) -&gt; new Thread(runnable, &quot;StandardJMeterEngine-&quot; + THREAD_COUNTER.incrementAndGet())); 如果提交线程池失败，则调用stopTest方法停止测试，并抛出JMeterEngineException异常。 至此，StandardJMeterEngine对象的runTest方法执行完毕，测试计划开始执行。那接下来我们就需要看下StandardJMeterEngine对象的run方法了。 run先贴一个完整方法定义，然后再逐步分析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134@Overridepublic void run() &#123; log.info(&quot;Running the test!&quot;); running = true; /* * Ensure that the sample variables are correctly initialised for each run. */ SampleEvent.initSampleVariables(); JMeterContextService.startTest(); try &#123; PreCompiler compiler = new PreCompiler(); test.traverse(compiler); &#125; catch (RuntimeException e) &#123; log.error(&quot;Error occurred compiling the tree:&quot;, e); JMeterUtils.reportErrorToUser(&quot;Error occurred compiling the tree: - see log file&quot;, e); return; // no point continuing &#125; /* * Notification of test listeners needs to happen after function * replacement, but before setting RunningVersion to true. */ SearchByClass&lt;TestStateListener&gt; testListeners = new SearchByClass&lt;&gt;(TestStateListener.class); // TL - S&amp;E test.traverse(testListeners); // Merge in any additional test listeners // currently only used by the function parser testListeners.getSearchResults().addAll(testList); testList.clear(); // no longer needed test.traverse(new TurnElementsOn()); notifyTestListenersOfStart(testListeners); List&lt;?&gt; testLevelElements = new ArrayList&lt;&gt;(test.list(test.getArray()[0])); removeThreadGroups(testLevelElements); SearchByClass&lt;SetupThreadGroup&gt; setupSearcher = new SearchByClass&lt;&gt;(SetupThreadGroup.class); SearchByClass&lt;AbstractThreadGroup&gt; searcher = new SearchByClass&lt;&gt;(AbstractThreadGroup.class); SearchByClass&lt;PostThreadGroup&gt; postSearcher = new SearchByClass&lt;&gt;(PostThreadGroup.class); test.traverse(setupSearcher); test.traverse(searcher); test.traverse(postSearcher); TestCompiler.initialize(); // for each thread group, generate threads // hand each thread the sampler controller // and the listeners, and the timer Iterator&lt;SetupThreadGroup&gt; setupIter = setupSearcher.getSearchResults().iterator(); Iterator&lt;AbstractThreadGroup&gt; iter = searcher.getSearchResults().iterator(); Iterator&lt;PostThreadGroup&gt; postIter = postSearcher.getSearchResults().iterator(); ListenerNotifier notifier = new ListenerNotifier(); int groupCount = 0; JMeterContextService.clearTotalThreads(); if (setupIter.hasNext()) &#123; log.info(&quot;Starting setUp thread groups&quot;); while (running &amp;&amp; setupIter.hasNext()) &#123;//for each setup thread group AbstractThreadGroup group = setupIter.next(); groupCount++; String groupName = group.getName(); log.info(&quot;Starting setUp ThreadGroup: &#123;&#125; : &#123;&#125; &quot;, groupCount, groupName); startThreadGroup(group, groupCount, setupSearcher, testLevelElements, notifier); if (serialized &amp;&amp; setupIter.hasNext()) &#123; log.info(&quot;Waiting for setup thread group: &#123;&#125; to finish before starting next setup group&quot;, groupName); group.waitThreadsStopped(); &#125; &#125; log.info(&quot;Waiting for all setup thread groups to exit&quot;); //wait for all Setup Threads To Exit waitThreadsStopped(); log.info(&quot;All Setup Threads have ended&quot;); groupCount = 0; JMeterContextService.clearTotalThreads(); &#125; groups.clear(); // The groups have all completed now /* * Here&#x27;s where the test really starts. Run a Full GC now: it&#x27;s no harm * at all (just delays test start by a tiny amount) and hitting one too * early in the test can impair results for short tests. */ JMeterUtils.helpGC(); JMeterContextService.getContext().setSamplingStarted(true); boolean mainGroups = running; // still running at this point, i.e. setUp was not cancelled while (running &amp;&amp; iter.hasNext()) &#123;// for each thread group AbstractThreadGroup group = iter.next(); //ignore Setup and Post here. We could have filtered the searcher. but then //future Thread Group objects wouldn&#x27;t execute. if (group instanceof SetupThreadGroup || group instanceof PostThreadGroup) &#123; continue; &#125; groupCount++; String groupName = group.getName(); log.info(&quot;Starting ThreadGroup: &#123;&#125; : &#123;&#125;&quot;, groupCount, groupName); startThreadGroup(group, groupCount, searcher, testLevelElements, notifier); if (serialized &amp;&amp; iter.hasNext()) &#123; log.info(&quot;Waiting for thread group: &#123;&#125; to finish before starting next group&quot;, groupName); group.waitThreadsStopped(); &#125; &#125; // end of thread groups if (groupCount == 0) &#123; // No TGs found log.info(&quot;No enabled thread groups found&quot;); &#125; else &#123; if (running) &#123; log.info(&quot;All thread groups have been started&quot;); &#125; else &#123; log.info(&quot;Test stopped - no more thread groups will be started&quot;); &#125; &#125; //wait for all Test Threads To Exit waitThreadsStopped(); groups.clear(); // The groups have all completed now if (postIter.hasNext()) &#123; groupCount = 0; JMeterContextService.clearTotalThreads(); log.info(&quot;Starting tearDown thread groups&quot;); if (mainGroups &amp;&amp; !running) &#123; // i.e. shutdown/stopped during main thread groups running = tearDownOnShutdown; // re-enable for tearDown if necessary &#125; while (running &amp;&amp; postIter.hasNext()) &#123;//for each setup thread group AbstractThreadGroup group = postIter.next(); groupCount++; String groupName = group.getName(); log.info(&quot;Starting tearDown ThreadGroup: &#123;&#125; : &#123;&#125;&quot;, groupCount, groupName); startThreadGroup(group, groupCount, postSearcher, testLevelElements, notifier); if (serialized &amp;&amp; postIter.hasNext()) &#123; log.info(&quot;Waiting for post thread group: &#123;&#125; to finish before starting next post group&quot;, groupName); group.waitThreadsStopped(); &#125; &#125; waitThreadsStopped(); // wait for Post threads to stop &#125; notifyTestListenersOfEnd(testListeners); JMeterContextService.endTest(); if (JMeter.isNonGUI() &amp;&amp; SYSTEM_EXIT_FORCED) &#123; log.info(&quot;Forced JVM shutdown requested at end of test&quot;); System.exit(0); // NOSONAR Intentional &#125;&#125; 初始化与日志记录: 12log.info(&quot;Running the test!&quot;);running = true; 测试开始，并且设置一个标志表明测试正在运行。 采样器变量初始化 123456789SampleEvent.initSampleVariables();public static void initSampleVariables() &#123; String vars = JMeterUtils.getProperty(SAMPLE_VARIABLES); variableNames = vars != null ? vars.split(&quot;,&quot;) : new String[0]; if (log.isInfoEnabled()) &#123; log.info(&quot;List of sample_variables: &#123;&#125;&quot;, Arrays.toString(variableNames)); &#125;&#125; 初始化采样器变量，这些变量将在测试期间用于存储和访问采样数据， JMeterContextService 标记测试开始 123456789JMeterContextService.startTest();public static synchronized void startTest() &#123; if (testStart.get() == 0) &#123; NUMBER_OF_ACTIVE_THREADS.set(0); testStart.set(System.currentTimeMillis()); JMeterUtils.setProperty(&quot;TESTSTART.MS&quot;, Long.toString(testStart.get()));// $NON-NLS-1$ &#125;&#125; 这个同步的静态方法作用如下： 检查测试是否已经开始:使用原子变量 testStart（类型为 AtomicLong）来检查测试是否已经开始了。如果 testStart 的值为0，说明测试尚未开始。其实在测试结束后，也会通过调用 JMeterContextService.endTest() 方法将 testStart 的值重置为0。 设置活跃线程数:将 NUMBER_OF_ACTIVE_THREADS（也是 AtomicInteger 类型）设置为0，这通常用于跟踪活跃的线程数量。在测试开始时将其重置，以便正确地计数参与测试的线程。 记录测试开始时间:设置 testStart 的值为当前时间戳（毫秒级）。这提供了测试开始的基准时间，对于分析测试结果和监控性能指标非常有用。 保存测试开始时间到属性:将测试开始的时间戳保存到 JMeter 属性中，键为 “TESTSTART.MS”。这使得测试开始时间可以在测试过程中被其他部分引用，例如在日志记录或结果报告中。 通过调用 startTest() 方法，JMeter 能够确保每个测试运行都有一个明确的起点，这对于统计和报告测试期间的性能指标非常重要。在多线程环境中，由于该方法被声明为 synchronized，可以保证即使有多个线程同时尝试调用它，也只会有一个线程能够进入方法体，从而避免了并发修改 testStart 或 NUMBER_OF_ACTIVE_THREADS 变量可能引发的问题。 HashTree预编译 12345678try &#123; PreCompiler compiler = new PreCompiler(); test.traverse(compiler);&#125; catch (RuntimeException e) &#123; log.error(&quot;Error occurred compiling the tree:&quot;, e); JMeterUtils.reportErrorToUser(&quot;Error occurred compiling the tree: - see log file&quot;, e); return; // no point continuing&#125; 虽然代码就两三行，但是里面的信息量是非常大的，HashTree 是 JMeter 的核心数据结构，它存储了所有测试组件的配置信息，包括线程组、采样器、监听器等。在测试开始之前，JMeter 会遍历整个 HashTree，对每个组件进行预编译，以便在测试运行时能够快速地访问和执行这些组件。预编译的过程其实就是变量替换的过程，它将配置文件中的变量替换为实际的值，以便在测试运行时能够正确地使用这些变量。预编译是 JMeter 性能优化的关键之一，因为它可以减少测试运行时的计算量，提高测试的执行效率。然而，需要注意的是，某些动态值（如随机数或基于时间的值或参数化的变量等）在预编译时只能计算一次，这意味着如果需要在每次采样时都有不同的值，那么这些函数将不能完全预编译，而是在每次采样时重新计算。预编译会调用org.apache.jmeter.engine.PreCompiler#addNode 方法，其中涉及到一个非常重要的类，叫做 org.apache.jmeter.engine.util.ValueReplacer，变量替换就由它实现。由于篇幅有限，不在此处展开讲变量替换的过程，在后面讲Jmeter核心类的文章中会讲解此类。此处我们只要知道这段代码做什么就行了。 通知监听器 123456789101112/* * Notification of test listeners needs to happen after function * replacement, but before setting RunningVersion to true. */SearchByClass&lt;TestStateListener&gt; testListeners = new SearchByClass&lt;&gt;(TestStateListener.class); // TL - S&amp;Etest.traverse(testListeners);// Merge in any additional test listeners// currently only used by the function parsertestListeners.getSearchResults().addAll(testList);testList.clear(); // no longer neededtest.traverse(new TurnElementsOn());notifyTestListenersOfStart(testListeners); 遍历测试计划树，收集所有的org.apache.jmeter.testelement.TestStateListener实例，并激活所有测试元素，准备它们的运行状态，然后通知这些监听器(实现了TestStateListener接口的类)测试即将开始。TestStateListener 是 JMeter 中用于监听测试状态变化的接口，它定义了在测试开始、结束以及每个采样周期开始和结束时需要执行的方法。通过调用 notifyTestListenersOfStart() 方法，JMeter 可以确保所有注册的 TestStateListener 都能够接收到测试开始的通知，并执行相应的操作。发送测试开始通知的方法是 org.apache.jmeter.engine.StandardJMeterEngine#notifyTestListenersOfStart。 准备测试元素 123456789List&lt;?&gt; testLevelElements = new ArrayList&lt;&gt;(test.list(test.getArray()[0]));removeThreadGroups(testLevelElements);SearchByClass&lt;SetupThreadGroup&gt; setupSearcher = new SearchByClass&lt;&gt;(SetupThreadGroup.class);SearchByClass&lt;AbstractThreadGroup&gt; searcher = new SearchByClass&lt;&gt;(AbstractThreadGroup.class);SearchByClass&lt;PostThreadGroup&gt; postSearcher = new SearchByClass&lt;&gt;(PostThreadGroup.class);test.traverse(setupSearcher);test.traverse(searcher);test.traverse(postSearcher);TestCompiler.initialize(); 这里首先获取测试计划的顶层元素列表。test 对象代表的是测试计划 (TestPlan)，test.getArray()[0] 获取的是测试计划数组中的第一个元素，通常这是测试计划的根元素。然后通过调用 list() 方法获取与该元素关联的所有子元素，并将这些子元素放入一个 ArrayList 中。由于类型不确定，所以列表的类型声明为 List&lt;?&gt;。 接下来，调用 removeThreadGroups() 方法从列表中移除所有线程组。线程组是 JMeter 中用于控制测试并发性的组件，它定义了测试中并发线程的数量以及每个线程的行为。在测试计划中，线程组通常位于顶层元素之下，因此需要从顶层元素列表中移除它们，以便后续的遍历操作不会重复处理线程组。 然后，创建三个 SearchByClass 对象，分别用于搜索 SetupThreadGroup、AbstractThreadGroup 和 PostThreadGroup 类型的元素。这些类都是 JMeter 中用于控制测试设置和清理的组件，它们定义了在测试开始之前和结束之后需要执行的操作。 接下来，调用 test.traverse() 方法遍历测试计划树，将 SetupThreadGroup 类型的元素添加到 setupSearcher 的结果列表中，将 AbstractThreadGroup 类型的元素添加到 searcher 的结果列表中，将 PostThreadGroup 类型的元素添加到 postSearcher 的结果列表中。 最后，调用 TestCompiler.initialize() 方法初始化测试编译器。测试编译器是 JMeter 中用于将测试计划转换为可执行代码的组件，它将测试计划中的元素转换为相应的 Java 代码，以便在测试执行期间执行。初始化测试编译器是执行测试之前的必要步骤，它确保测试编译器已经准备好处理测试计划中的元素。划重点：TestCompiler.initialize() 方法是 JMeter 中用于初始化测试编译器的静态方法，它将测试计划中的元素转换为相应的 Java 代码，以便在测试执行期间执行。初始化测试编译器是执行测试之前的必要步骤，它确保测试编译器已经准备好处理测试计划中的元素。大家如果有兴趣，可以使用文本工具打开一个jmx文件看下，里面ThreadGroup标签有两个属性guiClass 和 testclass 在&lt;jmeter安装路径&gt;&#x2F;bin&#x2F;saveservice.properties 文件中就定义了这些标签名和全限定类名的映射关系，当然，其他组件也是类似。 准备线程组，开始预热 12345678910111213141516171819202122232425262728Iterator&lt;SetupThreadGroup&gt; setupIter = setupSearcher.getSearchResults().iterator();Iterator&lt;AbstractThreadGroup&gt; iter = searcher.getSearchResults().iterator();Iterator&lt;PostThreadGroup&gt; postIter = postSearcher.getSearchResults().iterator();ListenerNotifier notifier = new ListenerNotifier();int groupCount = 0;JMeterContextService.clearTotalThreads();if (setupIter.hasNext()) &#123; log.info(&quot;Starting setUp thread groups&quot;); while (running &amp;&amp; setupIter.hasNext()) &#123;//for each setup thread group AbstractThreadGroup group = setupIter.next(); groupCount++; String groupName = group.getName(); log.info(&quot;Starting setUp ThreadGroup: &#123;&#125; : &#123;&#125; &quot;, groupCount, groupName); startThreadGroup(group, groupCount, setupSearcher, testLevelElements, notifier); if (serialized &amp;&amp; setupIter.hasNext()) &#123; log.info(&quot;Waiting for setup thread group: &#123;&#125; to finish before starting next setup group&quot;, groupName); group.waitThreadsStopped(); &#125; &#125; log.info(&quot;Waiting for all setup thread groups to exit&quot;); //wait for all Setup Threads To Exit waitThreadsStopped(); log.info(&quot;All Setup Threads have ended&quot;); groupCount = 0; JMeterContextService.clearTotalThreads();&#125;groups.clear(); 首先，创建三个 Iterator 对象，分别用于遍历 setupSearcher、searcher 和 postSearcher 的结果列表。这些 Iterator 对象用于遍历测试计划树中找到的 SetupThreadGroup、AbstractThreadGroup 和 PostThreadGroup 类型的元素。 接下来，创建一个 ListenerNotifier 对象，用于通知监听器测试执行的状态。ListenerNotifier 是 JMeter 中用于通知监听器测试执行状态的组件，它将测试执行的状态信息传递给监听器，以便它们可以执行相应的操作。在测试执行期间，ListenerNotifier 对象会不断更新测试执行的状态，并将状态信息传递给监听器。 然后，获取测试计划树中找到的线程组的数量，并将其存储在 groupCount 变量中。groupCount 变量用于记录测试计划树中找到的线程组的数量，以便在测试执行期间进行计数。 接下来，调用 JMeterContextService.clearTotalThreads() 方法清除 JMeter 上下文中的总线程数。JMeterContextService 是 JMeter 中用于管理 JMeter 上下文的组件，它提供了许多与 JMeter 上下文相关的操作，例如获取和设置上下文属性、获取和设置上下文中的线程数等。调用 JMeterContextService.clearTotalThreads() 方法可以清除 JMeter 上下文中的总线程数，以便在测试执行期间重新计算总线程数。 然后，判断是否需要执行 setup 线程组。如果有下一个 setup 线程组，则进入 while 循环，循环执行 setup 线程组的启动操作。SetupThreadGroup 通常用于在测试开始前执行一些预处理任务，如数据库连接、服务器预热等。 如果没有线程组，或者setup线程组执行完了，则调用groups.clear()清理groups集合。 执行前，扫个地 12345JMeterUtils.helpGC();public static void helpGC() &#123; System.gc(); // NOSONAR Intentional System.runFinalization();&#125; jmeter真正开始执行前，调用System.gc()和System.runFinalization()方法，以帮助 JVM 进行垃圾回收和运行终结器。这些方法可以减少内存泄漏和垃圾堆积的问题，从而提高测试的稳定性和性能。 开始执行 1234567891011121314151617181920212223242526272829JMeterContextService.getContext().setSamplingStarted(true);boolean mainGroups = running; // still running at this point, i.e. setUp was not cancelledwhile (running &amp;&amp; iter.hasNext()) &#123;// for each thread group AbstractThreadGroup group = iter.next(); //ignore Setup and Post here. We could have filtered the searcher. but then //future Thread Group objects wouldn&#x27;t execute. if (group instanceof SetupThreadGroup || group instanceof PostThreadGroup) &#123; continue; &#125; groupCount++; String groupName = group.getName(); log.info(&quot;Starting ThreadGroup: &#123;&#125; : &#123;&#125;&quot;, groupCount, groupName); startThreadGroup(group, groupCount, searcher, testLevelElements, notifier); if (serialized &amp;&amp; iter.hasNext()) &#123; log.info(&quot;Waiting for thread group: &#123;&#125; to finish before starting next group&quot;, groupName); group.waitThreadsStopped(); &#125;&#125; // end of thread groupsif (groupCount == 0) &#123; // No TGs found log.info(&quot;No enabled thread groups found&quot;);&#125; else &#123; if (running) &#123; log.info(&quot;All thread groups have been started&quot;); &#125; else &#123; log.info(&quot;Test stopped - no more thread groups will be started&quot;); &#125;&#125;//wait for all Test Threads To ExitwaitThreadsStopped();groups.clear(); // The groups have all completed now 这段代码用于真正的拉起线程组（非 setup&#x2F;post 线程组）执行测试，在测试线程组开始执行前，JMeterContextService 会设置采样器状态为 true，即测试开始了，监听器可以开始收集数据了。 等线程组结束后，继续把线程组清理掉。 线程组执行结束，扫地 1234567891011121314151617181920212223242526if (postIter.hasNext()) &#123; groupCount = 0; JMeterContextService.clearTotalThreads(); log.info(&quot;Starting tearDown thread groups&quot;); if (mainGroups &amp;&amp; !running) &#123; // i.e. shutdown/stopped during main thread groups running = tearDownOnShutdown; // re-enable for tearDown if necessary &#125; while (running &amp;&amp; postIter.hasNext()) &#123;//for each setup thread group AbstractThreadGroup group = postIter.next(); groupCount++; String groupName = group.getName(); log.info(&quot;Starting tearDown ThreadGroup: &#123;&#125; : &#123;&#125;&quot;, groupCount, groupName); startThreadGroup(group, groupCount, postSearcher, testLevelElements, notifier); if (serialized &amp;&amp; postIter.hasNext()) &#123; log.info(&quot;Waiting for post thread group: &#123;&#125; to finish before starting next post group&quot;, groupName); group.waitThreadsStopped(); &#125; &#125; waitThreadsStopped(); // wait for Post threads to stop&#125;notifyTestListenersOfEnd(testListeners);JMeterContextService.endTest();if (JMeter.isNonGUI() &amp;&amp; SYSTEM_EXIT_FORCED) &#123; log.info(&quot;Forced JVM shutdown requested at end of test&quot;); System.exit(0); // NOSONAR Intentional&#125; post线程组类似于我们写ut时的teardown，在测试结束后，执行一些清理工作，比如关闭文件、关闭数据库连接等。PostThreadGroup 执行结束后，又会通知监听器，测试结束了，然后重置线程数为0。最后再根据配置来看在Non-Gui模式下是否需要终止进程。 总结至此，StandardJMeterEngine 的执行流程就分析完了。整个执行过程可以简短概括为： 初始化测试 执行setup线程组 执行测试线程组 执行post线程组 执行结束 ClientJMeterEngineClientJMeterEngine 是 JMeter 的客户端执行引擎，它主要负责在远程模式下，执行远程服务器上的测试计划。在执行远程测试时，ClientJMeterEngine#runTest 被非像本地测试一样被直接调用，而是通过org.apache.jmeter.engine.DistributedRunner#start(java.util.List&lt;java.lang.String&gt;)来被调用。此处我们只分析ClientJMeterEngine 的 runTest 方法。先不关注 DistributedRunner 是如何分发测试任务的。接下来我们还是从 configure 和 runTest 两个方法来入手分析 configure123456@Overridepublic void configure(HashTree testTree) &#123; TreeCloner cloner = new TreeCloner(false); testTree.traverse(cloner); test = cloner.getClonedTree();&#125; ClientJMeterEngine#configure 方法实现很简单，就是克隆一份测试计划，然后赋值给HashTree test，这个test对象会在org.apache.jmeter.engine.ClientJMeterEngine#runTest 方法中被使用。 runTestClientJmeterEngine#runTest 方法实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Overridepublic void runTest() throws JMeterEngineException &#123; log.info(&quot;running clientengine run method&quot;); // See https://bz.apache.org/bugzilla/show_bug.cgi?id=55510 JMeterContextService.clearTotalThreads(); HashTree testTree = test; synchronized(testTree) &#123; PreCompiler compiler = new PreCompiler(true); testTree.traverse(compiler); // limit the changes to client only test elements JMeterContextService.initClientSideVariables(compiler.getClientSideVariables()); testTree.traverse(new TurnElementsOn()); testTree.traverse(new ConvertListeners()); &#125; String methodName=&quot;unknown&quot;; try &#123; JMeterContextService.startTest(); /* * Add fix for Deadlocks, see: * * See https://bz.apache.org/bugzilla/show_bug.cgi?id=48350 */ File baseDirRelative = FileServer.getFileServer().getBaseDirRelative(); String scriptName = FileServer.getFileServer().getScriptName(); synchronized(LOCK) &#123; methodName=&quot;rconfigure()&quot;; // NOSONAR Used for tracing remote.rconfigure(testTree, hostAndPort, baseDirRelative, scriptName); &#125; log.info(&quot;sent test to &#123;&#125; basedir=&#x27;&#123;&#125;&#x27;&quot;, hostAndPort, baseDirRelative); // $NON-NLS-1$ if(savep == null) &#123; savep = new Properties(); &#125; log.info(&quot;Sending properties &#123;&#125;&quot;, savep); try &#123; methodName=&quot;rsetProperties()&quot;;// NOSONAR Used for tracing remote.rsetProperties(toHashMapOfString(savep)); &#125; catch (RemoteException e) &#123; log.warn(&quot;Could not set properties: &#123;&#125;, error:&#123;&#125;&quot;, savep, e.getMessage(), e); &#125; methodName=&quot;rrunTest()&quot;; remote.rrunTest(); log.info(&quot;sent run command to &#123;&#125;&quot;, hostAndPort); &#125; catch (IllegalStateException ex) &#123; log.error(&quot;Error in &#123;&#125; method &quot;, methodName, ex); // $NON-NLS-1$ $NON-NLS-2$ tidyRMI(log); throw ex; // Don&#x27;t wrap this error - display it as is &#125; catch (Exception ex) &#123; log.error(&quot;Error in &#123;&#125; method&quot;, methodName, ex); // $NON-NLS-1$ $NON-NLS-2$ tidyRMI(log); throw new JMeterEngineException(&quot;Error in &quot; + ethodName + &quot; method &quot; + ex, ex); // $NON-NLS-1$ $NON-NLS-2$ &#125;&#125; 方法执行过程如下： 初始化 JMeterContextService，将JMeterContextService中的线程信息清空，调用的方法为JMeterContextService#clearTotalThreads。 通过ClientJmeterEngine#configure方法克隆一份测试计划，赋值给一个新的HashTree对象testTree。 testTree对象被同步，然后通过PreCompiler对测试计划进行预编译，将测试计划中的变量进行替换，并获取客户端变量。 1234567synchronized(testTree) &#123; PreCompiler compiler = new PreCompiler(true); testTree.traverse(compiler); // limit the changes to client only test elements JMeterContextService.initClientSideVariables(compiler.getClientSideVariables()); testTree.traverse(new TurnElementsOn()); testTree.traverse(new ConvertListeners());&#125; PreCompiler类是JMeter的预编译器，用于替换测试计划中的变量。在上面讲StandardJMeterEngine的时候，我们提到过，JMeter的变量替换是在测试计划执行之前进行的，而PreCompiler就是负责这个工作的。 JMeterContextService.initClientSideVariables(compiler.getClientSideVariables());这行代码的作用是将预编译器中获取到的客户端变量初始化到JMeterContextService中。初始化变量的过程是org.apache.jmeter.engine.PreCompiler#addNode方法解析这个testTree，然后对HashTree中的每个元素进行判断，如果元素类型是org.apache.jmeter.testelement.TestPlan，则去解析用户自定义的变量，然后放到org.apache.jmeter.threads.JMeterVariables中，如果元素类型是org.apache.jmeter.config.Arguments, 则直接获取参数列表，然后放到org.apache.jmeter.threads.JMeterVariables中。 testTree.traverse(new TurnElementsOn());这行代码的作用是将测试计划中的所有元素都设置为运行状态，在 JMeter 中，一个测试元素可以有两个不同的状态：编辑状态和运行时状态，当测试计划在 JMeter 中被载入和显示时，它处于“编辑状态”；当测试计划被执行时，测试元素被转换到“运行状态”。 testTree.traverse(new ConvertListeners());这行代码的作用是将测试计划中的监听器转换为远程监听器，远程监听器是 JMeter 的一种特殊类型的监听器，它可以在远程服务器上运行，并将结果发送回客户端。 接下来就是通过RMI将测试计划发送到远程服务器，然后执行测试计划。RMI是Java远程方法调用（Remote Method Invocation）的简称，它是一种允许一个Java虚拟机上的对象调用另一个Java虚拟机上的对象的方法的技术。在JMeter中，RMI被用来在远程服务器上执行测试计划，并将结果发送回客户端。在org.apache.jmeter.engine.ClientJMeterEngine中，有一个private RemoteJMeterEngine remote 对象，这个对象就是用来执行远程测试计划的。在org.apache.jmeter.engine.RemoteJMeterEngine中也同样定义了与org.apache.jmeter.engine.JMeterEngine接口中类似的方法，只不过这些方法前面都多了一个r表示远程调用。如：rrunTest()、rconfigure()、rsetProperties()等。 如果在执行过程中发生异常，则停止远程服务器上的测试计划，并打印相关日志。 总结： org.apache.jmeter.engine.ClientJMeterEngine类是JMeter的客户端执行引擎，它负责将测试计划发送到远程服务器，并在远程服务器上执行测试计划。整个执行过程跟org.apache.jmeter.engine.StandardJMeterEngine类似，只不过org.apache.jmeter.engine.ClientJMeterEngine是通过RMI将测试计划发送到远程服务器，并在远程服务器上执行测试计划，然后由远程服务器将结果发送回客户端。","categories":[],"tags":[{"name":"Jmeter源码系列","slug":"Jmeter源码系列","permalink":"https://linvaux.github.io/tags/Jmeter%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/"}]},{"title":"【Jmeter扩展开发】自定义Java请求","slug":"【Jmeter扩展开发】自定义Java请求","date":"2024-08-03T01:36:37.000Z","updated":"2024-09-21T00:59:08.940Z","comments":true,"path":"posts/75270eba/","permalink":"https://linvaux.github.io/posts/75270eba/","excerpt":"","text":"自定义Java请求1. Java请求1.1 Java请求简介JMeter 内置支持了一系列的常用协议，例如 HTTP&#x2F;HTTPS、FTP、JDBC、JMS、SOAP 和 TCP 等，可以直接通过编写脚本来支持相关协议的测试场景。除了这些协议之外，用户也可能需要进行一些其他标准协议的测试，或者某些情况下在标准协议基础上增加了定制化的内容，需要对定制后的协议进行测试。本文中介绍的 Java Sampler 扩展机制就是 JMeter 提供的一种可以轻松实现对新协议支持的方式。 1.2 Java请求的使用场景Java请求可以用于以下场景： 需要在JMeter中实现复杂的请求逻辑，例如需要调用多个Java类或方法，或者需要处理复杂的返回值。 需要在JMeter中实现自定义的协议，或者Jmeter原生尚未支持的协议，例如需要调用自定义的协议或协议扩展。 需要在JMeter中实现一些特殊的测试需求，例如需要调用第三方API或服务，或者需要处理一些特殊的返回值。 不想写beanshell脚本，或者beanshell脚本无法满足需求。 2. Java请求的实现2.1 工程创建 使用Maven的quickstart模板创建一个Maven项目 在pom.xml文件中添加以下依赖： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wick.jmeter.demo&lt;/groupId&gt; &lt;artifactId&gt;jmeter-java-test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;jmeter.version&gt;5.4.1&lt;/jmeter.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.jmeter&lt;/groupId&gt; &lt;artifactId&gt;ApacheJMeter_java&lt;/artifactId&gt; &lt;version&gt;$&#123;jmeter.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2.2 代码实现 创建一个Java类，该类需要实现org.apache.jmeter.protocol.java.sampler.JavaSamplerClient接口，或者继承 org.apache.jmeter.protocol.java.sampler.AbstractJavaSamplerClient。 在Java类中，实现&#x2F;重写以下4个方法: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.wick.jmeter.demo;import org.apache.jmeter.config.Arguments;import org.apache.jmeter.protocol.java.sampler.AbstractJavaSamplerClient;import org.apache.jmeter.protocol.java.sampler.JavaSamplerContext;import org.apache.jmeter.samplers.SampleResult;/** * @author: wick * @date: 2024/8/3 09:58 * @description: jmeter自定义java请求 */public class CustomJavaRequestTest extends AbstractJavaSamplerClient &#123; /** * 获取参数，此方法中配置的参数会在Jmeter的Java请求页面展示， * @return 请求参数 */ @Override public Arguments getDefaultParameters() &#123; return super.getDefaultParameters(); &#125; /** * 测试开始前做初始化，只会执行一次 * @param context Jmeter采样器上下文 */ @Override public void setupTest(JavaSamplerContext context) &#123; super.setupTest(context); &#125; /** * 测试结束后做清理，只会执行一次 * @param context Jmeter采样器上下文 */ @Override public void teardownTest(JavaSamplerContext context) &#123; super.teardownTest(context); &#125; /** * 采样器执行，执行多次，具体执行次数取决于此采样器所在的线程组配置 * @param context Jmeter采样器上下文 * @return 采样器结果 */ public SampleResult runTest(JavaSamplerContext context) &#123; return null; &#125;&#125; 2.3 打包测试 打包jar，注意：需要将带有完整依赖的jar打包出来，否则运行时可能会报错1mvn clean package -T 4C -DskipTests 将jar放到 &lt;jmeter安装路径&gt;/lib/ext/ 目录下 重启Jmeter，在Jmeter中添加Java请求，并配置参数，运行测试 3. Java请求的配置在JMeter中，可以通过以下步骤打开Java请求的配置界面： 在JMeter的测试计划中，右键单击要添加Java请求的线程组。 选择“添加” -&gt; “采样器” -&gt; “Java请求”。 在Java请求的配置界面中，可以设置以下参数： 名称：Java请求的名称。 类名：Java请求的类名。 请求参数：Java请求中设置的参数。 4. Java请求完整代码 假设我们需要实现以下需求：请求一个http接口，但是需要对其中某个字段做Base64编码，然后将编码后的字段作为请求参数传递给http接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.wick.jmeter.demo;import com.thoughtworks.xstream.core.util.Base64Encoder;import kong.unirest.Cookie;import kong.unirest.HttpResponse;import kong.unirest.JsonNode;import kong.unirest.Unirest;import org.apache.jmeter.config.Arguments;import org.apache.jmeter.protocol.java.sampler.AbstractJavaSamplerClient;import org.apache.jmeter.protocol.java.sampler.JavaSamplerContext;import org.apache.jmeter.samplers.SampleResult;import java.nio.charset.StandardCharsets;/** * @author: wick * @date: 2024/8/3 09:58 * @description: jmeter自定义java请求 */public class CustomJavaRequestTest extends AbstractJavaSamplerClient &#123; /** * 参数 */ private final String PARAM_USERNAME = &quot;username&quot;; private final String PARAM_PASSWORD = &quot;password&quot;; /** * 获取参数，此方法中配置的参数会在Jmeter的Java请求页面展示， * @return 请求参数 */ @Override public Arguments getDefaultParameters() &#123; Arguments arguments = new Arguments(); arguments.addArgument(PARAM_USERNAME, &quot;zhang_san&quot;); arguments.addArgument(PARAM_PASSWORD, &quot;1234&quot;); return arguments; &#125; /** * 测试开始前做初始化，只会执行一次 * @param context Jmeter采样器上下文 */ @Override public void setupTest(JavaSamplerContext context) &#123; Unirest.config() .defaultBaseUrl(&quot;https://httpbin.org/&quot;) .connectTimeout(60000) .addDefaultCookie(new Cookie(&quot;timestamp&quot;,String.valueOf(System.currentTimeMillis()))); &#125; /** * 采样器执行，执行多次，具体执行次数取决于此采样器所在的线程组配置 * @param context Jmeter采样器上下文 * @return 采样器结果 */ public SampleResult runTest(JavaSamplerContext context) &#123; String username = context.getParameter(PARAM_USERNAME); String password = context.getParameter(PARAM_PASSWORD); SampleResult result = new SampleResult(); result.sampleStart(); HttpResponse&lt;JsonNode&gt; response; try &#123; response = Unirest.get(&quot;/get&quot;) .queryString(&quot;username&quot;, username) .queryString(&quot;password&quot;, new Base64Encoder().encode(password.getBytes())) .asJson(); result.setSuccessful(response.isSuccess()); result.setSamplerData(response.getRequestSummary().getUrl()); result.setResponseCode(response.getStatusText()); result.setResponseHeaders(response.getHeaders().toString()); result.setResponseData(response.getBody().toString(), StandardCharsets.UTF_8.name()); &#125;catch (Exception e)&#123; result.setSuccessful(false); result.setResponseData(e.getMessage(), StandardCharsets.UTF_8.name()); &#125; result.sampleEnd(); return result; &#125; /** * 测试结束后做清理，只会执行一次 * @param context Jmeter采样器上下文 */ @Override public void teardownTest(JavaSamplerContext context) &#123; Unirest.shutDown(); &#125;&#125; 最后，在jmeter中添加Java请求，选中自己开发的请求类 com.wick.jmeter.demo.CustomJavaRequestTest 并配置参数，即可运行。","categories":[],"tags":[{"name":"Jmeter扩展开发","slug":"Jmeter扩展开发","permalink":"https://linvaux.github.io/tags/Jmeter%E6%89%A9%E5%B1%95%E5%BC%80%E5%8F%91/"}]},{"title":"IDEA插件整理(二)","slug":"IDEA插件整理-二","date":"2024-07-31T14:02:28.000Z","updated":"2024-09-21T00:59:08.924Z","comments":true,"path":"posts/67f865da/","permalink":"https://linvaux.github.io/posts/67f865da/","excerpt":"","text":"Mario Progress Bar 马里奥进度条，非常可爱 Cool Request IDEA里面非常好用的httpClient，支持发现项目中的接口，并且能自动填充请求报文 arthas idea 基于IntelliJ IDEA开发的Arthas命令生成插件，支持阿里巴巴Arthas官方常用命令。 jclasslib Bytecode Viewer 字节码反编译插件，对于想学习字节码和jvm的同学比较有用，功能强大。选中字节码文件 -&gt; 点击菜单栏View -&gt; 点击 Show Bytecode With Jclasslib 即可 Github Copilot Github出的神级代码提示插件，没有之一，不过要收费，可以自己去某宝上买账号 HighlightBracketPair 专注显示当前光标所在的括号范围，配合彩虹括号插件(Rainbow Brackets)使用更佳 Smart Input 智能切换输入法，该插件核心功能可以根据输入位置的上下文智能分析当前处于什么场景应该使用哪种输入法并自动切换，而且还可以&gt; 通过光标的颜色来提醒当前是什么输入法以及大小写状态。以下列举其中几个场景: 识别到注释场景时，自动切换为中文输入法。 识别到IdeaVim命令模式时，自动切换为英文输入法。 识别到Commit Message场景时，自动切换为中文输入法。 识别到Terminal窗口获得焦点时，自动切换为英文输入法。 用户输入字符串字面量时记录主动切换输入法习惯，下次自动切换到对应的输入法，越用越智能 我试了下，确实好用！","categories":[],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://linvaux.github.io/tags/IDEA/"}]},{"title":"Jmeter源码系列(4) - Jmeter 类详解-runNonGui()，无界面模式下的脚本执行过程","slug":"Jmeter源码系列-4-Jmeter-类详解-runNonGui-，无界面模式下的脚本执行过程","date":"2024-07-28T14:03:54.000Z","updated":"2024-09-21T00:59:08.935Z","comments":true,"path":"posts/7d6bf7a5/","permalink":"https://linvaux.github.io/posts/7d6bf7a5/","excerpt":"","text":"在前面几篇文章中，我们已经知道了 Jmeter 的启动过程，接下来我们一起看下，在 NON-GUI 模式下，Jmeter 是如何开始执行我们的 jmx 脚本的 startNonGui以下是 startNonGui 源代码，其实也没几行，简单过一下即可。 123456789101112131415161718192021222324private void startNonGui(String testFile, String logFile, CLOption remoteStart, boolean generateReportDashboard) throws IllegalUserActionException, ConfigurationException &#123; // add a system property so samplers can check to see if JMeter // is running in NonGui mode System.setProperty(JMETER_NON_GUI, &quot;true&quot;);// $NON-NLS-1$ JMeter driver = new JMeter();// TODO - why does it create a new instance? driver.remoteProps = this.remoteProps; driver.remoteStop = this.remoteStop; driver.deleteResultFile = this.deleteResultFile; PluginManager.install(this, false); String remoteHostsString = null; if (remoteStart != null) &#123; remoteHostsString = remoteStart.getArgument(); if (remoteHostsString == null) &#123; remoteHostsString = JMeterUtils.getPropDefault( &quot;remote_hosts&quot;, //$NON-NLS-1$ &quot;127.0.0.1&quot;);//NOSONAR $NON-NLS-1$ &#125; &#125; if (testFile == null) &#123; throw new IllegalUserActionException(&quot;Non-GUI runs require a test plan&quot;); &#125; driver.runNonGui(testFile, logFile, remoteStart != null, remoteHostsString, generateReportDashboard); &#125; 设置了环境变量 JMeter.NonGui&#x3D;true，其实我目前也不知道这个环境变量在哪里被用到了。 JMeter driver &#x3D; new JMeter(); 后面的TODO很有意思，为啥要创建一个新实例？其实在 org.apache.jmeter.JMeter 类中，只有此处实例化了Jmeter这个变量，加TODO的这个人估计想用单例模式来获取对象，但是明显是没必要的，因为Jmeter在NonGui模式下执行完jmx文件之后就结束进程了，倒也没必要用单例。 设置driver的两个属性，这两个属性一般在分布式压测时才需要 1234567891011121314/** * 需要发送到远程服务器的配置 */private Properties remoteProps;/** * 测试结束后，是否停止远程引擎 */private boolean remoteStop;/** * 测试开始前，是否删除 jtl 和 report */private boolean deleteResultFile = false; 插件管理器安装插件，一般对于GUI模式来说，需要执行此过程加载不同插件的页面，此处为 false，实际上不会安装 检查是否是远程启动压测，否则的话配置远程服务器地址为本机ip，然后检查jmx文件是否为null，接下来开始调用 runNonGui 真正的执行测试了。 runNonGui先贴个源码，这个方法有点点复杂，但是也是NonGui模式下最核心的方法了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108void runNonGui(String testFile, String logFile, boolean remoteStart, String remoteHostsString, boolean generateReportDashboard) throws ConfigurationException &#123; try &#123; File f = new File(testFile); if (!f.exists() || !f.isFile()) &#123; throw new ConfigurationException(&quot;The file &quot; + f.getAbsolutePath() + &quot; doesn&#x27;t exist or can&#x27;t be opened&quot;); &#125; FileServer.getFileServer().setBaseForScript(f); HashTree tree = SaveService.loadTree(f); @SuppressWarnings(&quot;deprecation&quot;) // Deliberate use of deprecated ctor JMeterTreeModel treeModel = new JMeterTreeModel(new Object());// NOSONAR Create non-GUI version to avoid headless problems JMeterTreeNode root = (JMeterTreeNode) treeModel.getRoot(); treeModel.addSubTree(tree, root); // Hack to resolve ModuleControllers in non GUI mode SearchByClass&lt;ReplaceableController&gt; replaceableControllers = new SearchByClass&lt;&gt;(ReplaceableController.class); tree.traverse(replaceableControllers); Collection&lt;ReplaceableController&gt; replaceableControllersRes = replaceableControllers.getSearchResults(); for (ReplaceableController replaceableController : replaceableControllersRes) &#123; replaceableController.resolveReplacementSubTree(root); &#125; // Ensure tree is interpreted (ReplaceableControllers are replaced) // For GUI runs this is done in Start.java HashTree clonedTree = convertSubTree(tree, true); Summariser summariser = null; String summariserName = JMeterUtils.getPropDefault(&quot;summariser.name&quot;, &quot;&quot;);//$NON-NLS-1$ if (summariserName.length() &gt; 0) &#123; log.info(&quot;Creating summariser &lt;&#123;&#125;&gt;&quot;, summariserName); println(&quot;Creating summariser &lt;&quot; + summariserName + &quot;&gt;&quot;); summariser = new Summariser(summariserName); &#125; ResultCollector resultCollector = null; if (logFile != null) &#123; resultCollector = new ResultCollector(summariser); resultCollector.setFilename(logFile); clonedTree.add(clonedTree.getArray()[0], resultCollector); &#125; else &#123; // only add Summariser if it can not be shared with the ResultCollector if (summariser != null) &#123; clonedTree.add(clonedTree.getArray()[0], summariser); &#125; &#125; if (deleteResultFile) &#123; SearchByClass&lt;ResultCollector&gt; resultListeners = new SearchByClass&lt;&gt;(ResultCollector.class); clonedTree.traverse(resultListeners); for (ResultCollector rc : resultListeners.getSearchResults()) &#123; File resultFile = new File(rc.getFilename()); if (resultFile.exists() &amp;&amp; !resultFile.delete()) &#123; throw new IllegalStateException(&quot;Could not delete results file &quot; + resultFile.getAbsolutePath() + &quot;(canRead:&quot; + resultFile.canRead() + &quot;, canWrite:&quot; + resultFile.canWrite() + &quot;)&quot;); &#125; &#125; &#125; ReportGenerator reportGenerator = null; if (logFile != null &amp;&amp; generateReportDashboard) &#123; reportGenerator = new ReportGenerator(logFile, resultCollector); &#125; // Used for remote notification of threads start/stop,see BUG 54152 // Summariser uses this feature to compute correctly number of threads // when NON GUI mode is used clonedTree.add(clonedTree.getArray()[0], new RemoteThreadsListenerTestElement()); List&lt;JMeterEngine&gt; engines = new ArrayList&lt;&gt;(); println(&quot;Created the tree successfully using &quot;+testFile); if (!remoteStart) &#123; JMeterEngine engine = new StandardJMeterEngine(); clonedTree.add(clonedTree.getArray()[0], new ListenToTest( org.apache.jmeter.JMeter.ListenToTest.RunMode.LOCAL, false, reportGenerator)); engine.configure(clonedTree); Instant now = Instant.now(); println(&quot;Starting standalone test @ &quot;+ formatLikeDate(now) + &quot; (&quot; + now.toEpochMilli() + &#x27;)&#x27;); engines.add(engine); engine.runTest(); &#125; else &#123; java.util.StringTokenizer st = new java.util.StringTokenizer(remoteHostsString.trim(), &quot;,&quot;);//$NON-NLS-1$ List&lt;String&gt; hosts = new ArrayList&lt;&gt;(); while (st.hasMoreElements()) &#123; hosts.add(((String) st.nextElement()).trim()); &#125; ListenToTest testListener = new ListenToTest( org.apache.jmeter.JMeter.ListenToTest.RunMode.REMOTE, remoteStop, reportGenerator); clonedTree.add(clonedTree.getArray()[0], testListener); DistributedRunner distributedRunner=new DistributedRunner(this.remoteProps); distributedRunner.setStdout(System.out); // NOSONAR distributedRunner.setStdErr(System.err); // NOSONAR distributedRunner.init(hosts, clonedTree); engines.addAll(distributedRunner.getEngines()); testListener.setStartedRemoteEngines(engines); distributedRunner.start(); &#125; startUdpDdaemon(engines); &#125; catch (ConfigurationException e) &#123; throw e; &#125; catch (Exception e) &#123; System.out.println(&quot;Error in NonGUIDriver &quot; + e.toString());//NOSONAR log.error(&quot;Error in NonGUIDriver&quot;, e); throw new ConfigurationException(&quot;Error in NonGUIDriver &quot; + e.getMessage(), e); &#125; &#125; 下面对这个方法执行过程进行分析，其中涉及到非常多的Jmeter核心类，以及几个比较重要的方法，这里就不一一展开，只对核心流程进行分析，这些核心类&#x2F;方法会在后面的文章中展开讲解。 检查测试文件： 1234File f = new File(testFile);if (!f.exists() || !f.isFile()) &#123; throw new ConfigurationException(&quot;The file &quot; + f.getAbsolutePath() + &quot; doesn&#x27;t exist or can&#x27;t be opened&quot;);&#125; 首先，通过提供的testFile(由启动参数 -t 指定))字符串创建一个File对象。然后检查这个文件是否存在并且是否是一个文件实体（而不是目录）。如果文件不存在或者无法打开，将抛出一个ConfigurationException。 设置文件服务器基目录： 1FileServer.getFileServer().setBaseForScript(f); 设置JMeter的基目录，这样JMeter就可以基于这个目录来查找和加载其他依赖的文件，比如图片、CSV数据文件等。 加载测试计划： 1HashTree tree = SaveService.loadTree(f); 从文件系统中读取测试计划的HashTree结构，这是JMeter内部存储测试元素的方式。 构建测试树模型： 1234@SuppressWarnings(&quot;deprecation&quot;) // Deliberate use of deprecated ctorJMeterTreeModel treeModel = new JMeterTreeModel(new Object());// NOSONAR Create non-GUI version to avoid headless problemsJMeterTreeNode root = (JMeterTreeNode) treeModel.getRoot();treeModel.addSubTree(tree, root); 创建一个JMeterTreeModel，并使用HashTree填充它，以构建完整的测试计划模型。 处理模块控制器： 1234567// Hack to resolve ModuleControllers in non GUI modeSearchByClass&lt;ReplaceableController&gt; replaceableControllers = new SearchByClass&lt;&gt;(ReplaceableController.class);tree.traverse(replaceableControllers);Collection&lt;ReplaceableController&gt; replaceableControllersRes = replaceableControllers.getSearchResults();for (ReplaceableController replaceableController : replaceableControllersRes) &#123; replaceableController.resolveReplacementSubTree(root);&#125; 在非GUI模式下，模块控制器需要特殊处理，因为它们可能包含引用其他测试片段的逻辑。这里遍历整个HashTree，找到所有ReplaceableController类的实例，并替换其内部的子树。 复制和解析测试树： 1HashTree clonedTree = convertSubTree(tree, true); 调用convertSubTree(tree, true);函数对测试树进行复制，确保所有ReplaceableControllers都被解析和替换。同时，如果有被禁用的元素，在这一步也会被删除。否则即使元素被禁用，也会被Jmeter执行引擎加载执行。 结果收集与汇总： 123456String summariserName = JMeterUtils.getPropDefault(&quot;summariser.name&quot;, &quot;&quot;);//$NON-NLS-1$if (summariserName.length() &gt; 0) &#123; log.info(&quot;Creating summariser &lt;&#123;&#125;&gt;&quot;, summariserName); println(&quot;Creating summariser &lt;&quot; + summariserName + &quot;&gt;&quot;); summariser = new Summariser(summariserName);&#125; 创建一个Summariser，用于在测试过程中实时显示摘要信息。其实在jmeter.properties文件中，默认是启用了Summariser的，所以这里会创建一个Summariser。 1summariser.name=summary 在执行测试时，我们也会在命令行看到类似这样的输出： 1234Creating summariser &lt;summary&gt;Created the tree successfully using test.jmxStarting standalone test @ Sat Aug 03 16:57:49 CST 2024 (1722675469483)Waiting for possible Shutdown/StopTestNow/HeapDump/ThreadDump message on port 4445 123456789101112ResultCollector resultCollector = null;if (logFile != null) &#123; resultCollector = new ResultCollector(summariser); resultCollector.setFilename(logFile); clonedTree.add(clonedTree.getArray()[0], resultCollector);&#125;else &#123; // only add Summariser if it can not be shared with the ResultCollector if (summariser != null) &#123; clonedTree.add(clonedTree.getArray()[0], summariser); &#125;&#125; 如果提供了logFile(由启动参数 -l 指定)，则创建一个ResultCollector来收集测试结果到文件中。如果没有指定文件，但有summariser，那么仅添加汇总器。 处理结果文件： 1234567891011if (deleteResultFile) &#123; SearchByClass&lt;ResultCollector&gt; resultListeners = new SearchByClass&lt;&gt;(ResultCollector.class); clonedTree.traverse(resultListeners); for (ResultCollector rc : resultListeners.getSearchResults()) &#123; File resultFile = new File(rc.getFilename()); if (resultFile.exists() &amp;&amp; !resultFile.delete()) &#123; throw new IllegalStateException(&quot;Could not delete results file &quot; + resultFile.getAbsolutePath() + &quot;(canRead:&quot; + resultFile.canRead() + &quot;, canWrite:&quot; + resultFile.canWrite() + &quot;)&quot;); &#125; &#125;&#125; 如果deleteResultFile为true(由启动参数 -f 指定)，则删除任何已存在的结果文件。如果deleteResultFile为false，则跳过这一步。 报告生成： 1234ReportGenerator reportGenerator = null;if (logFile != null &amp;&amp; generateReportDashboard) &#123; reportGenerator = new ReportGenerator(logFile, resultCollector);&#125; 如果generateReportDashboard(由启动参数 -e 指定)为true，并且指定了logFile，则创建一个ReportGenerator，用于在测试完成后生成详细的HTML报告。 远程通知与线程监听： 1clonedTree.add(clonedTree.getArray()[0], new RemoteThreadsListenerTestElement()); 添加一个RemoteThreadsListenerTestElement到测试树中，用于在非GUI模式下通知线程的开始和停止。 启动测试引擎： 1234567891011121314151617181920212223242526if (!remoteStart) &#123; JMeterEngine engine = new StandardJMeterEngine(); clonedTree.add(clonedTree.getArray()[0], new ListenToTest( org.apache.jmeter.JMeter.ListenToTest.RunMode.LOCAL, false, reportGenerator)); engine.configure(clonedTree); Instant now = Instant.now(); println(&quot;Starting standalone test @ &quot;+ formatLikeDate(now) + &quot; (&quot; + now.toEpochMilli() + &#x27;)&#x27;); engines.add(engine); engine.runTest();&#125; else &#123; java.util.StringTokenizer st = new java.util.StringTokenizer(remoteHostsString.trim(), &quot;,&quot;);//$NON-NLS-1$ List&lt;String&gt; hosts = new ArrayList&lt;&gt;(); while (st.hasMoreElements()) &#123; hosts.add(((String) st.nextElement()).trim()); &#125; ListenToTest testListener = new ListenToTest( org.apache.jmeter.JMeter.ListenToTest.RunMode.REMOTE, remoteStop, reportGenerator); clonedTree.add(clonedTree.getArray()[0], testListener); DistributedRunner distributedRunner=new DistributedRunner(this.remoteProps); distributedRunner.setStdout(System.out); // NOSONAR distributedRunner.setStdErr(System.err); // NOSONAR distributedRunner.init(hosts, clonedTree); engines.addAll(distributedRunner.getEngines()); testListener.setStartedRemoteEngines(engines); distributedRunner.start();&#125; 如果remoteStart(由启动参数 -R 指定)为false，则在本地运行测试。创建一个StandardJMeterEngine实例，配置测试树并运行。如果remoteStart(由启动参数 -R 指定)为true，则执行分布式测试。解析remoteHostsString以获取远程主机列表，创建ListenToTest监听器和DistributedRunner实例，初始化并开始分布式测试。 启动UDP守护进程： 1startUdpDdaemon(engines); 启动UDP守护进程，用于在分布式测试中接收来自远程节点的信号。此方法执行过程如下： 获取端口号：从JMeter的属性中读取默认的UDP端口号（jmeterengine.nongui.port），如果没有设置则使用常量UDP_PORT_DEFAULT作为默认值。同样，也读取最大端口号（jmeterengine.nongui.maxport），默认为4455，用于当指定端口被占用时寻找下一个可用端口。 检查端口号的有效性：如果端口号大于1000（通常操作系统保留了小于1024的端口给系统服务），则继续尝试创建DatagramSocket；否则，代码将不会尝试创建。 创建DatagramSocket：调用getSocket方法尝试在指定端口创建一个UDP套接字，如果该端口被占用，会尝试下一个直到达到最大端口号maxPort。 创建线程：如果成功创建了DatagramSocket，则创建一个新的线程waiter，并将其命名为”UDP Listener”。线程的run方法中调用waitForSignals方法，传入JMeter引擎列表和DatagramSocket，这表明线程的主要任务是等待并处理来自这些引擎的信号。 设置线程为守护线程：将waiter线程设置为守护线程（setDaemon(true)），这意味着当所有非守护线程结束时，JVM也会终止，即使守护线程还在运行。 启动线程：使用waiter.start();启动线程，使它开始执行run方法中的逻辑。 错误处理：如果没有成功创建DatagramSocket，则输出一条错误信息“Failed to create UDP port”，表明未能创建UDP端口。 整个过程是为了在JMeter非GUI模式下支持分布式测试，守护进程会监听特定的UDP端口，以便从远程节点接收控制信号，如测试的开始、停止或状态更新。这使得JMeter能够协调多个远程节点上的测试执行，实现分布式压力测试。 总结来说，这个方法的核心功能是在非GUI模式下加载和运行一个JMeter测试计划，无论是本地还是分布式，同时管理结果的收集、汇总和报告生成。这在自动化测试和持续集成环境中非常有用，因为它可以避免图形界面带来的资源开销，提高测试效率。","categories":[],"tags":[{"name":"Jmeter源码系列","slug":"Jmeter源码系列","permalink":"https://linvaux.github.io/tags/Jmeter%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/"}]},{"title":"Java集成GradleToolingAPI编译Gradle项目","slug":"Java集成GradleToolingAPI编译Gradle项目","date":"2024-07-13T15:15:50.000Z","updated":"2024-09-21T00:59:08.930Z","comments":true,"path":"posts/a60e7042/","permalink":"https://linvaux.github.io/posts/a60e7042/","excerpt":"","text":"解决方案使用Java代码控制Gradle编译与Maven Embedder编译有所不同，需要额外安装Gradle工具到本地，MavenEmbedder则是直接通过集成jar的方式实现。所以在编译Gradle项目之前，需要先在本地安装对应版本的Gradle，无需配置环境变量。 安装Gradle下载Gradle：https://gradle.org/releases/ 选择需要的版本安装即可 binary-only: 只有二进制文件 complete: 在二进制包基础上增加了 文档 , 源码 建议选择binary-only版本，我们只需要实现代码编译即可，无需引入其他内容。 引入依赖123456&lt;!-- gradle版本查询：https://mvnrepository.com/artifact/org.netbeans.external/gradle-tooling-api --&gt;&lt;dependency&gt; &lt;groupId&gt;org.netbeans.external&lt;/groupId&gt; &lt;artifactId&gt;gradle-tooling-api&lt;/artifactId&gt; &lt;version&gt;$&#123;gradle-tooling-api.version&#125;&lt;/version&gt;&lt;/dependency&gt; 笔者使用的版本为：RELEASE170 代码实现GradleCommand12345678910111213141516171819202122232425262728293031323334353637/** * @author: wick * @date: 2024/6/19 21:12 * @description: gradle编译相关命令 */public class GradleCommand &#123; /** * gradle命令 */ public static final String GRADLE = &quot;gradle&quot;; /** * 清理构建产物 */ public static final String CLEAN = &quot;clean&quot;; /** * 执行测试 */ public static final String TEST = &quot;test&quot;; /** * 排除某个任务 */ public static final String EXCLUDE = &quot;-x&quot;; /** * 编译 class */ public static final String CLASSES = &quot;classes&quot;; public static final List&lt;String&gt; COMMAND = new ArrayList&lt;&gt;() &#123;&#123; add(CLEAN); add(CLASSES); &#125;&#125;;&#125; Constant12public static final String JAVA_HOME = &quot;java.home&quot;;public static final File DEFAULT_GRADLE_USER_HOME = new File(&quot;~/.gradle&quot;); GradleManager123456789101112131415161718192021222324/** * @author: wick * @date: 2024/6/19 21:06 * @description: gradle编译接口 */public interface GradleBuildManager &#123; /** * 代码编译 * * @param dto dto */ void compiler(CompileDTO dto); /** * 获取模块列表 * * @param jdkPath jdk安装路径 * @param gradlePath gradle 安装路径 * @param codePath 代码路径 * @return 模块列表 */ List&lt;String&gt; modules(String jdkPath,String gradlePath, String codePath);&#125; GradleBuildManagerImpl1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Component@Slf4jpublic class GradleBuildManagerImpl implements GradleBuildManager &#123; @Override public void compiler(CompileDTO dto) &#123; log.info(&quot;开始编译Gradle项目，编译工具路径: &#123;&#125;，代码路径: &#123;&#125;, 编译参数: &#123;&#125;&quot;, dto.getBuildToolPath(), dto.getCodePath(), dto.getCommands()); long startTime = System.currentTimeMillis(); // 重定向标准错误输出流 ByteArrayOutputStream errorStream = new ByteArrayOutputStream(); PrintStream originalErrStream = System.err; // 重定向标准输出流 ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); PrintStream originalOutStream = System.out; try (ProjectConnection connection = GradleConnector.newConnector() .forProjectDirectory(new File(dto.getCodePath())) .useGradleUserHomeDir(CoverageConstant.DEFAULT_GRADLE_USER_HOME) .useInstallation(new File(dto.getBuildToolPath())) .connect()) &#123; BuildLauncher build = connection.newBuild(); build.setJavaHome(new File(dto.getJdkPath())); System.setErr(new PrintStream(errorStream)); System.setOut(new PrintStream(outputStream)); build.forTasks(dto.getCommands().toArray(new String[0])) .setStandardOutput(System.out) .setStandardError(System.err) // 跳过单测，多线程编译 .withArguments(GradleCommand.EXCLUDE, GradleCommand.TEST) // 不使用彩色日志，否则会导致日志中的颜色代码被打印出来，导致日志不易阅读 .setColorOutput(false) // 限制 gradle 内存，防止编译过程中内存溢出，具体配置视服务器内存而定 .setJvmArguments(&quot;-Xmx512m&quot;); build.run(); log.info(&quot;编译日志:\\n &#123;&#125;&quot;, outputStream); &#125; catch (Exception e) &#123; log.error(&quot;代码: &#123;&#125; 编译失败, 异常详情: &#123;&#125;&quot;, dto.getCodePath(), ExceptionUtils.getRootCauseMessage(e)); log.error(&quot;编译异常日志:\\n &#123;&#125;&quot;, errorStream); throw new ServiceException(&quot;编译失败&quot;); &#125; finally &#123; System.setErr(originalErrStream); System.setOut(originalOutStream); &#125; log.info(&quot;结束编译Gradle项目，编译耗时: &#123;&#125; s&quot;, (System.currentTimeMillis() - startTime) / 1000); &#125; @Override public List&lt;String&gt; modules(String jdkPath, String gradlePath, String codePath) &#123; String originJavaHome = System.getProperty(SystemPropertiesConstant.JAVA_HOME); System.setProperty(SystemPropertiesConstant.JAVA_HOME, jdkPath); log.info(&quot;开始扫描Gradle项目模块，编译工具路径: &#123;&#125;，代码路径: &#123;&#125;&quot;, gradlePath, codePath); try (ProjectConnection connection = GradleConnector.newConnector() .forProjectDirectory(new File(codePath)) .useInstallation(new File(gradlePath)) .connect()) &#123; GradleProject model = connection.getModel(GradleProject.class); return model.getChildren().stream().map(GradleProject::getName).collect(Collectors.toList()); &#125; catch (Exception e) &#123; log.error(&quot;代码: &#123;&#125; 模块扫描失败, 异常详情: &#123;&#125;&quot;, codePath, ExceptionUtils.getRootCauseMessage(e)); throw new ServiceException(&quot;模块扫描失败&quot;); &#125; finally &#123; System.setProperty(SystemPropertiesConstant.JAVA_HOME, originJavaHome); &#125; &#125;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://linvaux.github.io/tags/Java/"}]},{"title":"JVM 命令/工具使用介绍","slug":"JVM-命令-工具使用介绍","date":"2024-05-04T04:55:16.000Z","updated":"2024-09-21T00:59:08.927Z","comments":true,"path":"posts/f1ffc212/","permalink":"https://linvaux.github.io/posts/f1ffc212/","excerpt":"","text":"JDK 自带了非常多的工具用于管理和监控 Java 应用程序状态，对于 Java 开发者来说，了解这些工具如何使用是非常有必要的，尤其是在排查线上问题，或者使用内部网络的情况下，可能无法或不允许使用三方工具，如 arthas，jvm-tools 等，这个时候熟练使用 JDK 自带的 jvm 工具就非常有助于我们分析和解决 jvm 的问题。接下来我将对 JDK 中自带的比较常用的工具进行介绍，同时也会穿插部分其他 jvm 分析工具的讲解。 注意：以下内容均基于 JDK-11.0.12 版本讲解，不同版本的 JDK 中，命令或许有所不同。 jps:虚拟机进程状况工具JPS（Java Virtual Machine Process Status Tool）是Java自带的命令行工具，用于列出当前运行的Java虚拟机（JVM）进程的信息。它提供了一种简单的方法来查看正在运行的Java进程的PID（Process ID）和主类名称。以下是JPS命令的一般语法和选项： 1jps [ options ] 常见的选项包括： -q：只输出PID，不显示主类的名称。 -l：输出PID和主类的全名，即全限定类名。 -m：输出PID和主类的名称，并显示传递给main()方法的参数。 -v: 输出传递给 JVM 的参数 使用JPS命令可以获得以下信息： 运行的Java进程的PID（Process ID）：JPS可以列出当前正在运行的Java进程的PID，可以方便地使用其他工具（如jstack、jmap）进行进程诊断和分析。 主类的名称：JPS可以显示启动Java进程的主类的名称，这对于排查运行中的Java进程非常有用。 主类的参数：如果使用 -m 选项，JPS也可以显示传递给启动Java进程的主类的参数。这对于诊断和分析特定Java进程的配置和行为非常有用。 请注意，JPS只能检测与当前用户相关的Java进程。如果您想查看其他用户的Java进程，您可能需要使用root权限或使用适当的权限来运行JPS命令。 使用示例： 1jps 1jps -q 1jps -l 1jps -m 1jps -v jstack: 堆栈跟踪工具jstack 用于生成Java进程的线程转储（Thread Dump），以便分析和诊断Java应用程序的线程状态和问题。线程转储是指记录了Java进程中各个线程的堆栈信息，可以用来分析线程的运行状态、死锁、死循环等问题。 jstack 的一般语法如下： 1jstack [-l][-e] &lt;pid&gt; 常见的选项包括： -l: 以长格式输出线程转储信息。此参数可以显示关于每个线程的附加信息，如锁信息、监视器信息等 -e: 生成线程转储时输出扩展信息。它会显示更详细的线程堆栈信息，包括与线程关联的本地方法（Native Method）的符号信息 使用 jstack 命令可以获得以下信息： 线程堆栈信息：jstack 会打印出Java进程中每个线程的堆栈跟踪信息（包括正在运行的线程和等待中的线程），其中包含了线程调用栈的方法、行号和类信息。 死锁信息：通过查看线程转储，可以检测并诊断可能存在的死锁情况。死锁是指多个线程互相持有对方需要的资源而导致的相互等待的情况。 监控线程状态：线程转储还可以帮助监控线程状态，例如查找长时间运行的线程、查找线程的等待和阻塞情况等。 jstack 命令可以用于在线上或开发环境中定位和分析Java程序中的线程问题，如死锁、CPU高占用等。通常结合其他工具，如jps、jconsole、VisualVM等一起使用，以获取更全面的线程和性能信息，从而进行诊断和分析。 使用示例： 12# 使用刚才 springboot-demo-0.0.1-SNAPSHOT.jar 的进程来分析堆栈jps | grep demo | awk &#x27;&#123;print $1&#125;&#x27; | xargs -n 1 jstack -l &gt; jstack.log 我们从 jstack.log 中截取一段内容，来看下这段内容表示什么意思 12345678&quot;Reference Handler&quot; #2 daemon prio=10 os_prio=31 cpu=1.92ms elapsed=1359.35s tid=0x00007ff67900b800 nid=0x4403 waiting on condition [0x000070000e0a5000] java.lang.Thread.State: RUNNABLE at java.lang.ref.Reference.waitForReferencePendingList(java.base@11.0.12/Native Method) at java.lang.ref.Reference.processPendingReferences(java.base@11.0.12/Reference.java:241) at java.lang.ref.Reference$ReferenceHandler.run(java.base@11.0.12/Reference.java:213) Locked ownable synchronizers: - None “Reference Handler” #2 daemon prio&#x3D;10 os_prio&#x3D;31 cpu&#x3D;1.92ms elapsed&#x3D;1359.35s tid&#x3D;0x00007ff67900b800 nid&#x3D;0x4403 waiting on condition [0x000070000e0a5000]： “Reference Handler” 是线程的名称。 #2 表示该线程的序号。 daemon 表示该线程是一个守护线程。 prio&#x3D;10 表示该线程的调度优先级。 os_prio&#x3D;31 是操作系统对该线程的优先级。 cpu&#x3D;1.92ms 表示该线程占用 CPU 的时间。 elapsed&#x3D;1359.35s 表示该线程的运行时间。 tid&#x3D;0x00007ff67900b800 是线程的十六进制表示的线程 ID。 nid&#x3D;0x4403 是线程的十六进制表示的线程 ID，nid 也就是 Native ID。 waiting on condition 表示该线程当前正在等待某个条件。 [0x000070000e0a5000] 是线程的十六进制表示的栈地址。 java.lang.Thread.State: RUNNABLE： java.lang.Thread.State 表示线程的状态。 RUNNABLE 表示线程正在运行。 jstack 命令获取到的线程状态主要有以下几种： NEW：线程已创建但尚未启动。 RUNNABLE：线程正在执行或准备执行，可以在操作系统的可执行队列中运行。 BLOCKED：线程正在等待获得一个监视器锁（synchronized关键字）以进入同步代码块。 WAITING：线程正在无限期地等待另一个线程采取某些操作，直到被中断或唤醒。 TIMED_WAITING：线程正在等待另一个线程采取某些操作，但等待的时间有限，可以是超时等待或等待指定的条件。 TERMINATED：线程已完成执行，结束了它的生命周期。 at java.lang.ref.Reference.waitForReferencePendingList(&#x6a;&#x61;&#118;&#x61;&#46;&#98;&#97;&#115;&#x65;&#x40;&#x31;&#x31;&#46;&#48;&#x2e;&#x31;&#x32;&#x2F;Native Method)： 这是线程调用栈的一部分，显示了线程正在执行的方法。 at 后面是方法的完整名称。 Locked ownable synchronizers:： 这是线程拥有的独占锁的列表。 -None： 表示线程当前未拥有任何独占锁。 除了直接查看 jstack 生成的原始文件外，也可以借助其他工具来辅助我们分析，以下是几种常用的分析工具： 在线分析 离线分析 TMDA ———————— 昏割线，太困了，先睡了 ————————","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://linvaux.github.io/tags/Java/"}]},{"title":"Jacocoagent 改造-服务端覆盖率数据上报","slug":"Jacocoagent-改造-服务端覆盖率数据上报","date":"2023-10-26T15:14:25.000Z","updated":"2024-09-21T00:59:08.927Z","comments":true,"path":"posts/1cd2eecd/","permalink":"https://linvaux.github.io/posts/1cd2eecd/","excerpt":"","text":"背景代码覆盖率服务已经上线一段时间了，用户也反馈了不少问题，大家反馈比较集中的问题就是：测试忘记在服务器重启前生成覆盖率报告了，导致某段时间内覆盖率数据丢失。解决这个问题的思路比较简单，就是改造 javaagent，在 jvm 停止时，上报覆盖率数据到我们的代码覆盖率服务，等待生成报告时，将上报的数据和实时的覆盖率数据做合并即可。 实现方案具体实现方案涉及到两部分： jacoco 源码改造 代码覆盖率服务(以下简称 cov 服务)改造 jacoco改造 jacoco 改造主要涉及到以下几个类： org.jacoco.agent.rt.internal.Agent org.jacoco.core.runtime.AgentOptions 在 jacocoagent 的 org.jacoco.agent.rt.internal.Agent 类中，官方已经添加了一个 shutdownHook，只需要在此方法中实现我们的上报逻辑即可。为了方便测试，我们还需要对org.jacoco.core.runtime.AgentOptions 做改造，增加两个参数 debug 和 host。 debug：是否启用 debug 模式，如果是 debug 模式，则不会上报覆盖率数据，否则根据 host 配置推送覆盖率数据到代码覆盖率服务器。此参数默认为 false，表示会推送数据，也可以将 debug&#x3D;true，表示无需推送数据到覆盖率服务。 host: 测试平台的域名，用来发送覆盖率数据，可以根据 host 的配置，将数据发送到不同的环境。 改造前，需要在 org.jacoco.agent.rt 的 pom.xml 中加入以下依赖： 12345678910&lt;dependency&gt; &lt;groupId&gt;com.konghq&lt;/groupId&gt; &lt;artifactId&gt;unirest-java-core&lt;/artifactId&gt; &lt;version&gt;4.2.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; AgentOptions 实现代码如下： 12345678910111213141516// 此处省略 getter 和 setter 方法 /** * 是否启用 debug 模式，如果是 debug 模式，则不会上报覆盖率数据，否则根据 host 配置推送覆盖率数据到 cov 服务器 */ public static final String DEBUG = &quot;debug&quot;; /** * 测试平台域名，用来发送覆盖率数据 */ public static final String HOST = &quot;host&quot;; // 添加完参数后，需要将这两个参数加到 VALID_OPTIONS 中，否则会提示 “未知参数” private static final Collection&lt;String&gt; VALID_OPTIONS = Arrays.asList( DESTFILE, APPEND, INCLUDES, EXCLUDES, EXCLCLASSLOADER, INCLBOOTSTRAPCLASSES, INCLNOLOCATIONCLASSES, SESSIONID, DUMPONEXIT, OUTPUT, ADDRESS, PORT, CLASSDUMPDIR, JMX, HOST, DEBUG); Agent 实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public static synchronized Agent getInstance(final AgentOptions options) throws Exception &#123; if (singleton == null) &#123; final Agent agent = new Agent(options, IExceptionLogger.SYSTEM_ERR); agent.startup(); Runtime.getRuntime().addShutdownHook( new Thread(&quot;Jacocoagent Shutdown hook thread.&quot;) &#123; @Override public void run() &#123; AgentLogger.info(&quot;Jacocoagent Shutdown hook running.&quot;); // 非 debug 模式，直接上报数据到 cov 服务 if (!options.getDebug()) &#123; AgentLogger.info(&quot;Not in debug mode, push RuntimeData to OTS server.&quot;); // 直接在本地生成 exec 文件 File execFile = new File(&quot;output.exec&quot;); try &#123; FileOutputStream fos = new FileOutputStream(execFile); ExecutionDataWriter writer = new ExecutionDataWriter(fos); RuntimeData runtimeData = singleton.getData(); runtimeData.collect(writer, writer, false); fos.flush(); AgentLogger.info(&quot;Generate exec file success, exec file path is : &quot; + execFile.getAbsolutePath()); &#125; catch (Exception e) &#123; AgentLogger.severe(&quot;Failed to generate exec file: &quot; + e.getMessage()); &#125; try &#123; AgentLogger.info(&quot;OTS server host is: &quot; + options.getHost()); // 调用 cov 服务接口，上传数据 String reportApiPath = &quot;/coverage/rpc/jacocoagent/report&quot;; HttpResponse&lt;String&gt; response = Unirest.post(options.getHost() + reportApiPath) .field(&quot;ip&quot;, InetAddress.getLocalHost().getHostAddress()) .field(&quot;file&quot;, execFile) .asString(); if (response.getStatus() == 200) &#123; AgentLogger.info(&quot;Push data to OTS server success, request url is : &quot; + options.getHost() + reportApiPath + &quot;, request body is :&quot; + &quot; &#123;ip:&quot; + InetAddress.getLocalHost().getHostAddress() + &quot;, file:&quot; + execFile.getAbsolutePath() + &quot;&#125;&quot;); &#125; else &#123; AgentLogger.severe(&quot;Failed to push data to OTS server, request url is : &quot; + options.getHost() + reportApiPath + &quot;, request body is :&quot; + &quot; &#123;ip:&quot; + InetAddress.getLocalHost().getHostAddress() + &quot;, file:&quot; + execFile.getAbsolutePath() + &quot;&#125;&quot; + &quot;, response status is &quot; + response.getStatus() + &quot;, response body is : &quot; + response.getBody()); &#125; &#125; catch (Exception e) &#123; AgentLogger.severe(&quot;Failed to push data to OTS server, on exception: &quot; + e.getMessage()); &#125; finally &#123; // 删除 exec 文件 if (execFile.exists()) &#123; execFile.delete(); &#125; &#125; &#125; else &#123; AgentLogger.info(&quot;In debug mode, skip pushing data to OTS server.&quot;); &#125; agent.shutdown(); &#125; &#125;); singleton = agent; &#125; return singleton; &#125; 以下是日志工具类： 123456789101112131415161718192021222324252627282930313233343536373839package org.jacoco.agent.rt.internal;import java.io.File;import java.util.logging.FileHandler;import java.util.logging.Logger;/** * @author: wick * @date: 2024/1/25 17:46 * @description: agent日志工具类 */public class AgentLogger &#123; private static final Logger logger; private static final String defaultLogFileName = &quot;javaagent.log&quot;; private static final File LOG_LOCK_FILE = new File(&quot;javaagent.log.lck&quot;); // 静态初始化块配置 Logger 和 FileHandler static &#123; // 移除日志锁文件 if (LOG_LOCK_FILE.exists()) &#123; LOG_LOCK_FILE.delete(); &#125; logger = Logger.getLogger(&quot;AgentLogger&quot;); try &#123; FileHandler fileHandler = new FileHandler(defaultLogFileName, true); fileHandler.setFormatter(new SimpleFormatter()); logger.addHandler(fileHandler); logger.setUseParentHandlers(false); &#125; catch (Exception e)&#123; logger.warning(&quot;An error occurred initializing th AgentLogger: &quot; + e.getMessage()); &#125; &#125; public static void info(String msg)&#123; logger.info(msg); &#125; // 其他日志级别如法添加即可&#125; cov服务改造cov 服务改造很简单，添加一个 post 接口用来接受上传的文件即可，接口定义如下: 1234567891011@RestController@RequestMapping(&quot;/rpc/jacocoagent&quot;)public class JacocoagentReportController&#123; @Autowired private AgentService agentServie; @PostMapping(&quot;/report&quot;) public void report(@RequestParam(&quot;ip&quot;) String ip, @RequestParam(&quot;file&quot;) MultipartFile file)&#123; agentService.report(ip, file); &#125;&#125; 至此，jacocoagent 就实现了在 jvm 停止时，自动上报数据的功能。编译出来的 jacocoagent.jar 位于 org.jacoco.agent&#x2F;target&#x2F;classes 目录下。","categories":[],"tags":[{"name":"代码覆盖率","slug":"代码覆盖率","permalink":"https://linvaux.github.io/tags/%E4%BB%A3%E7%A0%81%E8%A6%86%E7%9B%96%E7%8E%87/"}]},{"title":"基于Jmeter和Selenium的WebUI自动化测试服务实现思路","slug":"基于Jmeter和Selenium的WebUI自动化测试服务实现思路","date":"2023-10-01T15:12:26.000Z","updated":"2024-09-21T00:59:08.943Z","comments":true,"path":"posts/4599864a/","permalink":"https://linvaux.github.io/posts/4599864a/","excerpt":"","text":"背景快到年底了，没啥东西要做了，搞一把 WebUI 自动化测试作为 2023 年收官之战，以下仅介绍技术实现思路，也欢迎大家有更好的想法在评论区交流。 需求实现一个面向普通用户的 WebUI 自动化测试服务，实现效果可以参考MeterSphere的 UI 自动化测试功能，当然这玩意儿是要收费才能用，可以申请个账号去体验下。注意：不是在给 MeterSPhere 打广告，只是懒得写需求而已。 技术选型虽然现在也有一些开源的 WebUI 自动化测试平台，但是调研了之后发现并不好用，比如 LuckyFrame，代码都是写死的，没啥扩展性，不是说这个项目不好，而是不满足我们的需求。所以最后选择了半天，使用如下技术栈来实现：Jmeter, Jmeter-plugins-webdriver, Springboot 以 Jmeter为底层用例的执行引擎，配合 Jmeter 丰富的组件，可以实现复杂的用例步骤。 Jmeter-plugins-webdriver是一个开源的 Jmeter 插件，底层基于 Selenium 开发，支持 Jmeter 实现 UI 自动化测试。 简单易上手的 web 框架自然是 Springboot 了。 实现流程 以上是大概的实现流程，整体思路为： 前端将用户操作封装为后端接口能处理的 json。 解析 json，将用户操作识别出来，然后生成代码，原理类似于 Selenium-IDE 中代码生成的逻辑。 生成一个空的 HashTree，默认填充 TestPlan 和 ThreadGroup 组件，并设置好属性。 按照用户的每一步的操作，分别生成一个 WebDriverSampler 组件，这个组件就是Jmeter-plugins-webdriver提供的采样器组件。 将第2步生成好的代码，填充到 WebDriverSampler 组件的 script 属性中。 拼装完整的 HashTree，并添加一个自己开发的后台监听器组件(继承AbstractBackendListenerClient即可，不知道的可以自己百度)。 将最后生成的 HashTree，交给 Jmeter 执行，注意，为了保证不同测试用例能够独立执行，每次执行新用例，必须要重新 new 一个 StandardJmeterEngine。 遇到的坑 Jmeter-plugins-webdriver 插件有个 bug，就是在执行WebDriverSampler.sample方法时，如果用例中有主动关闭浏览器的步骤，就会导致采样器报错，原因是：在脚本执行结束后，需要对采样器结果进行封装，会将页面源码封装为 SampleResult 对象的 ResposeData，将当前页面的 URL 设置为 SampleResult 对象的 URL，但是因为浏览器已经被主动关闭了，这个时候再也无法获取到页面源码和 url，就会导致采样器结果标记为异常。 WebDriverSampler的 sample方法中，并未设置采样器开始和结束时间，导致自己开发的后台监听器中，无法取到用例的执行时长。 我用的 Jmeter 版本是 5.4.1，其中 beanshell 版本是 Jmeter 自带的 2.0b6 版本，在这个版本中，使用 Java 编写代码时，会将 null 转为 void，详情可见这几个bug：https://github.com/apache/jmeter/issues/3411https://github.com/apache/jmeter/issues/6110解决方案就是把 beanshell 升级到 2.1.1 在服务器上部署时，需要安装浏览器运行环境，我这边用的 chrome，但是在测试时发现打开的页面要么中文是方框，要么页面默认是英语。记得安装中文语言包，并设置服务器默认语言为中文，不知道怎么设置就去问 gpt 吧，懒得写了。 服务器上运行 chrome 可能会出现 chrome 启动失败，记得增加如下配置到 ChromeOptions 中： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * @author: wick * @date: 2023/12/24 20:09 * @description: chrome options */public class ChromeOptionConstant &#123; /** * 允许跨域资源共享（CORS）请求。*表示接受所有来源的请求。 */ public static final String REMOTE_ALLOW_ORIGINS = &quot;--remote-allow-origins=*&quot;; /** * 无痕模式 */ public static final String INCOGNITO = &quot;--incognito&quot;; /** * 禁用沙箱 */ public static final String NO_SANDBOX = &quot;--no-sandbox&quot;; /** * 禁用 GPU，服务器上没有 GPU */ public static final String DISABLE_GPU = &quot;--disable-gpu&quot;; /** * 禁用共享内存，解央 DevToolsActivePort file doesn&#x27;t exist 异常 */ public static final String DISABLE_DEV_SHM_USAGE = &quot;--disable-dev-shm-usage&quot;; /** * 浏览器语言-中文 */ public static final String LANG_ZH_CN = &quot;--accept-lang=zh-CN&quot;; /** * 所有配置 */ public static final String OPTIONS = String.join(&quot; &quot;, REMOTE_ALLOW_ORIGINS, INCOGNITO, NO_SANDBOX, DISABLE_GPU, DISABLE_DEV_SHM_USAGE, LANG_ZH_CN);&#125; 无法并行执行用例，这个坑爹的问题困扰了我很久，最后发现是我在 ChromeOptions 中加了一个配置 “–remote-debugging-port&#x3D;9222”，这个配置会让 WebDriver 在指定端口启动，多个用例执行时会创建多个 session，但是 9222 端口被占用了，导致其他 session 创建失败，或者出现session 串掉的情况，千万别加这个配置，尤其是你需要并行执行用例的时候。 总结这个 WebUI 自动化技术实现上没啥难度，难的地方在于如何做技术选型，因为绝大多数人做 UI 自动化都是想着用框架写代码实现，但是很少有人会去挑战通过代码生成的方式来做，只要把实现思路理清楚，其实写代码也就那么回事了。对了，我fork 了这个Jmeter-plugins-webdriver插件到 gitee 了，把上面两个问题处理了一下，有兴趣的可以直接用我改过的代码：https://gitee.com/linvaux/jmeter-plugins-webdriver","categories":[],"tags":[{"name":"自动化测试","slug":"自动化测试","permalink":"https://linvaux.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"}]},{"title":"Java 集成Maven Embedder 编译 Maven 项目","slug":"Java-集成Maven-Embedder-编译-Maven-项目","date":"2023-09-07T15:01:56.000Z","updated":"2024-09-21T00:59:08.928Z","comments":true,"path":"posts/5b7c369d/","permalink":"https://linvaux.github.io/posts/5b7c369d/","excerpt":"","text":"背景最近在开发代码覆盖率的平台，涉及到对 java 项目编译后使用 jacococli 来生成报告，需要指定 java 项目 class 文件路径和源码路径。因此，需要对用户配置的 java 项目在服务器上进行编译，Java 项目构建工具有很多种，比如 Ant，Maven，Gradle 等，本文只针对 Maven 构建的项目如何编译进行讲解。以下用于演示编译的项目是 apolloconfig&#x2F;apollo 编译方案Maven 项目编译其实很简单，常用的命令就是 1mvn clean package 但是我在上面说了，我是要在部署了代码覆盖率服务(以下简称 cov 服务，使用 springboot 开发)的服务器上进行编译，这个 cov 服务本身就是使用 Maven 构建，然后使用 Dockerfile 打包成镜像，在 k8s 上部署的，在这个镜像里面只有必要的 JDK 依赖 。因此，如果要在 cov 服务上进行 Maven 项目的构建，则需要先配置 Maven 环境，因为这个镜像是由运维统一提供，所以再往镜像里面打包 Maven 这个事情推动起来比较困难(不要问我哪里困难，问就是他们不愿意)，因此，需要使用其他方式来创建 Maven 项目的编译环境。 使用 Maven 工具编译使用 Maven 工具编译应该是绝大多数人的第一反应，直接在项目启动时从 Maven 官方下载一个apache-maven-3.8.8-bin.zip安装包，解压到指定目录，然后通过 Java Runtime 来执行命令即可。道理确实如此，所以可以使用如下脚本进行安装。 1wget https://dlcdn.apache.org/maven/maven-3/3.8.8/binaries/apache-maven-3.8.8-bin.zip &amp;&amp; unzip apache-maven-3.8.8-bin.zip -d /opt 项目编译可以使用如下 Java 代码： 12Runtime runtime = Runtime.getRuntime();runtime.exec(&quot;cd /Users/wick/Downloads/repo/apollo &amp;&amp; mvn -T 4C clean install -Dmaven.test.skip=true&quot;); 使用 Maven Embedder 编译除了上面的方式之外，还有一种方法，就是使用 Maven Embedder 来编译 Maven 项目，这样只需要在我们 cov 服务中集成相关的依赖，就可以直接使用 Java 代码来编译 Maven 项目，无需在服务器上安装 Maven 工具。具体做法如下 在 cov 服务中配置 Maven 依赖 1234567891011121314151617181920212223242526272829303132333435&lt;!-- 省略了其他依赖 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.networknt&lt;/groupId&gt; &lt;artifactId&gt;slf4j-logback&lt;/artifactId&gt; &lt;version&gt;2.1.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-embedder&lt;/artifactId&gt; &lt;version&gt;3.6.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-compat&lt;/artifactId&gt; &lt;version&gt;3.6.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.resolver&lt;/groupId&gt; &lt;artifactId&gt;maven-resolver-connector-basic&lt;/artifactId&gt; &lt;version&gt;1.9.15&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.resolver&lt;/groupId&gt; &lt;artifactId&gt;maven-resolver-transport-http&lt;/artifactId&gt; &lt;version&gt;1.9.15&lt;/version&gt; &lt;/dependency&gt;&lt;!-- 拉取代码 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jgit&lt;/groupId&gt; &lt;artifactId&gt;org.eclipse.jgit&lt;/artifactId&gt; &lt;version&gt;6.6.0.202305301015-r&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 代码实现 12345678910111213141516171819202122232425import org.apache.maven.cli.MavenCli;/** * @author: wick * @date: 2023/8/19 21:39 * @description: Maven编译服务 */public class MavenCompilerService &#123; public void compiler(String codePath, String... commands) &#123; MavenCli cli = new MavenCli(); String mvnHome = MavenCli.USER_MAVEN_CONFIGURATION_HOME.getAbsolutePath(); System.getProperties().setProperty(&quot;maven.multiModuleProjectDirectory&quot;, mvnHome); int statusCode = cli.doMain(commands, codePath, System.out, System.err); if (statusCode != 0) &#123; throw new RuntimeException(&quot;编译失败&quot;); &#125; &#125; public static void main(String[] args) &#123; MavenCompilerService mavenCompilerService = new MavenCompilerService(); String[] commands = &#123;&quot;-T 4C&quot;,&quot;clean&quot;, &quot;install&quot;, &quot;-Dmaven.test.skip=true&quot;&#125;; mavenCompilerService.compiler(&quot;/Users/wick/Downloads/repo/apollo&quot;, commands); &#125;&#125; 在上面的 Maven 命令中，使用了一个参数 -T 4C ，作用是：使用 4 核编译，加快编译速度。 执行 main 方法之后，看一下控制台输出： 可以发现这个跟我们正常执行编译命令的输出没有区别，再看一下是不是真的编译完了 编译前 编译后 可以看到，这个项目的 target 目录已经生成，说明项目编译完成。 总结上面两种编译方案各有优势，直接使用 Maven 工具正常情况下来说是非常方便的，但是缺点是在我现在的场景下不太适用。第二种使用 Maven Embedder 虽然解决了安装工具的问题，但是对于需要执行一些特殊命令，如 deploy 时，就需要开发者去了解这个依赖相关的配置，要知道怎么在 MavenCli 中配置 Maven 仓库推送依赖的账号和密码，以及怎么指定仓库等等问题。所幸，cov 服务只是涉及代码拉取和编译，并不涉及到上述复杂场景，cov 拉取的代码也是公司内部的项目，均是在 pom.xml 中配置好公司内部仓库地址的。等后续遇到其他问题时，再来继续补充此文章内容吧，碎觉！","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://linvaux.github.io/tags/Java/"}]},{"title":"基于 Jacoco 的 java 代码覆盖率收集服务设计","slug":"基于-Jacoco-的-java-代码覆盖率收集服务设计","date":"2023-08-26T15:04:46.000Z","updated":"2024-09-21T00:59:08.941Z","comments":true,"path":"posts/d7156345/","permalink":"https://linvaux.github.io/posts/d7156345/","excerpt":"","text":"背景下半年开始搞精准测试了，先搞一波代码覆盖率，因为公司绝大多数项目都是基于 Java 开发的，所以就先搞 Java 的了，主流的代码覆盖率工具是 Jacoco(其实我也只知道这一个)，所以就直接基于 springboot 搞一个吧。 代码覆盖率知识什么是代码覆盖率代码覆盖率(Code Coverage)是软件测试中一种衡量测试质量的指标，用于评估测试用例对源代码的覆盖程度。它衡量了在执行测试用例时源代码中有多少行、分支、类、方法等被执行到。无论是单元测试、API测试还是功能性测试，最终都是调用了产品的代码；如何评价这些测试的效率?这些测试是否真正全部或者大部分覆盖了产品的代码？这个时候，代码覆盖率就是一个比较有价值的参考指标了。不同的代码覆盖率工具衡量指标可能不同。对于java语言，主流的代码覆盖率工具为Jacoco。当然，Jacoco其实是支持收集运行在JVM上的应用程序的覆盖率的。 代码覆盖率的意义 测试视角：分析未覆盖部分的代码，从而反推在前期测试设计是否充分?没有覆盖到的代码是否是测试设计的盲点，为什么没有考虑到？是需求&#x2F;设计不够清晰，测试设计的理解有误？还是工程方法应用后造成的策略性放弃等等，方便之后进行测试用例设计补充。 开发视角：检测出程序中的废代码，可以逆向反推在代码设计中思维混乱点，提醒设计&#x2F;开发人员理清代码逻辑关系，提升代码质量。 其他视角：代码覆盖率高不能说明代码质量高，但是反过来看，代码覆盖率低，代码质量不会高到哪里去，可以作为测试&#x2F;开发自我审视的重要工具之一。以上是代码覆盖率正面的意义，但是要注意一点：从质量的角度来说，肯定是希望用例能够对代码全部进行覆盖的，但是从实际出发，进行全覆盖也是不现实的，并且把测试覆盖率作为质量目标没有任何意义，而我们应该把它作为一种发现未被测试覆盖的代码的手段。从现有的覆盖率检测工具来看，即使覆盖率到达了100%，也不能保证用户场景完全被覆盖到或者不会出现漏测，因为从原理上来讲，代码覆盖率只能表示开发写的代码都执行了，但是不表示代码没有逻辑问题，如漏写异常处理，没有完全覆盖用户场景等。 代码覆盖率生成原理Jacoco代码覆盖率生成主要由以下几个过程组成： 1.代码插桩插桩分为编译期插桩和运行期插桩，两者区别如下： 编译期插桩（Offline模式）：在java源文件编译时，直接将桩插入代码行，编译后的class中已经包含了插桩代码，比如使用jacoco-maven-plugin插件即可实现编译期插桩。在Offline模式下，覆盖率数据是通过在编译期对字节码进行插桩生成的文件进行收集和分析。在编译阶段，Jacoco通过在Java字节码中插入代码来记录覆盖率信息。然后，在运行测试或应用程序之后，Jacoco使用已生成的覆盖率数据文件进行分析，生成相应的报告。由于覆盖率数据是在编译期收集并存储在文件中，这种模式可以在任何时候进行分析并生成报告，无需实时地收集覆盖率数据。这对于持续集成和定期报告生成非常有用。 运行期插桩（On-the-fly模式）：在应用程序运行期间，通过java agent技术，动态的对class文件做插桩，此类技术使用ASM框架实现，动态的修改了字节码文件。在On-the-fly模式下，覆盖率数据是在运行时实时收集并分析的。在应用程序运行时，Jacoco通过Java Agent技术加载到JVM中，并使用字节码插桩机制动态修改正在执行的字节码，以记录覆盖率信息。在应用程序运行期间，Jacoco会实时收集覆盖率数据并保存在内存中。一旦测试执行完成，覆盖率数据可以立即进行分析和报告。这种模式对于需要实时监控和反馈的场景非常有用，例如在开发过程中查看代码覆盖率。 编译期插桩的优点是不需要在运行时进行字节码的修改，可以更方便地与构建工具（如Maven或Ant）集成，并且不会对运行时性能产生显著的影响。缺点是需要重新编译代码，并且生成的插桩后的字节码会增加项目的大小。 运行期插桩的优点是可以对已经编译的字节码进行插桩，无需重新编译代码。缺点是在每次运行应用程序时都需要加载Jacoco Agent，可能会对应用程序的运行时性能产生一定的影响。 2.覆盖率数据收集在On-the-fly模式下，覆盖率数据使用jacocoagent.jar来收集，此agent会伴随被测服务一起启动。 jacoco生成的覆盖率数据文件默认为exec格式，覆盖率数据输出方式有以下几种： file：JVM 终止时，执行数据将写入属性中指定的文件中destfile。 tcpserver：代理侦听由address和 port属性指定的 TCP 端口上的传入连接。执行数据写入此 TCP 连接。 tcpclient：启动时，代理连接到address和port 属性指定的 TCP 端口。执行数据写入此 TCP 连接。 none：不产生任何输出。 一般对于服务端覆盖率数据收集，我们使用tcpserver模式，即jacocoagent跟着被测服务启动时，同时启动一个tcp端口(默认是6300)，后续可以通过jacococli或者其他工具访问6300端口来下载覆盖率数据。 3.覆盖率报告生成覆盖率数据报告生成需要借助jacococli.jar，先通过cli的dump命令获取覆盖率数据文件(即exec文件)，然后通过cli的report命令来生成覆盖率数据报告。 全量覆盖率适用场景： 初次测试：当开始进行测试时，全量代码覆盖率非常有用。它可以确保测试用例覆盖了整个代码库，从而验证代码在各种场景下的正确性和稳定性。 重构和优化：在进行重构或性能优化时，全量代码覆盖率可以帮助发现可能引入的新问题，并确保代码的质量和性能未受到不良影响。 稳定版本验证：在发布稳定版本之前，全量代码覆盖率可用于验证所有已经修改或新增的功能的测试覆盖程度，以确保发布的版本是经过全面测试的。 其他需要全量回归的场景，如：机房迁移，新环境部署… 增量覆盖率jacoco本身是不支持增量代码覆盖率的，但是可以通过二开或者使用其他的开源工具实现增量覆盖率报告生成。适用场景： 快速迭代测试：在项目快速迭代的情况下，仅针对新增或修改的代码进行增量代码覆盖率分析能够快速确定这些变动的测试覆盖程度，以便加快迭代速度。 高频更新验证：对于经常更新的代码库，每次都进行全量代码覆盖率分析可能会产生高昂的计算和执行成本。使用增量代码覆盖率可以更快地了解测试覆盖的变化情况，以便快速验证新增功能的正确性和稳定性。 增量测试补充：当时间有限而需求变动时，增量代码覆盖率可用于快速确定需求变动对现有测试覆盖的影响，并有针对性地补充和调整测试用例，以覆盖新增或修改的代码。 建设思路 目标：为整个中心不同部门&#x2F;项目组提供统一的Java 代码覆盖率收集能力 前期准备： 收集试点项目的技术栈，包括：开发框架，部署架构。 了解不同项目组对代码覆盖率的使用场景，比如 TL 关心开发提交的代码是否夹带私货，是否存在 dead code。测试人员或者产品经理关心是否测试全面，想通过代码的变更点推导出业务上的影响面。开发人员关心自己本个迭代提交的代码是否都测试完全等。 技术选型： 后端开发技术栈：Springboot，JacocoCli，Jgit，MavenCli，GradleToolingApi，MySQL，MyBatis 前端开发技术栈：vue2 应用架构设计(业务视角)业务架构图不方便贴，就说下基本流程： 配置凭据，即Git 账号和密码，此处使用类似 Jenkins 凭据的方式来管理。 配置服务信息，如服务名称，git 仓库地址，环境类型，dump 端口(jacocoagent启动端口)，ip 列表(同一个服务在不同环境有不同 ip，而且可能是多实例部署)，选择凭据。 配置覆盖率采集任务，选择环境自动带出此环境下面的服务列表，填写任务名称，迭代信息，在选择服务的时候要选择分支，如果是增量覆盖率，则需要选择采集分支和基准分支，如果是全量覆盖率，则选择采集分支即可。 执行采集任务，生成执行记录和覆盖率报告。 应用架构设计(技术视角)代码覆盖率只是整个测试平台的一个服务，测试平台使用 SBA 架构(服务导向的架构)，整个平台架构图如下所示： 代码覆盖率量子中只包含一个代码覆盖率容器，配合插件层的 jacocoagent 插件来协同工作。 安全方案代码覆盖率收集服务，主要业务是：根据用户配置的代码库地址和GIT账密来收集 Java 应用服务在某个时间段内的代码覆盖情况。其中会涉及到用户在平台上填写以下数据： 代码库地址(以下简称 代码库) GIT账号和密码(以下简称 凭据) 同时生成的覆盖率报告会包含部分&#x2F;所有的代码信息，因此需要对覆盖率报告也做数据权限的管控。因为测试平台使用多租户模式，所以不同的租户下面数据是完全隔离的，不存在跨租户访问数据的情况，只需要解决水平越权和垂直越权的安全问题即可。 因为安全方案涉及到公司内部数据，所以只给出以下思路： 菜单权限&#x2F;api权限：可以基于 Spring Security实现，或者其他安全框架实现 数据权限：对接口中的入参 by 租户进行校验，不允许访问未授权的测试库数据 数据安全：对 GIT 密码进行加密保存，可以选择 DES 或者 RSA 非对称加密 业务流程 代码覆盖率收集过程Step-1：代码插桩代码覆盖率收集过程基于 jacoco 的插桩来实现，jacoco 支持 2 中插桩方式： On-the-fly 模式（即时模式）：插桩时机：在应用程序运行时，通过 Java 代理（Java Agent）将 JaCoCo 注入到 JVM 中。数据收集方式：实时地收集代码覆盖率数据，即时生成运行时的覆盖率报告。 优点： 可以实时地监测应用程序的执行和覆盖率情况。 不需要对代码进行重新编译，使得在现有项目中使用更为方便。 缺点： 在运行时对字节码进行修改，可能会对应用程序的性能产生一定影响。 数据收集和报告生成过程会占用一些 CPU 和内存资源。 Offline 模式（离线模式）：插桩时机：在构建过程中对项目的字节码进行修改，通过构建工具（如 Maven 或 Gradle）进行插桩。数据收集方式：在应用程序运行时，JaCoCo 会收集覆盖率数据并将其保存到执行文件中（通常是一个二进制格式的 .exec 文件）。 优点： 不会对应用程序的运行性能造成直接影响。 可以在构建过程中自动插桩，方便集成到自动化构建和持续集成流程中。 缺点： 需要对项目进行重新编译，可能会增加构建过程的时间和开销。 需要对执行文件进行处理，生成可读性更好的覆盖率报告。 Step-2：生成 exec 文件exec 文件是 jacoco 默认的覆盖率数据文件类型，使用 on-the-fly 模式时，可以通过 Socket连接的方式，从远程服务器(即部署了 jacocoagent 的服务器) 上下载 exec 文件。JaCoCo 生成的 exec 文件是二进制文件，其中包含了代码覆盖率数据。它的结构如下： Header（文件头部）：包含了 exec 文件的元数据信息，如版本号和会话标识符。Sessions（会话信息）：存储了测试会话的信息，每个会话都有一个唯一的会话标识符。Probes（探针信息）：存储了所有被覆盖的代码块的信息。每个代码块都有一个唯一的标识符，并且将内联代码的情况进行了处理。Execution Data（执行数据）：实际的代码覆盖率数据。它记录了每个代码块是否被执行过。具体来说，Header 部分包括以下信息： Magic Number：一个特殊的标识符，用于识别文件类型。Version：exec 文件的版本号。Session Count：会话数量。Session Infos：会话信息的起始位置。Probe Count：探针数量。Probe Infos：探针信息的起始位置。Sessions 部分包括了每个会话的信息，例如会话标识符和会话名称。 Probes 部分包括了每个被覆盖的代码块的信息，例如代码块的标识符和分支相关的信息。 Execution Data 部分包括了实际的代码覆盖率数据，记录了每个代码块是否被执行过。 Step-3：代码差异比对(增量覆盖率才有此步骤)code-diff 阶段用于比对代码差异，进而分析出代码变更点。代码变更包括以下几种情况： 新增，修改，删除不会被统计在内，因为文件已经被删除，不会产生覆盖率数据。如果是全量覆盖率报告生成，则会跳过此阶段。code-diff 功能使用 jgit 库和 javaparser 库的 API 实现。code-diff 流程如下： 下载采集分支代码，即新分支，如 feature，develop 等。下载基准分支代码，即需要与之比较的分支，一般是 master 或者 release 等稳定分支。使用 jgit 获取变更过得文件，即 java 源文件。使用 javaparser 获取变更的类和方法，并记录方法信息(方法名，包名，方法签名等)。生成 code-diff文件，用于后面生成增量报告。 Step-4：代码编译代码编译过程用于将 java 源代码编译成 class 文件，用于生成覆盖率报告，在生成 JaCoCo 报告时，需要使用 class 文件和源码文件主要是为了对覆盖率数据进行解析和展示。 Class 文件：JaCoCo 通过分析 class 文件来获取代码结构和字节码信息。它包含了类、方法和字段的定义、修饰符以及字节码指令等信息。通过分析 class 文件，JaCoCo 可以确定每个代码块（如行、分支等）的起始和结束位置。 源码文件：源码文件是编写程序的原始文件，其中包含了开发人员编写的代码。在生成覆盖率报告时，JaCoCo 将覆盖率数据与源码文件进行关联，并进行代码染色，以显示被执行和未执行的代码行。这样，开发人员可以清楚地看到哪些行被覆盖，哪些行未被覆盖。本服务支持 Gradle 项目和 maven 项目编译，编译工具版本如下： JDK：jdk11，jdk8 Gradle：gradle 7, gradle 6, gradle 5 Maven：maven 3.6.1 Step-5：报告生成支持增量报告和全量报告生成。增量报告用于比较不同版本之间代码差异和覆盖率情况，全量报告直接展示新版本代码覆盖率情况。两种报告使用场景如下： 增量报告： 新迭代差异代码覆盖情况，一般用于开发自测，检查变更的代码是否被执行 全量报告： SIT 测试，通过代码覆盖情况间接表示功能覆盖情况 全量回归测试，比如机房迁移，项目重构等，会统计此分支下所有代码的执行情况 技术方案代码同步直接使用 Jgit 即可，Maven 坐标如下: 12345&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jgit&lt;/groupId&gt; &lt;artifactId&gt;org.eclipse.jgit&lt;/artifactId&gt; &lt;version&gt;6.5.0.202303070854-r&lt;/version&gt;&lt;/dependency&gt; 示例代码如下: 1234567891011121314151617181920212223public String clone(String repoUrl, String branch, String localPath, String username, String password) &#123; log.info(&quot;开始克隆代码，代码库地址: &#123;&#125;&quot;, repoUrl); long startTime = System.currentTimeMillis(); CredentialsProvider credentialsProvider = new UsernamePasswordCredentialsProvider(username, EncryptUtil.decryptByDes(password, desKey)); String savePath = CoverageConstant.GIT_CLONE_TEMP_PATH + localPath; log.info(&quot;git clone repoUrl: &#123;&#125;, branch: &#123;&#125;, savePath: &#123;&#125;&quot;, repoUrl, branch, savePath); try (Git ignored = Git.cloneRepository() .setURI(repoUrl) .setBranch(branch) .setCredentialsProvider(credentialsProvider) .setDirectory(new File(savePath)) .setDepth(1) .setCloneAllBranches(false) .call()) &#123; log.info(&quot;git clone success&quot;); &#125; catch (Exception e) &#123; log.error(&quot;Git clone 异常,异常详情: &#123;&#125;&quot;, ExceptionUtil.getErrorMessage(e)); throw new ServiceException(&quot;Git clone 异常&quot;); &#125; log.info(&quot;代码克隆完成，耗时: &#123;&#125; s, 代码库地址: &#123;&#125;&quot;, (System.currentTimeMillis() - startTime) / 1000, repoUrl); return savePath; &#125; 代码编译Maven 项目编译Maven 项目使用 Maven embedder 进行编译Maven 坐标如下 1234567891011121314151617181920212223242526&lt;dependency&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-embedder&lt;/artifactId&gt; &lt;version&gt;3.6.3&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.annotation&lt;/groupId&gt; &lt;artifactId&gt;jsr250-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-compat&lt;/artifactId&gt; &lt;version&gt;3.6.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.maven.resolver&lt;/groupId&gt; &lt;artifactId&gt;maven-resolver-connector-basic&lt;/artifactId&gt; &lt;version&gt;1.6.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.maven.resolver&lt;/groupId&gt; &lt;artifactId&gt;maven-resolver-transport-http&lt;/artifactId&gt; &lt;version&gt;1.6.3&lt;/version&gt;&lt;/dependency&gt; 示例代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Component@Slf4jpublic class MavenBuildManagerImpl implements MavenBuildManager &#123; @Override public void compiler(String codePath, List&lt;String&gt; commands) &#123; log.info(&quot;开始编译Maven项目，代码路径: &#123;&#125;, 编译参数: &#123;&#125;&quot;, codePath, commands); long startTime = System.currentTimeMillis(); File codeFile = new File(codePath); if (!codeFile.exists()) &#123; throw new ServiceException(&quot;代码路径不存在&quot;); &#125; MavenCli cli = new MavenCli(); System.getProperties().setProperty(MavenCli.MULTIMODULE_PROJECT_DIRECTORY, MavenCli.USER_MAVEN_CONFIGURATION_HOME.getAbsolutePath()); // 重定向标准错误输出流 ByteArrayOutputStream errorStream = new ByteArrayOutputStream(); PrintStream originalErrStream = System.err; System.setErr(new PrintStream(errorStream)); int statusCode = cli.doMain(commands.toArray(new String[0]), codePath, System.out, System.err); // 恢复标准错误输出流 System.setErr(originalErrStream); if (statusCode != 0) &#123; log.error(&quot;代码: &#123;&#125; 编译失败, 异常详情: &#123;&#125;&quot;, codePath, errorStream); throw new ServiceException(&quot;编译失败&quot;); &#125; log.info(&quot;结束编译Maven项目，编译耗时: &#123;&#125; s&quot;, (System.currentTimeMillis() - startTime) / 1000); &#125; /** * 多模块代码扫描 * @param codePath 代码路径 * @return 模块列表 */ @Override public List&lt;String&gt; modules(String codePath) &#123; List&lt;String&gt; modules; File pomFile = new File(codePath, &quot;pom.xml&quot;); try &#123; MavenXpp3Reader reader = new MavenXpp3Reader(); Model model = reader.read(new FileReader(pomFile)); modules = model.getModules(); &#125; catch (Exception e) &#123; log.error(&quot;代码: &#123;&#125; 模块扫描失败, 异常详情: &#123;&#125;&quot;, codePath, ExceptionUtil.getErrorMessage(e)); throw new ServiceException(&quot;模块扫描失败&quot;); &#125; return modules; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class MavenCommand &#123; /** * maven命令 */ public static final String MVN = &quot;mvn&quot;; /** * 清理构建产物 */ public static final String CLEAN = &quot;clean&quot;; /** * 编译 class 文件 */ public static final String COMPILE = &quot;compile&quot;; /** * 打包 */ public static final String PACKAGE = &quot;package&quot;; /** * 跳过测试 */ public static final String SKIP_TEST = &quot;-Dmaven.test.skip=true&quot;; /** * 批量模式 */ public static final String BATCH_MODE = &quot;--batch-mode&quot;; /** * 多核编译 */ public static final String PARALLEL = &quot;-T 1C&quot;; /** * 多线程编译 */ public static final String FORK = &quot;-Dmaven.compile.fork=true&quot;; /** * 通用编译命令 */ public static final List&lt;String&gt; COMMAND = new ArrayList&lt;&gt;()&#123;&#123; add(CLEAN); add(COMPILE); add(SKIP_TEST); add(BATCH_MODE); add(PARALLEL); &#125;&#125;;&#125; Gradle 项目编译Gradle 项目使用 gradle tooling api进行编译Maven 坐标如下: 12345&lt;dependency&gt; &lt;groupId&gt;org.netbeans.external&lt;/groupId&gt; &lt;artifactId&gt;gradle-tooling-api&lt;/artifactId&gt; &lt;version&gt;RELEASE170&lt;/version&gt;&lt;/dependency&gt; 示例代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Component@Slf4jpublic class GradleBuildManagerImpl implements GradleBuildManager &#123; @Override public void compiler(String gradlePath, String codePath, List&lt;String&gt; commands) &#123; log.info(&quot;开始编译Gradle项目，编译工具路径: &#123;&#125;，代码路径: &#123;&#125;, 编译参数: &#123;&#125;&quot;, gradlePath, codePath, commands); long startTime = System.currentTimeMillis(); // 重定向标准错误输出流 ByteArrayOutputStream errorStream = new ByteArrayOutputStream(); PrintStream originalErrStream = System.err; // 重定向标准输出流 ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); PrintStream originalOutStream = System.out; try (ProjectConnection connection = GradleConnector.newConnector() .forProjectDirectory(new File(codePath)) .useGradleUserHomeDir(CoverageConstant.DEFAULT_GRADLE_USER_HOME) .useInstallation(new File(gradlePath)) .connect()) &#123; BuildLauncher build = connection.newBuild(); System.setErr(new PrintStream(errorStream)); System.setOut(new PrintStream(outputStream)); build.forTasks(commands.toArray(new String[0])) .setStandardOutput(System.out) .setStandardError(System.err) // 跳过单测，多线程编译 .withArguments(GradleCommand.EXCLUDE, GradleCommand.TEST) // 不使用彩色日志，否则会导致日志中的颜色代码被打印出来，导致日志不易阅读 .setColorOutput(false) // 限制 gradle 内存，防止编译过程中内存溢出 .setJvmArguments(&quot;-Xmx512m&quot;); build.run(); log.info(&quot;编译日志:\\n &#123;&#125;&quot;, outputStream); System.setErr(originalErrStream); System.setOut(originalOutStream); &#125; catch (Exception e) &#123; log.error(&quot;代码: &#123;&#125; 编译失败, 异常详情: &#123;&#125;&quot;, codePath, ExceptionUtil.getErrorMessage(e)); log.error(&quot;编译异常日志:\\n &#123;&#125;&quot;, errorStream); throw new ServiceException(&quot;编译失败&quot;); &#125; log.info(&quot;结束编译Gradle项目，编译耗时: &#123;&#125; s&quot;, (System.currentTimeMillis() - startTime) / 1000); &#125; @Override public List&lt;String&gt; modules(String gradlePath, String codePath) &#123; log.info(&quot;开始扫描Gradle项目模块，编译工具路径: &#123;&#125;，代码路径: &#123;&#125;&quot;, gradlePath, codePath); try (ProjectConnection connection = GradleConnector.newConnector() .forProjectDirectory(new File(codePath)) .useInstallation(new File(gradlePath)) .connect()) &#123; GradleProject model = connection.getModel(GradleProject.class); return model.getChildren().stream().map(GradleProject::getName).collect(Collectors.toList()); &#125; catch (Exception e) &#123; log.error(&quot;代码: &#123;&#125; 模块扫描失败, 异常详情: &#123;&#125;&quot;, codePath, ExceptionUtil.getErrorMessage(e)); throw new ServiceException(&quot;模块扫描失败&quot;); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class GradleCommand &#123; /** * gradle命令 */ public static final String GRADLE = &quot;gradle&quot;; /** * 清理构建产物 */ public static final String CLEAN = &quot;clean&quot;; /** * 打包 */ public static final String BUILD = &quot;build&quot;; /** * 排除某个任务 */ public static final String EXCLUDE = &quot;-x&quot;; /** * 测试 */ public static final String TEST = &quot;test&quot;; /** * 多线程编译 */ public static final String PARALLEL = &quot;-Dorg.gradle.parallel=true&quot;; /** * 多进程编译 */ public static final String FORK = &quot;-Dorg.gradle.fork=true&quot;; /** * 编译class文件 */ public static final String CLASSES = &quot;classes&quot;; /** * 通用编译命令 */ public static final List&lt;String&gt; COMMAND = new ArrayList&lt;&gt;()&#123;&#123; add(CLEAN); add(CLASSES); &#125;&#125;;&#125; 差异代码比对直接参考这个就好：https://gitee.com/Dray/code-diff/blob/master/src/main/java/com/dr/code/diff/service/impl/CodeDiffServiceImpl.java原理就是直接通过jgit 分析出变更的文件，然后通过 javaparser 来分析代码 覆盖率报告生成生成报告参考这个：https://gitee.com/Dray/code-diff/blob/master/src/main/java/com/dr/code/diff/jacoco/report/ReportAction.java但是里面涉及到差异报告生成，就需要使用这个仓库提供的 jar 了 覆盖率报告解读全量覆盖率报告报告总览 Element：被覆盖和测量的代码元素，通常是源代码的各种层级，比如 模块，包，类，方法。其实在jacoco的报告中，也是按照上面的层级逐步深入展示覆盖率报告的。 Instructions：指令覆盖，Java 字节指令的覆盖率。执行的最小单位，和代码的格式无关。 Branches：分支覆盖，如if分支，switch分支等。 Cxty：圈复杂度，Jacoco 会为每一个非抽象方法计算圈复杂度，并为类，包以及组（groups）计算复杂度。圈复杂度简单地说就是为了覆盖所有路径，所需要执行单元测试数量，圈复杂度大说明程序代码可能质量低且难于测试和维护。 Lines：行覆盖，只要本行有一条指令被执行，则本行则被标记为被执行。 Methods：方法覆盖，任何非抽象的方法，只要有一条指令被执行，则该方法就会被计为被执行。 Classes：类覆盖，所有类，包括接口，只要其中有一个方法被执行，则标记为被执行。注意：构造函数和静态初始化块也算作方法。 覆盖率数据：注意，上图中 1432 of 28186 94% 表示的意思是 一共有28186条指令，其中有1432条指令没有执行，94%≈(28186-1432)&#x2F;28186 * 100% 背景色及标记由于单行通常编译为多个字节代码指令，源代码突出显示为包含源代码的每行显示三种不同的状态 背景色： 无覆盖：该行没有指令被执行（红色背景） 部分覆盖：仅执行了该行的部分指令（黄色背景） 全覆盖：该行所有指令均已执行（绿色背景） 菱形标记： 绿色菱形：这一行的所有分支都被执行 黄色菱形：这一行的分支中只有一部分被执行 红色菱形：在这一行中没有分支被执行 增量覆盖率报告增量覆盖率报告与全量覆盖率报告大体一致，只有部分标记存在差异。 蓝色加号：新增的代码 黄色铅笔：修改过的代码 代码覆盖率接入常见问题jacoco官方本身提供了FA&amp;Q，绝大多数覆盖率相关的问题都可以在这边找到，只有以下比较特殊的场景需要注意： 反射导致的服务启动失败或者接口调用失败jacoco不管是以何种方式运行，都会在class中插入static boolean[] $jacocoData 和 $jacocoInit() 来记录覆盖率数据。当我们使用反射来获取一个类的属性和方法时，很容易就获取到这两个特殊的Field，比如通过一个类来保存JDBC配置的时候，就会读到$jacocoData，导致jdbc连接失败。为了解决这个问题，需要在使用反射的地方通过如下方法处理： 123456789101112131415public static void main(String[] args) &#123; ChromeDriver chromeDriver = new ChromeDriver(); Field[] declaredFields = chromeDriver.getClass().getDeclaredFields(); for (Field declaredField : declaredFields) &#123; if (declaredField.isSynthetic()) &#123; System.out.println(&quot;当前属性: &quot;+ declaredField.getName() +&quot;为合成属性，跳过...&quot;); &#125; &#125; Method[] declaredMethods = chromeDriver.getClass().getDeclaredMethods(); for (Method declaredMethod : declaredMethods) &#123; if (declaredMethod.isSynthetic()) &#123; System.out.println(&quot;当前方法: &quot;+ declaredMethod.getName() +&quot;为合成方法，跳过...&quot;); &#125; &#125;&#125; 关于 isSynthetic() 的解释可以参考：Class.IsSynthetic 属性 (Java.Lang) 写在最后的话准备提桶了，没啥心情写了，就先写这么多吧，希望诸位都能找到合适的工作PS：代码编译比较耗费资源，记得改成 mq，触发任务采集的时候通过 mq 来做任务排队 参考文档 https://www.jacoco.org/jacoco/trunk/doc/ https://gitee.com/Dray/jacoco https://gitee.com/Dray/code-diff https://blog.csdn.net/Huang1178387848/article/details/114399056 https://maven.apache.org/ref/3-LATEST/maven-embedder/index.html https://blog.csdn.net/ByteDanceTech/article/details/123059368 https://www.jacoco.org/jacoco/trunk/doc/mission.html https://www.jacoco.org/jacoco/trunk/doc/counters.html https://www.jacoco.org/jacoco/trunk/doc/agent.html https://www.jacoco.org/jacoco/trunk/doc/cli.html https://www.jacoco.org/jacoco/trunk/doc/faq.html https://blog.csdn.net/tushuping/article/details/134347325 https://blog.csdn.net/tushuping/article/details/112613528 https://blog.csdn.net/tushuping/article/details/131640959","categories":[],"tags":[{"name":"代码覆盖率","slug":"代码覆盖率","permalink":"https://linvaux.github.io/tags/%E4%BB%A3%E7%A0%81%E8%A6%86%E7%9B%96%E7%8E%87/"}]},{"title":"Java中的异常处理","slug":"Java中的异常处理","date":"2023-08-22T14:37:04.000Z","updated":"2024-09-21T00:59:08.929Z","comments":true,"path":"posts/22260569/","permalink":"https://linvaux.github.io/posts/22260569/","excerpt":"","text":"1. Java 中的异常分类Java中的异常类均以Throwable为父类，而Throwable又派生出 Error 和 Exception 两类，区别如下 1.1 Error类及其子类代表了JVM自身的异常。这一类异常发生时，无法通过程序来修正。例如系统崩溃、内存溢出等。与异常不同，错误表示程序无法继续执行下去，一般不需要进行捕获或处理。错误通常是由底层系统或环境导致的，它们是不可控的，最可靠的方式就是尽快地停止JVM的运行。 1.2 Exception类及其子类Exception又分为运行时异常(RuntimeException)和非运行时异常， 这两种异常有很大的区别，也称之为非受检异常（Unchecked Exception）和受检异常（Checked Exception），其中Error类及其子类也是非受检异常。 受检异常：也称为“编译时异常”，编译器在编译期间检查的那些异常。由于编译器“检查”这些异常以确保它们得到处理，因此称为“检查异常”。如果抛出检查异常，那么编译器会报错，需要开发人员手动处理该异常，要么捕获，要么重新抛出。除了RuntimeException之外，所有直接继承 Exception 的异常都是检查异常。 非受检异常：也称为“运行时异常”，编译器不会检查运行时异常，在抛出运行时异常时编译器不会报错，当运行程序的时候才可能抛出该异常。Error及其子类和RuntimeException 及其子类都是非检查异常。 Java 中异常类的关系可以使用如下 UML 类图表示 受检异常和非受检异常是针对编译器而言的，是编译器来检查该异常是否强制开发人员处理该异常： 受检异常导致异常在方法调用链上显式传递，而且一旦底层接口的检查异常声明发生变化，会导致整个调用链代码更改。 使用非受检异常不会影响方法签名，而且调用方可以自由决定何时何地捕获和处理异常。 1.3 受检异常举例 编译器提示需要处理这个异常，这种异常处理有两种方式： 在方法签名上抛出此异常，由方法调用方处理 使用try-catch 捕获异常，内部处理 1.4 非受检异常异常举例所有继承 RuntimeException 的异常都是非检查异常，直接抛出非检查异常编译器不会提示错误 方法直接抛出 RuntimeException 时，编译器并不会要求捕获或者抛出此异常。 2. try-catchtry-catch 关键字在Java 中主要用于捕获异常，并进行处理。简单示例如下： 在 try{} 代码块中，是可能抛出异常的代码或者调用了签名上会抛出异常的方法。cath{} 代码块中则是捕获异常，并处理异常。注意：catch 可以捕获多种异常，并根据异常种类不同，分开处理，但是要注意异常捕获的顺序。 在上面的示例中，先捕获了 IOException，IDE 就会提示下面的 FileNotFoundException 无需再被捕获了，因为 IOException 是 FileNotFoundException 的父类，捕获到 IOException 之后，其所有子类的异常捕获代码都会失效。 下面演示如何同时捕获多个异常，并用同一个分支处理： 当我们需要对多个异常分组处理时，可以使用 catch(Exception1 | Exception2 e) 来捕获多个异常。 3. try-catch-finallytry-catch-finally 用于在处理异常时，不管是否发生异常，都要执行的操作。示例代码如下： try 代码块中发生了异常： 提问：为什么先打印了 finally 代码块中的内容，后打印了异常信息？ try 代码块未异常： finally{} 一般用于资源的关闭，或者数据的清理， 但是也可以在 finally 中执行 return 命令来修改方法返回。示例代码如下： 提问：大家觉得这个cal 方法返回值是多少？为什么？ 正常情况下，finally 代码块中的代码一定是会执行的，但是也有以下几种失效情况： 在执行 try 或 catch 块之前 JVM 被非法终止，比如程序正在运行，但是使用 pkill -9 java 命令强行停止 Java 进程。 在 try 或 catch 块中发生了 System.exit() 调用，导致 JVM 直接退出。 在 try 或 catch 块中发生了死循环，导致程序无法继续执行。 在 try 或 catch 块中发生了栈溢出异常（StackOverflowError）或虚拟机异常（如 OutOfMemoryError），导致 JVM 崩溃。 程序所在的线程被强制中断或程序进程被操作系统杀死。 在 try 或 catch 块中使用了 System.halt() 方法，显式终止 JVM。 调用了 native 方法，而该方法中不包含 finally 块。 4. try-with-resources 用法try-with-resources 是 Java 7 引入的一个语法结构，用于更加方便地处理需要关闭的资源。它可以自动关闭实现了 AutoCloseable 或 Closeable 接口的资源，无需手动编写 finally 块来关闭资源。try-with-resources 的语法形式是在 try 关键字之后使用圆括号括起来的资源声明列表。每个资源在括号中声明并初始化。当 try 块结束时，无论是否发生异常，这些资源都将自动关闭，而不需要显式调用 close() 方法。以下是一个读取文件并自动关闭流的示例： FileInputStream 之所以可以自动关闭，是因为其继承了 InputStream 类，而InputStream类实现了 Closeable 接口，FileInputStream重写了 close()方法，以下是具体实现： 那如何证明使用 try-with-resources 时，close 方法真的被调用了呢？我们可以使用如下命令编译 App.java 文件，并看下生成的字节码文件 12# -g 参数用于生成与调试相关的信息，包括调试符号和源代码行号。它允许在编译后的字节码中插入调试信息，以便在调试过程中可以精确地映射回源代码的行号和变量名javac -g App.java 生成的 class 文件如下： 从上面的 class 文件中我们可以清楚看到 jvm 帮我们生成了一个 catch 代码块，用来捕获外层 try 代码块可能抛出的异常，并且在 catch 代码块中显式调用了 fis 的 close() 方法进行资源关闭。这就是为什么说 无论是否发生异常，这些资源都将自动关闭。 5. 异常处理规范异常处理规范参考 《阿里巴巴代码开发规范》 中的约束。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://linvaux.github.io/tags/Java/"}]},{"title":"线上问题分析案例:一个小括号引发的惨案","slug":"线上问题分析案例-一个小括号引发的惨案","date":"2023-08-17T14:58:02.000Z","updated":"2024-09-21T00:59:08.946Z","comments":true,"path":"posts/a12172a0/","permalink":"https://linvaux.github.io/posts/a12172a0/","excerpt":"","text":"悲剧的开始2023.8.17 早上 7:30 刚睡醒，都没来得及洗漱，手机上就收到了公司运维平台发的告警有一台服务器 cpu 使用率超过 95%了，当时没在意，以为上面正在跑任务(这个服务器上面部署的是我们自己开发的自动化测试平台，用例执行引擎是 Jmeter，后端开发框架是 springboot)。等我收拾完准备出门上班的时候，发现手机上又双收到了 2 条告警，cpu 使用率没有下去，当时在想是不是自动化任务跑的时间比较长，再等等。。。然后就骑车出门了。 8:30 在地铁上打开手机看了下，发下又双叒收到了告警，我擦，怎么没完了，隐隐有种不好的预感。同时在 vx 群里，老板也在艾特我，问我为啥一直在告警，可是我也母鸡啊。。。 8:50到公司，打开 IM 工具一看，好家伙，又双叒叕多了好几条告警，上运维平台看了下服务器监控，瞬间血压就上来了。。。 问题出现我次奥啊，这台 8C16GB 服务器的 cpu 使用率从8.14 开始，蹭蹭蹭的往上涨啊，一点回落的迹象都没有。同时看了下最近一周的监控记录，发现 cpu 使用率在 8.10就开始增长了，8.11回落了，然后过了一个周末，从 8.14 开始就跟吃了炫迈一样，根本停不下来。结合这个服务的发版记录，猜测可能是 8.10 发布的那个版本有问题，导致8.11当天出现了 cpu 使用率上涨的问题。因为8.11那天发现 8.10 发布的版本有问题，8.11 晚上又发布了一个 hotfix 版本，而且那天正好是周五，所以周末两天都没人用自动化测试，cpu 使用率就非常低。8.14周一上班了，大家开始做自动化测试了，问题就开始出现了。再看下内存使用率，差点一口气没上来，16GB 的内存用了 14GB，这特喵的是内存泄露了吧，而且 cpu 使用率还高的吓人，但是当时看了下服务器上的日志，并没有几个任务再跑，说明有其他的线程可能在狂占 cpu。 初步定位就在我对着这个监控数据抓狂的时候，陆续又收到了其他测试同学的反馈：自动化用例执行了结果出不来，刷新页面偶尔出现了“上游服务器无响应” 等等问题。得！赶紧先上服务器捞一把数据，然后把服务器重启了先，不然等会儿就真的要宕机了。登录服务器之后，首先要看下 cpu 和内存使用率是不是真的高到离谱，用 top 命令一看确实不行了(运维平台的监控偶尔抽风不准)。 分析 GC 情况执行命令 1jstat -gcutil 339 1000 100 &gt; gc.log 好家伙，youngGC 了 20 多万次，fullGC 4万多次，基本每2s 进行一次 GC，这内存不爆才有鬼了。再看下 JVM 配置可以，很 6，jvm 直接给了 13GB，哪个天杀的教他们这么配置 heap 的！ 分析对象直方图执行命令 1jmap -histo 339 &gt; histo.txt 很秀，光 org.apache.jmeter.samplers.SampleResult 对象都有 1224w+ 了，占用了 3G 内存，熟悉 Jmeter 的同学都知道，这个对象是 Jmeter 用来存储采样器结果的(不知道的可以去百度一下)。TM 什么样的测试用例能跑出来这么多对象，而且还没释放，说明这种用例还在执行，那其实就从侧面印证了 cpu 使用率为啥居高不下。 光凭这两个数据，还是没法准确分析出问题出在哪里，所以最后只能祭出终极大招：分析内存快照 分析内存快照执行命令 1jmap -dump:format=b,file=heapdump.bin 339 &gt; heapdump.bin 光执行这个命令都用了 5 分钟，生成的原始文件 16GB，然后使用 zip 压缩以下再下载。 1zip heapdump.bin.zip heapdump.bin 不要幻想用 tar 去压缩，tar 压缩效率很低，而且压缩完成的文件跟原始文件差不多大。zip压缩完成后得到的 heapdump.bin.zip 有 1.7GB，下载都用了 20min(U1S1，从生产环境的服务器下载东西是真的慢……) 这个时候是不是该分析这个文件了？错！分析个毛线啊，赶紧重启服务器啊，不然等会彻底宕机了，我们就凉凉了。因为这个服务是双实例部署，所以使用串行重启，网关那边做了负载均衡，对于用户来说基本无法感知到服务被重启了(不排除运气不好的人，请求正在被重启的服务器上执行，则就会出现 504 的问题)。 服务器重启完成后，再看下 cpu 使用率，发现终于降下来了，内存不用看，13GB 的堆内存还是挺抗打的。但是，如果现在不解决，cpu 和内存飚上去是迟早的事情，可能都等不到我们下次发版本了，估计本周末就能 gg。 服务重启完了，赶紧分析下快照文件吧，我用的工具是 MAT，然后就发现了一个悲剧的事情，这个 bin 文件有 16GB，我电脑内存才 16GB，MAT 默认的内存是 2GB，打开这个文件转圈转了 10min 都没处理完。先把mat 内存改下吧。修改 mat 安装目录下的 &#x2F;Applications&#x2F;mat.app&#x2F;Contents&#x2F;Eclipse&#x2F;MemoryAnalyzer.ini 文件中的 -Xmx 配置为 8g然后重新打开这个bin 文件，这次转圈转了 5min 才好。 内存泄露分析先看下 mat 生成的 leak suspects 报告，看下是不是有疑似内存泄露的问题。emm……漏就漏了吧，不漏才见鬼了从上面的报告可以看到，有个疑似内存泄漏的对象：ApiBackendListenerClient这个类是我们服务自己写的类，继承了 Jmeter 的 AbstractBackendListenerClient，是一个监听器类，作用是收集 Jmeter 执行过程中的采样器结果。这个类有三个重写的方法 setupTest: 允许开发者在测试开始之前进行一些初始化操作，例如建立与后端系统的连接、准备发送数据等，此方法只会调用一次。 handleSampleResults: 每个线程组的每个请求都会生成一个样本结果，样本结果包含了该请求的响应时间、响应码、响应数据等信息。handleSampleResults方法会接收这些样本结果，并进行处理。可以在这个方法中编写代码来将样本结果存储、发送到数据库、生成报告等。通过重写handleSampleResults方法，可以自定义后端监听器在测试期间如何处理样本结果。这个方法会频繁调用，即 Jmeter 每发送一次请求，此方法都会被调用一次。 teardownTest: 测试结束后的操作，一般用于发送数据，清理数据等等，此方法只会调用一次。 既然都找到自己的类了，那就先看下为啥这个类会持有这么多 SampleResult 对象吧。接下来对代码进行分析。在这个类中，创建了一个 List&lt;SampleResult&gt; results 来存储测试过程中产生的采样器结果，测试完成后，会把这个 list 清空。既然现在出现了这么多对象，那就说明由以下两种情况导致： 还没有测试完成，testdownTest 方法没有调用 result.clear()没执行，原因可能是上面的方法执行异常 没测试完成这个原因有点扯淡，刚才看服务器日志发现都没几个任务在跑，不可能产生 1224w+ 个对象，所以有可能就是 teardownTest 里面的 handlerTeardownTest 方法异常了，导致下面没有清理对象，所以重点是先看下这个方法是不是哪里有问题。但是啊，事实证明我的推测是错误的… 在对这个handlerTeardownTest方法翻来覆去看了一个多小时，都没发现哪里有问题，该做异常处理的地方都做了，讲道理，应该会执行result.clear()，难道是 jmeter 抽风了，这个 teardownTest 根本就没有被调用？那如果没有被调用，就说明测试没结束，这样就说的通了：还有测试任务在进行，虽然服务器上日志显示没啥任务再跑，但是保不齐 Jmeter 的执行线程还在跑其他任务，而且这个任务是没有被我们服务正常处理掉的，因为我们为了保证用例(对应一个 hashTree，即 jmx 脚本)不能占用太长的时间，所以做了限制，当一条用例执行超过 5min 时，会强行结束，并把用例执行结果标记为超时。 事已至此，那就只能分析这个 SampleResult 对象为什么会创建这么多，而不进行释放，检查此对象引用关系 可以看到此时正在执行一个 jdbc 采样器，对采样器 label 进行 unicode 转中文可以看到内容是： 【SIT】xxxxxxxxx@~@While循环@~@校验调动数据 xxxxx-第113069次循环 (上面的 xxx 就是用例相关内容，此处做了脱敏)其中，第113069次循环 表示次用例可能是放在了一个 while 控制器中，但是 while 控制器是有固定的退出逻辑，如果到达指定时间没有满足条件，则会自动退出循环，一般来说不可能出现 11w+次的循环。在这里解释下为啥我说是进行了 113069 次循环，这是因为我们在对 Jmeter 做二次开发的时候，在生成报告时需要展示循环控制器下面采样结果，为了区分是哪个循环控制的，所以使用特殊分隔符 @~@ 来标记，后面的 113069 就是循环次数，大家也可以在 Jmeter 中添加一个 查看结果树 组件来看下效果。同时结合一个线上缺陷 我猜测，这个 bug 根本就没修复好，或者修复了非空判断的问题，但是改出来了另一个 bug。事已至此，无需多言，让改 bug 的人再去检查代码，最后发现确实是在生成 while 循环控制器的条件时，代码错误，导致这个 while 控制器无法退出。虽然有用例执行超时 5min 的限制，那也只是终止了调用 StandardJMeterEngine.run 方法的线程，Jmeter 在实际执行时还会创建子线程来执行采样器，这就导致了虽然用户看到了用例超时，但是这个循环控制器根本就停不下来，然后不停的调用 handleSampleResults方法，往 results里面塞数据，导致这个 list 膨胀的非常大。再加上加了 while 控制器的用例很多，大家都跑用例，导致这种线程停不下来，把服务器累个半死，内存也没法释放。 最终，这个问题被修复了，修复方法很简单，在生成 while 控制器循环条件的时候加一个小括号就行，上次修复 bug 的时候漏了这个小括号，导致 while-true 了。欸，心累啊。。。 总结这次事故根本原因就是开发在编写代码时没有对自己写代码做充分自测，并且没有评估到这种改动会造成什么样的影响，在我工作这么多年以来，这基本是一个无解的问题，只能说：各安天命吧！ 写在最后的话其实整篇文章看完，有些同学可能会嗤之以鼻，说：直接装一个 arthas，看下 dashboard 里面 RUNNERABLE 状态的线程，不就很快找到原因了么，哪有这么麻烦。但是现实情况是： 生产环境外网隔离，无法安装这类软件。 arths 在注入 jvm 时，可能会导致 jvm 中的线程出现挂起的情况，导致用户操作失败。 当时服务器已经非常卡了，我在执行 jstack 命令时都出现了几次失败的情况，更别说这种重量级软件运行了。 所以啊，还是得学会用 JDK 自带的工具来分析问题，并且写代码的时候长点心吧！ 本文省略了其他分析过程，因为那部分分析内容涉及到敏感代码和数据。 终。。。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://linvaux.github.io/tags/Java/"}]},{"title":"深入理解Java中的序列化和反序列化","slug":"深入理解Java中的序列化和反序列化","date":"2023-07-26T14:14:54.000Z","updated":"2024-09-21T00:59:08.945Z","comments":true,"path":"posts/131d41e/","permalink":"https://linvaux.github.io/posts/131d41e/","excerpt":"","text":"1. 技术背景​ 互联网的迅猛发展受益于网络通信技术的成熟和稳定。网络通信协议是机器双方共同约定的协议。在应用层看到的是结构体、对象，但是在网络协议里，机器之间传输的都是二进制流。网络编程中，需要定义应用层协议。最原始的应用层协议是字节数组，在 Java 语言里以 byte［］体现，在C语言里以 char［］体现。不管是 Java 语言还是 C 语言，开发人员都需要知道字节数组里每个字节的含义才能保证数据写入和读取的正确性。这对开发人员来说，是非常严苛且低效的。如何将程序中的结构体、对象等结构化内存对象转换为扁平的二进制流？如何将二进制流还原为结构化内存对象？为了解决这些问题，序列化&#x2F;反序列化技术应运而生。 核心意义：对象状态的保存(序列化)和重建(反序列化) 2. 序列化协议的特性 通用性 技术层面，序列化协议是否支持跨平台、跨语言。如果不支持，在技术层面上的通用性就大大降低了。 流行程度，社区是否成熟，是否能及时跟进Issue并解决Bug。 鲁棒性 成熟度不够，一个协议从制定到实施，到最后成熟往往是一个漫长的阶段。协议的强健性依赖于大量而全面的测试，对于致力于提供高质量服务的系统，采用处于测试阶段的序列化协议会带来很高的风险。 语言&#x2F;平台的不公平性。为了支持跨语言、跨平台的功能，序列化协议的制定者需要做大量的工作；但是，当所支持的语言或者平台之间存在难以调和的特性的时候，协议制定者需要做一个艰难的决定–支持更多人使用的语言&#x2F;平台，亦或支持更多的语言&#x2F;平台而放弃某个特性。当协议的制定者决定为某种语言或平台提供更多支持的时候，对于使用者而言，协议的强健性就被牺牲了。 可扩展性&#x2F;兼容性 扩展性表现为随着业务需求变化需要增减字段。字段变化的过程中，不会对现有系统的数据存储、数据访问造成影响，具有向后兼容性。扩展性也是序列化&#x2F;反序列化技术的核心指标之一。 性能 时间开销，复杂的序列化协议会导致较长的解析时间，这可能会使得序列化和反序列化阶段成为整个系统的瓶颈。 空间开销，如果序列化过程引入的额外开销过高，可能会导致过大的网络，磁盘等各方面的压力。对于海量分布式存储系统，数据量往往以TB为单位，巨大的的额外空间开销意味着高昂的成本。 易用性 易用性决定了开发者是不是需要花很多时间去学习，门槛是不是很高，接口是不是容易理解和使用。 安全性 安全性也是序列化工具选型的重要参考意见，比如广泛使用的fastjson，很多版本都存在RCE漏洞。 3. 序列化引擎​ 一般来说，序列化&#x2F;反序列化分为IDL（Interface Description Language，接口描述语言）和非IDL两类。非IDL技术方案包含 JSON、XML等，提供构造和解析的工具包即可使用，不需要做代码生成的工作。IDL技术方案包含 Thrift、Protocol Buffer、Avro 等，有比较完整的规约和框架实现。 IDL 描述文件：比如，Thrift 是以 thrift 为后缀的文件，Protocol Buffer是以 proto 为后缀的文件。IDL 文件编译器：根据 IDL 文件生成具有序列化&#x2F;反序列化功能的代码文件。例如，Thrift 通过 thrift 命令行指定编程语言类型来生成代码文件，Protocol Buffer 根据 protoc 命令行生成代码文件。Stub&#x2F;Skeleton 代码：在客户（Client）端，一般称为 Stub 代码。在服务器（Server）端，一般称为 Skeleton 代码。 4. Java序列化方式4.1 实现Serializable接口4.1.1 默认的序列化&#x2F;反序列化实现 Serializable 接口是最常用的序列化方式，以下是简单示例 准备一个待序列化的对象 12345678910111213141516package com.wick.pojo;import lombok.*;import java.io.Serializable;@Getter@Setter@ToString@NoArgsConstructor@AllArgsConstructorpublic class User implements Serializable &#123; private String name; private int age; private String address;&#125; 执行序列化操作 123456789101112131415161718package com.wick;import com.wick.pojo.User;import java.io.File;import java.io.IOException;import java.io.ObjectOutputStream;import java.nio.file.Files;public class App &#123; public static void main( String[] args ) throws IOException &#123; User user = new User(&quot;wick&quot;, 18, &quot;beijing&quot;); try (ObjectOutputStream os = new ObjectOutputStream(Files.newOutputStream(new File(&quot;user.out&quot;).toPath())))&#123; os.writeObject(user); &#125;; &#125;&#125; 在上面的例子中，我们使用 ObjectOutputStream.writeObject(Object obj ) 方法来完成对象的序列化，并保存到本地文件中，我们可以使用二进制文件编辑器打开看下文件内容 同样的，我们也可以使用 ObjectInputStream.readObject() 方法来将一个对象反序列化出来。 12345678 @Test public void test() throws IOException, ClassNotFoundException &#123; ObjectInputStream ins = new ObjectInputStream(Files.newInputStream(new File(&quot;user.out&quot;).toPath())); User user = (User) ins.readObject(); System.out.println(user); &#125;// out: User(name=wick, age=18, address=beijing) 除了使用默认的序列化机制外，对于一些特殊的类， 我们需要定制序列化和反序列化方法的时候，可以通过重写以下方法实现。 123private void writeObject(java.io.ObjectOutputStream out) throws IOException;private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException;private void readObjectNoData() throws ObjectStreamException; 上面的三个方法，并不是 Serializable 接口中的方法，而是特殊名称的方法，只要实现了 Serializable 接口，就可以通过重写这几个方法来实现定制的序列化和反序列化需求，jdk 中的很多类都有此操作，有兴趣的可以自行查看各自的实现，此处不做展开。 4.1.2 自定义序列化&#x2F;反序列化 对于上面的 User 类，我们可以通过重写 writeObject(java.io.ObjectOutputStream out) 方法来实现自定义的序列化，代码如下所示 123456789101112131415161718192021package com.wick.pojo;import lombok.*;import java.io.IOException;import java.io.Serializable;@Getter@Setter@ToString@NoArgsConstructor@AllArgsConstructorpublic class User implements Serializable &#123; private String name; private int age; private String address; private void writeObject(java.io.ObjectOutputStream s) throws IOException &#123; s.defaultWriteObject(); // 追加 toString() 的内容 s.writeBytes(&quot;name: &quot; + name + &quot;, age: &quot; + age + &quot;, address: &quot; + address); &#125;&#125; 序列化对象 1234567@Testpublic void testSerializer() throws IOException &#123; User user = new User(&quot;wick&quot;, 18, &quot;beijing&quot;); try (ObjectOutputStream os = new ObjectOutputStream(Files.newOutputStream(new File(&quot;user1.out&quot;).toPath())))&#123; os.writeObject(user); &#125;;&#125; 使用工具查看生成的二进制文件内容，可以明显看到后面追加了刚才 toString() 方法的内容，这样就实现了对象的自定义序列化。 同样的，我们也可以通过重写 readObject(java.io.ObjectInputStream s) 方法来实现自定义的反序列化操作 1234567891011private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); // 读取 toString() 的内容 byte[] bytes = new byte[1024]; int len = s.read(bytes); String[] split = new String(bytes, 0, len).split(&quot;,&quot;); // 此处，将 name 和 address 属性交换读取，不然看不出来区别 this.address = split[0].split(&quot;:&quot;)[1].trim(); this.age = Integer.parseInt(split[1].split(&quot;:&quot;)[1].trim()); this.name = split[2].split(&quot;:&quot;)[1].trim(); &#125; 反序列化对象 1234567@Testpublic void test() throws IOException, ClassNotFoundException &#123; ObjectInputStream ins = new ObjectInputStream(Files.newInputStream(new File(&quot;user1.out&quot;).toPath())); User user = (User) ins.readObject(); System.out.println(user.toString());&#125;// out: User(name=beijing, age=18, address=wick) 4.2 实现Externalizable接口除了实现 Serializable 接口完成序列化&#x2F;反序列化外，还可以通过实现 Externalizable 接口达到序列化&#x2F;反序列化的目的， 但是如果实现了 Externalizable 接口， 那就必须实现 writeExternal(ObjectOutput out) 和 readExternal(ObjectInput in) 方法。 以下我们还是以简单的 Person 类来举例。 12345678910111213141516171819202122232425262728293031323334353637383940package com.wick.pojo;import lombok.*;import java.io.Externalizable;import java.io.IOException;import java.io.ObjectInput;import java.io.ObjectOutput;/** * @author: wick * @date: 2023/5/3 12:09 * @description: */@Setter@Getter@NoArgsConstructor // 必须要有无参构造，如果没有重写构造方法，则默认会有无参构造@ToString@AllArgsConstructorpublic class Person implements Externalizable &#123; private String name; private int age; private String address; @Override public void writeExternal(ObjectOutput out) throws IOException &#123; out.writeObject(name); out.writeInt(age); out.writeObject(address); &#125; @Override public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException &#123; name = (String) in.readObject(); age = in.readInt(); address = (String) in.readObject(); &#125;&#125; 序列化对象 1234567@Testpublic void test2() throws IOException &#123; Person person = new Person(&quot;wick&quot;, 18, &quot;nanjing&quot;); try (ObjectOutputStream os = new ObjectOutputStream(Files.newOutputStream(new File(&quot;person.out&quot;).toPath())))&#123; os.writeObject(person); &#125;;&#125; 使用工具查看序列化后的内容 反序列化对象 1234567@Testpublic void test3() throws IOException, ClassNotFoundException &#123; ObjectInputStream ins = new ObjectInputStream(Files.newInputStream(new File(&quot;person.out&quot;).toPath())); Person user = (Person) ins.readObject(); System.out.println(user.toString());&#125;// out: Person(name=wick, age=18, address=nanjing) 4.3 两种序列化方式的比较 实现方式 Serializable 接口：是 Java 语言提供的标记接口，即不需要实现任何方法，只需要在类名加上 implements Serializable 即可。当一个对象被序列化时，Java 的序列化机制会把对象的状态保存到一个字节序列中。而当一个对象被反序列化时，Java 的序列化机制会根据保存的字节序列来创建并初始化一个对象。 Externalizable 接口：需要实现 readExternal 和 writeExternal 两个方法，用来表示如何序列化和反序列化一个对象。可以通过这两个方法来控制对象状态的写入和读取。 readExternal 和 writeExternal 方法不是由 Java 序列化机制调用的，而是需要手动调用，因此可以进行一些额外的初始化或特殊操作。 序列化效率 Serializable 接口：在序列化和反序列化一个对象时，序列化机制会自动地对该对象的所有非静态成员进行序列化和反序列化操作。因为使用的是自动序列化机制，这可能会创建一些不必要的对象和字节数组，从而降低序列化的效率，尤其当某个类的父类也实现了可序列化接口时，更耗费资源。 Externalizable 接口：由于对对象的序列化和反序列化过程都是手动控制的，Externalizable 实现的序列化效率比 Serializable 高，特别是在序列化大型对象图时。但是，需要手动调用接口的方法，可能需要更多的代码开销和维护成本。 综上所述，Serializable 接口更加简单且容易实现，但是效率相比于 Externalizable 接口会下降；而 Externalizable 接口需要手动编写序列化和反序列化的方法，但是它提供了更好的控制序列化的过程并且具有更高的序列化效率。 5 Java序列化核心类&#x2F;接口5.1 SerializableSerializable 接口源码如下： 12public interface Serializable &#123;&#125; Serializable 是一个空接口，表明了实现自该接口的子类具有序列化行为特征，所有要支持序列化的类都应该实现这个接口。在后面介绍 ObjectOutputStream 的writeObject 方法时，会解释为什么必须这么做。 5.2 ExternalizableExternalizable 接口源码如下： 123456public interface Externalizable extends java.io.Serializable &#123; void writeExternal(ObjectOutput out) throws IOException; void readExternal(ObjectInput in) throws IOException, ClassNotFoundException;&#125; 此接口有两个必须要重写的方法，在上面我们已经介绍过，writeExternal 的参数是 ObjectOutput，表示输出对象的抽象，它继承自 DataOutput，能支持基本类型、String、数组、对象的输出。实际应用中，会使用它的实现类 ObjectOutputStream。 readExternal 的参数是 ObjectInput，表示输入对象的抽象，它继承自 DataInput，能支持基本类型、String、数组、对象的输入。实际应用中，会使用它的实现类 ObjectInputStream。自定义的类必须包含无参构造函数。 5.3 ObjectOutputStreamjava.io.ObjectOutputStream 是实现序列化的关键类，它可以将一个对象转换成二进制流，然后通过 ObjectInputStream 将二进制流还原成对象。为了能更好地理解 ObjectOutputStream，先简要说明其内部的几个关键类： 5.3.1 BlockDataOutputStreamBlockDataOutputStream 是Java标准库中的一个类，它是DataOutputStream 的子类，用于提供对数据进行块写入的功能。BlockDataOutputStream 类主要用于为ObjectOutputStream 类提供支持。在对象序列化过程中，ObjectOutputStream 会使用 BlockDataOutputStream 来处理原始数据的写入。 以下是BlockDataOutputStream的一些主要特点和功能： 块数据写入：BlockDataOutputStream允许以块的形式，将原始数据按照一组字节进行写入。块数据包含了一些元信息，如块长度、类型等，以便在反序列化时进行正确的解析。 压缩：BlockDataOutputStream 可以对数据进行压缩，以减小序列化数据的大小，提高传输效率。 写入类型：除了基本的数据类型，BlockDataOutputStream 还支持写入字符串、数组、特定类型对象等。 缓冲区管理：BlockDataOutputStream使用内部缓冲区（Buffer）来提高写操作的性能。缓冲区会在需要时被填满并进行刷出。 简单来说，BlockDataOutputStream是用于支持对象序列化过程中的底层数据写入。它提供了块数据写入的功能，可以进行压缩以减小数据大小，同时也实现了缓冲区管理，以提高写入操作的性能。作为 ObjectOutputStream 内置的具有缓冲作用的输出功能类，包含阻塞和非阻塞两种工作模式。两种模式的工作流程相同，都是先把待写的数据写到缓冲区，直到缓冲区满后再执行真正的写入操作，只是在阻塞模式下，每次将缓冲区数据写入之前会写入一个阻塞标记头部（Block Data Header）。 5.3.2 HandleTable管理对象引用的处理，在 Java 的序列化机制中，如果一个对象被多次引用，那么在序列化过程中会将对象序列化为多个拷贝，这样会导致序列化结果变得冗长。为了解决这个问题，Java 序列化机制使用了对象引用句柄。HandleTable 类的作用是维护了一张对象引用句柄表，用来管理对象的序列化和反序列化过程中的引用处理。它通过使用句柄来代替重复的对象，从而实现对象的共享和压缩。具体来说，HandleTable 类中的 handles 数组存储了对象的引用句柄，索引值作为句柄值。当序列化一个对象时，ObjectOutputStream 会将对象写入输出流，并将其句柄（索引值）写入句柄表中。当序列化过程中遇到同一个对象的引用时，它会使用相同的句柄值来表示该对象，这样就实现了对象的共享。在反序列化过程中，ObjectInputStream会根据句柄值从句柄表中获取对应的对象引用。通过使用句柄表，HandleTable 类可以有效地减少序列化结果的大小，并提高序列化和反序列化的效率。它是Java序列化机制中的一个关键组件，帮助实现了序列化对象的共享和压缩。我们可以通过下面一张图来理解这个过程。 在上面这张简单的表示组合关系的类图中，我们可以看到 A 类是由 B 和 C 两个类来组合得到的，而 B，C 类内部都有 T 类，如果没有 HandleTable，那 A类的序列化过程就会变成： 构造对象 B 和 C 在 B 中构造对象 T，在 C 中构造对象 T 从上面这个过程我们发现，T 这个对象会分别在 B 和 C 中被构造一次，如果是更为复杂的对象，那么对于 T 来说，可能会出现非常多的拷贝对象，但是当引入 HandleTable 之后，事情就变得简单了，比先构造对象 B，然后发现用到了 T，则构造一次，并使用一个 Object[] 来缓存这个 T 对象，当构造 C 的时候发现它也用到了对象 T，则直接会从 Object[] 中取到这个对象的引用，避免了二次创建对象，下面是HandleTable类的简化示例： 12345678910111213class HandlesTable &#123; private Object[] handles; // 引用句柄表 public void setObject(int handle, Object obj) &#123; // 设置句柄对应的对象引用 handles[handle] = obj; &#125; public Object getObject(int handle) &#123; // 获取句柄对应的对象引用 return handles[handle]; &#125;&#125; 通过使用数组作为存储结构，HandleTable 能够快速通过句柄值来获取对应的对象引用。通过索引操作，可以直接访问数组的元素，无需进行遍历或搜索操作，因此具有较快的存取速度。当需要序列化和反序列化对象时，HandleTable 会根据需要动态扩展数组的大小，以适应不同数量的对象引用。 5.3.3 ReplaceTableReplaceTable类的主要作用是在序列化过程中，当遇到可以被替换的对象时，将对象替换为其他对象。这样可以更好地控制序列化的结果，实现自定义的序列化逻辑。具体来说，ReplaceTable类维护了一个替换表（Replacement table），它是一个Map数据结构，用于存储对象的替代对应关系。在序列化过程中，当要序列化一个对象时，ObjectOutputStream会检查该对象是否实现了writeReplace()方法。若实现了此方法，ObjectOutputStream会调用该方法获取替代对象，并将替代对象进行序列化。如果替代对象不为null，则将替代对象添加到替换表中。在后续的序列化过程中，如果遇到与替换表中的对象相等的对象时，ObjectOutputStream会将该对象替换为替代对象进行序列化。这样可以在序列化过程中实现对象替换，更好地控制序列化结果。通过使用ReplaceTable类，可以在序列化过程中灵活地替换对象，实现自定义的序列化行为，例如实现对象的版本控制、对象的压缩、对象的安全性检查等。 5.3.4 ObjectStreamClassObjectStreamClass 的主要作用是提供关于类的序列化和反序列化的元数据信息。它存储了与类相关的信息，并在序列化和反序列化时使用这些信息来进行匹配和操作。通过 ObjectStreamClass ，我们可以了解类的版本号、类的字段信息以及类的序列化支持情况等。这使得在进行序列化和反序列化过程时，能够正确地处理对象的属性和版本兼容性。以下是其核心字段及作用： 字段 字段意义 Class&lt;?&gt; cl 序列化类的 Class 类型 String name 序列化类的完整类名 volatile Long suid 序列化 ID，使用 volatile 关键字还可以禁止编译器进行某些优化，例如重排序。这是因为在对象序列化和反序列化的过程中，与版本号相关的操作必须按照特定的顺序进行，否则可能导致不正确的结果。 boolean isProxy 是否是代理类 boolean isEnum 是否是枚举类 boolean serializable 是否实现了 Serializable 接口 boolean externalizable 是否实现了 Externalizable 接口 boolean hasWriteObjectData 是否使用自定义的 writeObject 方法写数据 boolean hasBlockExternalData 类是否包含阻塞式外部数据，阻塞式外部数据指的是在进行对象的序列化时，如果存在某些在序列化过程中需要阻塞的外部数据（比如通过网络传输），那么阻塞式外部数据就会设置为true。 当hasBlockExternalData字段为true时，序列化和反序列化过程中的某些步骤可能会被阻塞，直到外部数据就绪或可用。这样可以确保在序列化和反序列化过程中正确地处理外部依赖。通过这个字段，ObjectStreamClass类在序列化和反序列化时可以根据需要采取相应的行动，以确保阻塞式外部数据正常处理。 ClassNotFoundException resolveEx 尝试解析类时发生的异常 ExceptionInfo deserializeEx 非枚举类反序列化异常，ExceptionInfo 也是 ObjectStreamClass 的一个内部类，表示操作类时产生的异常 ExceptionInfo serializeEx 非枚举类序列化异常 ExceptionInfo defaultSerializeEx 尝试默认序列化时引发的异常 ObjectStreamField[] fields 可序列化字段 int primDataSize 基本类型的成员字段个数，不包含被 static 和 transient 修饰的字段 int numObjFields 非基本类型的成员字段个数 FieldReflector fieldRefl 缓存与类相关联的字段反射信息。它提供了一个快速访问字段的能力，避免了每次进行字段反射访问时的性能开销 volatile ClassDataSlot[] dataLayout 类的层次结构：当前类，父类，及其所有子类的类描述 Constructor&lt;?&gt; cons 适合序列化的构造函数，如果没有，则为 null ProtectionDomain[] domains 与类相关联的保护域（ProtectionDomain）的数组。这些保护域定义了在序列化和反序列化过程中对类的访问权限。ProtectionDomain是Java安全性机制中的一个概念，它代表了一组相关代码的安全域。每个ProtectionDomain都由一个代码源（code source）和一组权限（permissions）组成。当一个对象被序列化时，其类信息会被存储在序列化数据中。在反序列化过程中，为了确保安全性，Java虚拟机（JVM）必须验证反序列化的类是否具有足够的权限进行访问。这个验证过程使用了类的保护域信息。通过domains属性，ObjectStreamClass可以存储和获取与类相关联的保护域信息。这些保护域将在反序列化过程中被用于验证类的访问权限。 Method writeObjectMethod 序列化方法，通过反射获取 Method readObjectMethod 反序列化方法，通过反射获取 Method writeReplaceMethod 当一个对象被序列化时，如果该对象类中定义了writeReplace()方法，那么在序列化过程中将调用这个方法来确定要序列化的对象。writeReplace()方法负责返回实际要序列化的对象。这样可以灵活地控制对象的序列化过程。 Method readObjectNoDataMethod 如果该对象类中定义了readObjectNoData()方法，那么在反序列化过程中将调用这个方法进行对象的初始化。readObjectNoData()方法用于在反序列化之后对反序列化得到的对象进行进一步处理，以确保对象的完整性和一致性 Method readResolveMethod 当一个对象被反序列化时，如果该对象类中定义了readResolve()方法，那么在反序列化过程中将调用这个方法来确定实际要返回的对象。readResolve()方法负责返回一个替代的对象，以确保在反序列化后得到的对象与原始对象保持一致。 ObjectStreamClass localDesc 当前类描述 ObjectStreamClass superDesc 父类描述 boolean initialized 对象是否已经初始化完成 5.4 ObjectInputStreamjava.io.ObjectInputStream 是实现Java反序列化的关键类，和 ObjectOutputStream 是对应的，内部包含了 BlockDataInputStream、HandleTable、ReplaceTable、ObjectStreamClass 等，这里不展开描述。 6. Java 序列化原理以上，我们了解到了 java 实现序列化的方式，以及序列化过程中会用到的核心类&#x2F;接口，接下来我们需要知道Java序列化的流程、原理，以及各种类型数据进行Java序列化后的格式和占用空间大小等细节，这也是序列化技术的核心所在。不同序列化方案的技术细节不尽相同，对各种数据类型处理后的格式和大小也不尽相同。 6.1 基本类型数据序列化流程在学习基本类型的序列化流程之前，我们先回顾两个知识点 Java 中基本数据类型有几种，及其长度 数据类型 字节长度 int 4字节（-2,147,483,648 到 2,147,483,647） long 8字节（-9,223,372,036,854,775,808 到 9,223,372,036,854,775,807） double 8字节（IEEE 754双精度浮点数） char 2字节（无符号Unicode字符，以UTF-16编码表示，可存储一个unicode字符） byte 1字节（-128 到 127） boolean 1 位，只能是 true 或者 false short 2字节（-32,768 到 32,767） float 4字节（IEEE 754单精度浮点数） 字节的高低位 在计算机中，一个字节由8个位（bit）组成。在一个字节中的每个位都有特定的位置。位可以被编号，从最右边的位（称为最低有效位）开始，往左依次递增编号，最左边的位称为最高有效位，也称为高位。其实这个很好理解，在电视上我们也见过支票，支票的金额就是从左往右写的 比如上面这张图，在右边的金额栏，从左往右依次是高单位到低单位，所以最左边的就是高位，最右边的就是低位。 字节的高位和低位术语通常用于表示多字节数据类型（如整数）的个别字节在内存中的存储顺序。在多字节的数据类型中，数据在内存中以连续的字节序列存储，而字节序列的顺序可以是”大端”或”小端”。 大端字节序：最高有效位存储在起始地址，最低有效位存储在最后地址。 小端字节序：最低有效位存储在起始地址，最高有效位存储在最后地址。 举个例子，假设一个整数值0x12345678在内存中按照大端字节序存储。将这个整数值转换为字节序列时，高位字节0x12存储在起始地址，低位字节0x78存储在最后地址。 地址: 0 1 2 3 ​ | 0x12 | 0x34 | 0x56 | 0x78 | 相反，如果按照小端字节序存储，高位字节0x78存储在起始地址，低位字节0x12存储在最后地址。 地址: 0 1 2 3 ​ | 0x78 | 0x56 | 0x34 | 0x12 | 在Java中，默认使用的是采用大端字节序（Big Endian）的内存存储模式。这意味着在多字节数据类型（如int、long、float、double等）存储在内存中时，最高有效字节存储在起始地址，按顺序向后存储。 回顾完上面两个问题，我们继续看 Java 是如何序列化基本类型数据的，Java序列化对基本类型数据的处理，严格按照其内存占用大小来进行。比如int类型占用4字节，Java 序列化按照高位到低位依次放到字节数组，再写入到序列化输出对象，真正的写入是通过调用 BlockDataOutputStream 的 writeInt 方法实现的。BlockDataOutputStream 内部维护了一个1024字节大小的缓冲区，如果缓冲区还可以容纳待写入的 int 类型数据，则把当前数据放入缓冲区；如果缓冲区不能容纳待写入的int类型数据，则调用 DataOutputStream 的 writeInt 方法，如以下代码所示： 接下来我们看下 DataOutputStream 的 writeInt() 方法是如何写 int 类型数据的 我们可以逐步看下这几段代码的含义： out.write(): 很明显这是一个写入操作，可以将内容写入文件或者套接字。 v &gt;&gt;&gt; 24: 这是一个无符号右移操作符，将v向右移动24位（int 长度 4 字节，即 32 位，从第一个字节(8位)开始向右移动24 位即可达到最低位 32 ）。右移操作是将二进制表示中的各位数值向右移动指定的位数，右边的空位用零填充。无符号右移运算符保证移位后左边空出的位总是用零填充。在这个表达式中，我们将整数v的最高8位移动到最低8位，并将其余位数清零，这样就可以提取一个 int 类型变量的最高有效字节的值，而不考虑符号位。 &amp; 0xFF: 这是一个按位与操作符，将上一步的结果与0xFF（十进制为255）进行按位与操作。0xFF的二进制表示为 00000000 00000000 00000000 11111111。这个操作可以确保结果只保留v最高的8位，将其他位数清零。 从上面的代码我们可以看出，确实是按照从高到低的顺序来写入的。我们继续看 out.write() 做了什么(在当前流程中，out 是 BlockDataOutputStream 实例) 如果缓冲区能容纳当前待写入字节，则把当前字节写入缓冲区；如果缓冲区已满，则会先执行 drain 方法把缓冲区的数据输出，再把当前待写入字节放到缓冲区。通过上述流程，一个 int 类型的数据就写完了，其他类型数据流程类似，此处不做展开。 6.2 对象类型数据序列化流程学习完基本类型的序列化流程，我们来看下对象类型的数据是怎么被序列化的。Java序列化对非基本类型的数据处理比基本类型的数据处理更复杂，这里说的非基本类型包括Object、Enum、Array等。Java序列化对非基本类型数据的序列化操作是通过 ObjectOutputStream 的 writeObject 方法实现的，接下来将介绍其内部工作原理。 我们先看下 writeObjet 方法定义 首先检查是否启用了对象写入的重写功能。如果启用了，将调用writeObjectOverride方法，并立即返回。这个条件语句允许自定义的子类重写写入对象的逻辑。obj表示自定义的序列化对象或者Array、Enum类型对象。writeObject0 方法的第2个参数表示一个对象被多个对象共同引用时，在序列化的时候是否要共享写入。如果共享写入，被引用的对象实例只会被序列化一次，其他引用只会写入引用对象句柄。如果不共享写入，被引用的对象实例则会被序列化多次，序列化后的数据大小会增加。在 writeObject 方法里调用 writeObject0，第2个参数默认是false，表示共享写入。 我们继续看下 writeObject0 里面是如何处理非基本类型数据的。 代码比较简单，就是判断 obj 的类型，然后分别调用对应的处理方法，其实如果大家有翻过 String 或者 Enum 的源码，就会发现，这两个类也是实现了 Serializable 接口的，表示这些类都能被正常的序列化。对于Array对象，如果Array的元素是基本类型，则调用基本类型的序列化方式；如果Array的元素是Object类型，则递归调用writeObject0方法来执行序列化，又会执行到上述if分支判断。 如果是自定义的序列化类，则必须实现自Serializable。总之，要能够被 ObjectOutputStream 的 writeObject 方法序列化，对象必须实现自Serializable，否则会抛NotSerializableException异常。 如果是自定义的序列化类，则会执行 writeOrdinaryObject 方法。 我们看下 writeOrdinaryObject 这个方法是如何处理我们自定义的序列化类的。 如果自定义的类是 Externalizable 类型并且不是代理类，则调用writeExternalData方法；否则调用writeSerialData方法。Exernalizable继承自Serializable，并增加了writeExternal和readExternal两个接口。我们继续跟进 writeSerialData方法。 首先获取 obj 对象的布局信息，getClassDataLayout() 表示获取当前类及继承链路上所有直接或间接实现了Serializable的祖先类对应的序列化元数据信息，返回值为ClassDataSlot类型数组，数组元素的顺序是从最根部的祖先类到当前类。ClassDataSlot包含了一个ObjectStreamClass类型的desc字段和boolean类型的hasData字段。ObjectStreamClass类前面已经提过，hasData字段表示desc对应的Java对象是否有数据被序列化。对于ClassDataSlot数组的每一个元素，如果该元素对应的类包含writeObject方法，则调用writeObjet方法。通过查看ObjectStreamClass里的invokeWriteObject方法内部实现，可以看出wirteObject方法以反射方式被调用，代码如下所示。 回到writeSerialData方法内部实现，如果当前待序列化的类没有writeObject方法，则调用defaultWriteFields方法实现序列化，其内部实现如以下代码所示。 流程也比较简单，就是分开处理基本类型和对象类型的数据，其实没有 writeObject() 方法的类，但是还需要序列化的，我们很明显就知道是实现了 Serializable 接口的类，这也就是为什么你实现了这个序列化接口，但是无需实现序列化方法的原因。 回到writeOrdinaryObject方法实现，如果自定义类实现了Externalizable且不是动态代理类，则会调用writeExternalData方法实现序列化，核心代码如下所示。 代码最终调用自定义类对象的writeExternal方法实现写入，看起来比Serializable类更简洁，原因是Externalizable接口中包含了readExternal和writeExternal方法，实现了Externalizable的子类必须覆盖readExternal和writeExternal方法。 7. Java 序列化高级特性7.1 transient 关键字Java序列化可以通过transient关键字来控制字段不被序列化。通过跟进ObjectStreamClass的getDefaultSerialFields方法内部实现，可以看到序列化字段不能为static 且不能为 transient，如以下代码所示： 7.2 static 关键字static字段属于类全局共有，不会被序列化。在反序列化得到的结果里，静态变量的值依赖类对该静态字段的初始化操作以及是否在同一个JVM进程内。比如说静态变量初始值为0，在序列化之前静态变量的值被设置为10，在同一个JVM进程内执行反序列化操作，得到的静态变量的值为10。如果在另外一个JVM进程内执行反序列化操作，得到的静态变量的值为0。这是因为类在JVM进程内只会被加载一次，相同的类在不同的JVM内都会初始化一遍。 7.3 serialVersionUIDserialVersionUID用来实现类版本兼容，在实际开发中能满足类字段变化的需求。如果我们有一个 Person 类，实现了 Serializable 接口，但是没有定义serialVersionUID字段，对Person类增加一个double类型的字段height，再读取增加字段之前的序列化数据，反序列化会报InvalidCastException 异常。如果Person类定义了serialVersionUID字段，对Person类增加一个double类型的字段height，再读取增加字段之前的序列化数据，反序列化可以成功。 serialVersionUID字段必须是 static+final 类型，否则serialVersionUID字段不会被序列化，通过 ObjectStreamClass 的 getDeclaredSUID 方法实现可以得到验证: 如果不定义serialVersionUID字段，Java序列化会根据类字段和其他上下文计算一个默认值。所以，当类字段发生变化时，serialVersionUID值也会跟着变化，就会出现上述因类字段变化导致反序列化失败的问题。在Java编码规范中，应该强制自定义的序列化类包含serialVersionUID字段，各个Java IDE开发工具均能配置针对serialVersionUID的检查告警级别。 7.4 序列化&#x2F;反序列化hook7.4.1 writeReplace 方法writeReplace方法用于序列化写入时拦截并替换成一个自定义的对象。这个方法也是在 ObjectStreamClass 类中被反射获取的 由于writeReplace方法调用是基于反射来执行的，所以作用域限定符不受限制，可以是private、default、protected、public中的任意一种。 如果定义了wirteReplace方法，就没必要再定义writeObject方法了。即使定义了writeObject方法，该方法也不会被调用，内部会先调用writeReplace方法将当前序列化对象替换成自定义目标对象。同理，也没必要定义readObject方法，即使定义了也不会被调用。writeReplace方法的生效原理见ObjectOutputStream的writeObject0方法实现，核心代码如下所示。 7.4.2 readReplace 方法readResolve方法用于反序列化拦截并替换成自定义的对象。但和writeReplace方法不同的是，如果定义了readResolve方法，readObject方法是允许出现的。同样的，readResolve 方法也是在 ObjectStreamClass 类中被反射获取的。 readResolve方法的工作原理为： 首先调用readObject0方法得到反序列化结果。 如果readResolve方法存在，则会调用该方法返回自定义的对象。 将自定义的对象作为ObjectInputStream的readObject的返回值。 readResolve方法用在什么场景呢？常见的一种场景是类实现的枚举类型，枚举对象在反序列化时做恢复性保护。对于类实现的枚举类型，反序列化出来的枚举对象期望是定义的枚举对象，这也体现了枚举的意义。但是从代码执行情况看，反序列化出来的的枚举对象是一个新建出来的枚举对象，虽然值和枚举值定义的一样，但不是同一个对象。因此，需要在反序列化的过程中对枚举对象进行恢复保护，readResolve方法就派上用场了。示例如下： 未使用 readResolve 方法前： 123456789101112131415161718192021222324252627282930313233343536package com.oppo.serializedemo.pojo.po;import lombok.AllArgsConstructor;import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter;import java.io.*;/** * @author: wick * @date: 2023/7/29 22:17 * @description: */@Getter@Setter@NoArgsConstructor@AllArgsConstructorpublic class PhoneType implements Serializable &#123; private static final long serialVersionUID = 1L; private int type; public static final PhoneType OPPO = new PhoneType(0); public static final PhoneType VIVO = new PhoneType(1); public static void main(String[] args) throws Exception &#123; ObjectOutputStream os = new ObjectOutputStream(new FileOutputStream(new File(&quot;phoneType.out&quot;))); os.writeObject(PhoneType.OPPO); os.close(); ObjectInputStream is = new ObjectInputStream(new FileInputStream(new File(&quot;phoneType.out&quot;))); PhoneType phoneType = (PhoneType) is.readObject(); System.out.println(phoneType == PhoneType.OPPO); // false &#125;&#125; 添加 readResolve 方法: 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.oppo.serializedemo.pojo.po;import lombok.AllArgsConstructor;import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter;import java.io.*;/** * @author: wick * @date: 2023/7/29 22:17 * @description: */@Getter@Setter@NoArgsConstructor@AllArgsConstructorpublic class PhoneType implements Serializable &#123; private static final long serialVersionUID = 1L; private int type; public static final PhoneType OPPO = new PhoneType(0); public static final PhoneType VIVO = new PhoneType(1); private Object readResolve() throws ObjectStreamException &#123; if (type == 0) &#123; return OPPO; &#125; else if (type == 1) &#123; return VIVO; &#125; return null; &#125; public static void main(String[] args) throws Exception &#123; ObjectOutputStream os = new ObjectOutputStream(new FileOutputStream(new File(&quot;phoneType.out&quot;))); os.writeObject(PhoneType.OPPO); os.close(); ObjectInputStream is = new ObjectInputStream(new FileInputStream(new File(&quot;phoneType.out&quot;))); PhoneType phoneType = (PhoneType) is.readObject(); System.out.println(phoneType == PhoneType.OPPO); // true &#125;&#125; 7.5 数据校验Java序列化机制在反序列化时支持对数据进行校验。这是因为Java序列化后的数据是明文形式，有可能被修改。在反序列化过程中，为了安全起见，可以对读取到的数据进行校验。默认的Java反序列化是不会校验数据的。 使用数据校验特性，需要让自定义的序列化类实现 java.io.ObjectInputValidation 接口，通过调用回调函数 validateObject 来实现数据验证。此处给出示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.oppo.serializedemo.pojo.po;import lombok.*;import java.io.*;import java.util.Objects;/** * @author: wick * @date: 2023/7/30 10:45 * @description: */@Getter@Setter@NoArgsConstructor@AllArgsConstructor@ToStringpublic class User implements Serializable, ObjectInputValidation &#123; private static final long serialVersionUID = 1L; private String name; @Override public void validateObject() throws InvalidObjectException &#123; if (Objects.equals(name, &quot;zhangSan&quot;)) &#123; throw new InvalidObjectException(&quot;用户已经被禁用&quot;); &#125; &#125; private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException &#123; in.defaultReadObject(); // 执行默认的反序列化操作 validateObject(); // 在反序列化完成后进行对象验证 &#125; public static void main(String[] args) throws Exception &#123; ObjectOutputStream os = new ObjectOutputStream(new FileOutputStream(&quot;user&quot;)); User user = new User(&quot;zhangSan&quot;); os.writeObject(user); os.close(); ObjectInputStream is = new ObjectInputStream(new FileInputStream(&quot;user&quot;)); // 在此处就会抛出异常：java.io.InvalidObjectException: 用户已经被禁用 User user1 = (User) is.readObject(); is.close(); System.out.println(user1); &#125;&#125; 8 选择 Serializable 还是 Externalizable在Java序列化应用方面，读者应该会困惑两种机制应选择哪种。从功能角度看，二者都是Java序列化已经支持的。从易用性方面来考虑，Serializable比Externalizable易用性好。首先，Serializable提供了默认的序列化与反序列化行为，用户不需要关注序列化的实现细节即可拿来使用；而Externalizable必须实现readExternal和writeExternal接口且要提供默认构造函数。其次，在自定义序列化行为方面，Serializable也可以通过readObject和writeObject来支持。 对于初学者或者对自己代码水平没啥自信的同学，可以优先选择Serializable。从很多JDK源码和开源代码中可以看到，序列化接口都实现自Serializable。在继承链路上，如果要终止一个子类的Serializable或者Externaizable特性，则在readObject&#x2F;writeObject方法或readExternal&#x2F;writeExternal方法接口里抛出 UnsupportedOperationException 异常，表示不支持序列化和反序列化功能。 9. Java序列化安全Java序列化后的数据是明文形式，而且数据的组成格式有明确的规律。当这些数据脱离Java安全体系存在磁盘中时，可以通过二进制数编辑工具查看，甚至修改。如果这些数据注入了病毒，应用程序的表现行为将无法预计。为了保障数据的安全性，引入SealedObject和SignedObject对序列化数据进行加密。 9.1 SealedObject以下演示如何使用 SealedObject 来保证序列化&#x2F;反序列化安全 12345678910111213141516171819202122232425262728293031323334353637383940package com.oppo.serializedemo.pojo.po;import lombok.*;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.SealedObject;import javax.crypto.SecretKey;import java.io.FileOutputStream;import java.io.ObjectOutputStream;import java.io.Serializable;/** * @author: wick * @date: 2023/7/30 10:45 * @description: */@Getter@Setter@NoArgsConstructor@AllArgsConstructor@ToStringpublic class User implements Serializable &#123; private static final long serialVersionUID = 1L; private String name; private Integer age; public static void main(String[] args) throws Exception &#123; ObjectOutputStream os = new ObjectOutputStream(new FileOutputStream(&quot;user&quot;)); SecretKey key = KeyGenerator.getInstance(&quot;DESede&quot;).generateKey(); Cipher cipher = Cipher.getInstance(&quot;DESede&quot;); cipher.init(Cipher.ENCRYPT_MODE, key); User user = new User(&quot;zhangSan&quot;, 18); SealedObject sealedObject = new SealedObject(user, cipher); os.writeObject(sealedObject); os.close(); &#125;&#125; 使用二进制工具查看 user 文件，发现跟我们之前未加密的数据不一样，连基本字段和值都看不到了 我们直接使用 ObjectInputStream 反序列化一下试试 123456789101112131415161718192021222324252627282930313233343536373839404142package com.oppo.serializedemo.pojo.po;import lombok.*;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.SealedObject;import javax.crypto.SecretKey;import java.io.*;/** * @author: wick * @date: 2023/7/30 10:45 * @description: */@Getter@Setter@NoArgsConstructor@AllArgsConstructor@ToStringpublic class User implements Serializable &#123; private static final long serialVersionUID = 1L; private String name; private Integer age; public static void main(String[] args) throws Exception &#123; ObjectOutputStream os = new ObjectOutputStream(new FileOutputStream(&quot;user&quot;)); SecretKey key = KeyGenerator.getInstance(&quot;DESede&quot;).generateKey(); Cipher cipher = Cipher.getInstance(&quot;DESede&quot;); cipher.init(Cipher.ENCRYPT_MODE, key); User user = new User(&quot;zhangSan&quot;, 18); SealedObject sealedObject = new SealedObject(user, cipher); os.writeObject(sealedObject); os.close(); ObjectInputStream is = new ObjectInputStream(new FileInputStream(&quot;user&quot;)); SealedObject sealedObject1 = (SealedObject) is.readObject(); is.close(); User u1 = (User) sealedObject1.getObject(key); System.out.println(u1); // User(name=zhangSan, age=18) &#125;&#125; 至此，我们就通过一个加密&#x2F;解密的手段来保护了对象在序列化&#x2F;反序列化过程中的安全。 9.2 SignedObjectSignedObject 也是通过加解密的方式来保护序列化安全的，示例如下： 1234567891011121314151617181920212223242526272829303132333435363738package com.oppo.serializedemo.pojo.po;import lombok.*;import java.io.*;import java.security.KeyPair;import java.security.KeyPairGenerator;import java.security.Signature;import java.security.SignedObject;/** * @author: wick * @date: 2023/7/30 11:26 * @description: */@Getter@Setter@NoArgsConstructor@AllArgsConstructor@ToStringpublic class Account implements Serializable &#123; private String name; private Double money; public static void main(String[] args) throws Exception &#123; ObjectOutputStream os = new ObjectOutputStream(new FileOutputStream(&quot;account&quot;)); KeyPair keyPair = KeyPairGenerator.getInstance(&quot;RSA&quot;).generateKeyPair(); Account account = new Account(&quot;zhangSan&quot;, 1000.0); SignedObject signedObject = new SignedObject(account, keyPair.getPrivate(), Signature.getInstance(&quot;SHA256withRSA&quot;)); os.writeObject(signedObject); os.close(); ObjectInputStream is = new ObjectInputStream(new FileInputStream(&quot;account&quot;)); SignedObject signedObject1 = (SignedObject) is.readObject(); Account account1 = (Account) signedObject1.getObject(); System.out.println(account1); &#125;&#125; 10. 总结Java序列化方案成熟度高，但性能和压缩效果均一般，只适合JVM系列语言共享数据，不具备完全的跨语言能力。另外，它会带来一些数据安全性和完整性问题。在我们真正的 web 开发过程中，基本不会去使用以上的序列化方式，而是往往会选择具有跨语言能力、性能高效、压缩效果显著的方案，例如Thrift、Protocol Buffer、Json、Xml 等。但是了解 Java 的序列化&#x2F;反序列化过程，对于程序员能力的提升，还是有较大的意义。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://linvaux.github.io/tags/Java/"}]},{"title":"IDEA高效使用指南(一)","slug":"IDEA高效使用指南（一）","date":"2023-07-26T13:48:42.000Z","updated":"2024-09-21T00:59:08.926Z","comments":true,"path":"posts/fb3714ea/","permalink":"https://linvaux.github.io/posts/fb3714ea/","excerpt":"","text":"设置全局 JDK File -&gt; New Projects Setup -&gt; Structure… Maven 配置 Perferences -&gt; Build,Execution,Deployment -&gt; Build Tools -&gt; Maven 自动导包&#x2F;删除无用包 Perferences -&gt; Editor -&gt; General -&gt; Auto Import 注释模板 Perferences -&gt; Editor -&gt; File and Code Templates class 注释模板示例 123456789#if ($&#123;PACKAGE_NAME&#125; &amp;&amp; $&#123;PACKAGE_NAME&#125; != &quot;&quot;)package $&#123;PACKAGE_NAME&#125;;#end#parse(&quot;File Header.java&quot;)/** * @author: $&#123;USER&#125; * @date: $&#123;DATE&#125; $&#123;TIME&#125; * @description: */public class $&#123;NAME&#125; &#123;&#125; 显示方法分割线 Perferences -&gt; Editor -&gt; General -&gt; Appearance 代码自动补全 Perferences -&gt; Editor -&gt; General -&gt; Code Completion 设置每行代码最大长度 Perferences -&gt; Editor -&gt; Code Style 阿里巴巴的 Java 开发规范推荐每行长度不要超过 120，但是我习惯用 200 修改注释颜色 Perferences -&gt; Editor -&gt; Color Scheme -&gt; Java 去掉Inherit values from 前面的√，选中 Foreground 自己设置个喜欢的颜色 这是我现在的配置 Line comment: FFB704, Text: 02FA15 禁止 IDEA 启动时，自动打开上一个项目 Perperences -&gt; Appearance &amp; Behavior -&gt; System Settings 修改字体 Perferences -&gt; Editor -&gt; Font 我习惯使用 Consolas 字体，但是 mac 上默认没有这个字体，需要自行安装: http://www.fontpalace.com/font-details/Consolas/ 修改文件编码 Perferences -&gt; Editor -&gt; File Encodings 直接使用 UTF-8 编码即可，如果出现乱码，记得勾选下面的 Transparent native-to-ascii conversion 修改 IDEA 的 JVM 堆配置 IDEA 默认的堆配置貌似是 750MB，启动一个大型项目时，这点内存不大够用，可以自己通过如下配置修改 help -&gt; Edit custom VM options 修改配置 -Xmx8192m, 按照自己电脑内存大小配置 窗口多标签换行显示 Perferences -&gt; Editor -&gt; General -&gt; Editor Tabs 标识修改过的文件 Perferences -&gt; Editor -&gt; General -&gt; Editor Tabs 实现 Serializable 接口时，提示生成 SerialVersionUID Perferences -&gt; Editor -&gt; Inspections 在实现了 Serializable 接口的类上使用快捷键 alt+enter,就会提示生成 SerialVersionUID","categories":[],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://linvaux.github.io/tags/IDEA/"}]},{"title":"IDEA插件整理(一)","slug":"IDEA插件整理（一）","date":"2023-07-25T15:24:54.000Z","updated":"2024-09-21T00:59:08.925Z","comments":true,"path":"posts/c8c9feb8/","permalink":"https://linvaux.github.io/posts/c8c9feb8/","excerpt":"","text":"Atom Material Icons material风格图标库，装完之后页面就花里胡哨的，挺好看 Material Theme UI material风格主题，还是挺好看的 One Dark Theme 暗黑风格主题（推荐），主要是免费 Rainbow Brackets 彩虹括号 .ignore 生成各类.ignore文件，在创建git仓库的时候使用此插件格外方便 CodeGlance 代码缩略图，方便定位代码 Java Bean to Json 在bean上右键，即可将此bean复制为json格式，在构造请求时比较方便 maven-search maven&#x2F;gradle坐标搜索插件，贼好用，支持模糊搜索 Maven Helper 依赖冲突查看神器，也可以树状展示依赖关系 Mybatisx mybatis-plus团队出品的插件，支持从数据库表直接生成代码，包含基本CRUD功能，很方便 MyBatisCodeHelperPro 怎么说呢，就是很厉害，基本不用自己写代码了，但是收费 演示视频：https://www.bilibili.com/video/av50632948 使用文档：https://gejun123456.github.io/MyBatisCodeHelper-Pro/#/ MyBatis Log EasyPlus 格式化mybatis日志，很好用 SequenceDiagram 生成方法的时序图，非常有用官方文档：https://vanco.github.io/SequencePlugin/ PlantUML 时序图，类图绘制插件 Grep Console 由于Intellij idea不支持显示ascii颜色，grep-console插件能很好的解决这个问题，下面就以开发JavaEE项目中，结合Log4j配置多颜色日志输出功能。 GitToolBox git工具箱，可以显示当前代码分支和每一行代码提交人以及commit log Translation 翻译插件，再也不用去百度翻译了 RestfulToolkit 根据url直接跳转到对应的controller，比较好用，尤其是url多的时候，直接搜索url就可以了 Key promoter X 记性不好的可以试试，时间长了就能记住快捷键了 Statistic 项目信息统计 Git Commit Message Helper 帮助生成commit message","categories":[],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://linvaux.github.io/tags/IDEA/"}]},{"title":"Jmeter源码系列(3) - Jmeter 类详解-start方法，Jmeter 真正的启动过程","slug":"Jmeter源码系列-3-Jmeter-类详解-start方法，Jmeter-真正的启动过程","date":"2023-07-14T14:07:00.000Z","updated":"2024-09-21T00:59:08.934Z","comments":true,"path":"posts/e7832353/","permalink":"https://linvaux.github.io/posts/e7832353/","excerpt":"","text":"在开始讲 start 方法前，大家先考虑一个问题，Jmeter 启动时带不带参数有什么影响？我们可以带着这个问题往下看。 Jmeter启动参数是如何传递的？在前面两篇文章中，已经跟大家非常详细的介绍了 Jmeter 启动时会做什么，回顾一下就是： 调用 NewDriver.main(String[] args) 方法，此方法会反射调用 Jmeter.start(String[] args) 方法。 在执行 Jmeter.start(String[] args) 方法前，Jmeter 类现需要实例化，这个类中包含了非常多的静态常量，绝大多数都是跟启动参数相关，这些参数会在类实例化时也被初始化掉。 那么这些参数是从哪来的呢？其实入口就是 NewDriver.main(String[] args) ，这个方法的参数列表可以从 Jmeter 的启动脚本获取，也可以通过执行 1java -jar ApacheJMeter.jar xxx 来启动 后面的 xxx 表示的就是启动参数，跟执行以下命令效果一样 1jmeter xxx 我们可以通过查看 Jmeter &#x2F;bin 目录下的 jmeter 脚本来验证这个过程，以下内容是 JMeter 在 mac 下的启动脚本，其中只保留了最后几行内容，其他系统下的脚本内容也是类似，就不在此处展开解释。这段脚本其实很简单，就是判断 JMETER_COMPLETE_ARGS 这个变量是不是为空，用来控制 ARGS 参数值，最后一行就是很普通的 java 应用启动命令，后面的 “$@” 是一个特殊变量，用于表示所有向脚本传递的位置参数（命令行参数）。具体来说，$@ 会将所有的位置参数作为一个单独的字符串列表返回。每个位置参数会被当作一个独立的字符串，在使用时可以通过遍历 $@ 获取每个参数。需要注意的是，”$@” 使用双引号括起来时，会将每个位置参数作为独立的字符串处理，保留参数中的空格和特殊字符。这样可以确保传递参数时的正确性，在处理包含空格或特殊字符的参数时非常有用。 顺便提一句，上面判断了 JMETER_COMPLETE_ARGS 是为了给 Java9 单独设置一些启动参数，因为在 Java 9 之前的版本中，可以使用标准的 JAVA_OPTS 环境变量来设置 Java 虚拟机的选项。然而，从 Java 9 开始，Oracle 官方建议使用 JAVA_TOOL_OPTIONS 环境变量来设置 Java 应用程序的选项，以便与新的模块化系统和命令行标志兼容。为了确保 JMeter 在不同版本的 Java 中都能正常运行，并且可以方便地配置 Java 9 相关的选项，此处单独处理了 Java 9 的选项设置。通过使用 JAVA9_OPTS 环境变量存储 Java 9 相关的选项，并将其与其他选项拼接到 ARGS 字符串中，以便将这些选项传递给 JMeter 启动脚本。这种单独处理 Java 9 的选项，能够更好地适应不同版本的 Java，并确保在升级或切换 Java 版本时不会影响到 JMeter 的启动脚本和选项设置。这样做的目的是为了提高 JMeter 的兼容性和可移植性。 ok，那现在我们知道了，NewDeriver.main(String[] args) 会接受命令行参数，然后 main 方法再反射调用 Jmeter.start(String[] args) 时，也会把参数传递下去，代码如图所示：invoke 方法第二个参数 args 就是 main 方法接收到的参数，这就完成了参数从命令行传递给 Jmeter 的过程，在实例化 Jmeter 时，这些参数又被 CLOptionDescriptor 类处理了一次，从一堆字符串变成了一个对象，方便 Jmeter 更好的处理参数，那接下来我们迎来了本文章的重点：Jmeter.start(String[] args) 方法到底做了什么？ Jmeter 是如何启动的？在解释代码之前，大家有没有发现一个现象： 当我们什么启动参数都不带时，Jmeter 会直接以 GUI 模式启动，我们可以写脚本调试，甚至直接开始测试，也可以不跑测试，写个脚本就把它关掉。但是当我们使用 cli 时，就可以直接传递一个 jmx 脚本给 Jmeter，这时 Jmeter 就会直接开始测试。这两种方式是如何实现的呢？ 如果大家有观察过这个现象，那接下来的内容会非常容易理解，因为这涉及到了 Jmeter 的 2 种启动模式： startGui startNonGui 但是这个时候大家会疑惑，之前不是说 Jmeter 有三种启动模式么，分别是：GUI，NON-GUI, SERVER，为啥到这边又成了 2 种了？ 其实，这前后并没有矛盾，因为 SERVER 和 NON-GUI 模式都是属于 NON-GUI 的方式启动，我们此处只是讨论 Jmeter 在启动时的宏观表现，即有没有图形界面。 接下来，我们就开始从代码出发，看下 Jmeter 真正的启动过程。 1.命令行参数校验在进入 start 方法后，会先对命令行参数的组合进行判断，如果参数组合不支持，则生成一个 error 信息，然后判断 error 是否为 null，如果有错误信息，则停止启动，并在控制台输出错误信息。 2.初始化运行环境参数校验通过之后，Jmeter 会进行运行环境初始化，虽然 NewDriver 已经初始化过一次(主要做类加载)，但是 Jmeter 会做更细致的初始化动作，以下是 Jmeter 初始化内容 初始化 Properties：实现方法为 Jmeter.initializeProperties(CLArgsParser parser) 方法。首先检查用户是否通过 -p 参数设置了 property 文件，如果没有设置，则直接使用 bin&#x2F;jmeter.properties 文件。其次设置 Jmeter 语言环境，设置 JmeterHome，还有就是读取 user.properties，system.properties 以及用户通过命令行参数自己指定的 property 文件，最后设置下日志等级。 添加安全提供程序：根据给定的 Properties 对象，筛选匹配特定模式的键值对，并按照键的顺序逐个调用 addSecurityProvider 方法，作用是：(1)扩展功能：通过添加安全提供程序，可以扩展 Java 程序的加密、签名、哈希等安全功能，使其支持更多的算法和标准。这样，程序就可以使用更多安全服务来满足特定的需求。(2)第三方库或协议支持：有些第三方库或协议可能需要特定的加密、签名或认证机制。通过添加相应安全提供程序，可以为这些库或协议提供所需的支持，确保程序能够与它们进行兼容性的交互。(3)安全策略和规范：在某些情况下，出于安全策略和规范的考虑，需要使用特定的安全提供程序来确保符合特定的安全要求。通过添加这些提供程序，可以实施和遵循特定的安全标准。 设置默认的未捕获异常处理器：当发生未捕获异常时，使用注册的异常处理器进行处理，即在控制台输出异常信息。 设置代理：因为用户可以通过命令行参数设置代理服务器，代码比较简单，就不展开讲解了，知道是做什么就行了。 更新加载的类：又去把一堆类加载进来，核心还是调用 NewDriver.addURL(path); 方法。此处不展开讲解。 设置几个属性：设置开始时间，开始日期，以及开始的时分秒，但是感觉没啥鸟用，连注释都写了：Set some (hopefully!) useful properties，意思就是希望这几个参数你能用得上。 3.Jmeter 真正的启动 首先，判断用户有没有使用 -s 参数，如果用了这个参数，则使用 Server 模式启动。下面还有个 startOptionalServers(); 方法，其实不管是哪种启动方式，都会执行这个方法，它的作用就是根据配置启动可选的 Beanshell 服务器和 Mirror 服务器。Beanshell 服务器提供了自定义逻辑的执行能力，而 Mirror 服务器则用于模拟外部服务器行为。通过这些服务器，用户可以在测试期间执行自定义逻辑和模拟环境，以满足特定的测试需求。 接下来判断是否使用了 -t 和 -g 两个参数，-t 用来指定 jmx 文件，-g 用来生成报告。注意，此时并没有真的把 jmx 文件加载进 Jmeter，更没有生成报告，只是做了参数的赋值操作。 继续判断是否使用了 -n 参数，如果没有使用这个参数，则会启动图形界面。在启动图形界面前，会先调用PluginManager.install(this, true);方法来加载插件，还记得之前讲过Jmeter 实现了JMeterPlugin 接口么？作用就在此处体现了，要去加载 Jmeter 的图标和其他的资源文件。然后就会真正的启动 GUI 了，同时会在控制台打印一段熟悉的内容此时，Jmeter 通过图形界面真正的启动了，当然如果你在启动前指定了 jmx 文件，那么 Jmeter 打开之后，就会默认加载这个文件，否则就是默认新建 TestPlan 的页面。 如果用户使用了 -n 参数，则说明要使用 NON-GUI 启动。启动流程也很简单，先检查下几个文件夹能不能正常写入，比如通过 -o 参数指定的报告文件夹，Jmeter 默认的报告输出文件夹等。然后就是检查是否通过 -R 指定了远程执行的机器，通过 -t 生成 jtl 文件，再检查使用了 -e 参数之后，-t 参数是不是为 null，如果没有指定要生成 jtl 文件，但是要求生成报告的话，则会抛异常，因为 Jmeter 的报告就是通过解析 jtl 文件得到的，具体是怎么生成的，会在后面的章节中跟大家探讨。最后调用 startNonGui()方法来启动无界面模式的 Jmeter。 4.总结至此，让我们通过一张图来了解下 Jmeter 的启动过程 此时，Jmeter 算是真正的启动起来了，因为 GUI 模式启动涉及到大量关于 Java Swing 的内容，不在本文章讨论范围内，我会主要从 NON-GUI 模式来跟大家讲解 Jmeter 的运行原理，因为两种模式本质上都是通过 Jmeter 执行引擎来实现测试的。下一章开始，我们将继续深入了解使用无界面模式启动后，Jmeter 是如何开始测试的…","categories":[],"tags":[{"name":"Jmeter源码系列","slug":"Jmeter源码系列","permalink":"https://linvaux.github.io/tags/Jmeter%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/"}]},{"title":"Jmeter源码系列(2) - Jmeter 类详解-命令行参数处理CLOptionDescriptor","slug":"Jmeter源码系列-2-Jmeter-类详解-命令行参数处理CLOptionDescriptor","date":"2023-07-08T14:06:03.000Z","updated":"2024-09-21T00:59:08.933Z","comments":true,"path":"posts/ebfc10d8/","permalink":"https://linvaux.github.io/posts/ebfc10d8/","excerpt":"","text":"上一篇我们详细了解了 Jmeter 的启动类 NewDriver，知道了 NewDriver 会通过反射调用 Jmeter.start(String[] args)方法来启动 Jmeter，今天我们来分析下，Jmeter这个类内部到底做了什么。本篇章不会直接开始讲 start 方法，而是会先讲一下 Jmeter 类里面设置的 static 变量，因为这些变量会影响 jmeter 启动时的一些行为。 Jmeter 类的作用Jmeter类位于 org.apache.jmeter 包下，通过类注释可以了解到它的作用 123/** * Main JMeter class; processes options and starts the GUI, non-GUI or server as appropriate. */ Jmeter.class 是 Jmeter 的主要类，是为了让 Jmeter 通过 GUI，NON-GUI 或者server模式启动。通过我们使用 Jmeter 工具也能发现，Jmeter 正常情况下启动会有用户界面，方便我们编写 jmx 脚本或者调试 jmx 脚本。但是也可以通过 jmeter -n 模式来启动命令行模式(此处应该是无界面模式更合适)执行 jmx 脚本，并且在 Jmeter 启动时，console 里面也会打印如下内容： 12345678================================================================================Don&#x27;t use GUI mode for load testing !, only for Test creation and Test debugging.For load testing, use CLI Mode (was NON GUI): jmeter -n -t [jmx file] -l [results file] -e -o [Path to web report folder]&amp; increase Java Heap to meet your test requirements: Modify current env variable HEAP=&quot;-Xms1g -Xmx1g -XX:MaxMetaspaceSize=256m&quot; in the jmeter batch fileCheck : https://jmeter.apache.org/usermanual/best-practices.html================================================================================ 这段内容其实包含 2 个关键内容： 调试 jmx 脚本的时候可以使用有界面模式，如果要进行测试的话，建议我们使用CLI模式，即无界面模式。 告诉用户如何配置 Jmeter 的堆内存，因为 Jmeter 本身是基于 Java 开发，也是运行在 JVM 虚拟机上的，所以如果我们进行性能测试前，可以适当调整堆内存，来防止测试过程中发生 OOM 等异常。 除了有界面和无界面两种启动模式，Jmeter 还有一种server模式，即集群模式。Jmeter 本身是支持分布式压测的，当单机的并发能力存在瓶颈的时候，可以通过配置 slave 节点来实现分布式压测，这个时候，Jmeter 就是以 server 模式启动的。 Jmeter 中的 CLOptionDescriptor打开 org.apache.jmeter.Jmeter.java 源码，我们会发现，这个类内部定义了几十个静态变量，而且这个类还实现了一个 JMeterPlugin 接口。我们先看JMeterPlugin接口，此接口内部只有两个方法 String[][] getIconMappings(); String[][] getResourceBundles(); 第一个 getIconMappings() 方法用于获取插件中的图标映射信息。返回一个二维字符串数组，每个数组元素包含两个字符串：图标名称和图标文件的路径。这些图标文件可以用于在 JMeter 用户界面中显示插件的图标。通过实现 getIconMappings() 方法并返回相应的图标映射，插件可以将自定义的图标与插件相关联，并在 JMeter 中展示出来，以提供更好的用户体验和可视化效果。我们使用 Jmeter 的时候就能发现，每个组件前面都会带个小图标，就是通过这个方法来去加载这些图标的。 第二个 getResourceBundles() 其实更容易理解，如果大家开发过 web 项目，知道 resourceBundles 是啥，没错，就是用来做国际化的。这个方法用于获取插件中的资源绑定信息。返回一个二维字符串数组，每个数组元素包含两个字符串：资源包的基本名称和资源包的位置。资源包是包含本地化文本消息、错误消息、标签等的文件集合，用于国际化和本地化插件的用户界面。通过实现 getResourceBundles() 方法并返回相应的资源绑定信息，插件可以实现多语言支持，并根据用户的语言环境动态加载适当的本地化资源。 接下来，我们看下 Jmeter 中定义了这么多变量有啥用，当然，我不会把每个变量都解释一遍，只会对关键部分做解释说明。在这些变量中，有很多变量是类似于以下这种： 1private static final int REMOTE_OPT_PARAM = &#x27;R&#x27;; 大家要注意，这个变量类型是 int，并不是 char，因为这个变量其实是代表了’R’的 ASCII 编码值（十进制数）也就是：82。这种做法是为了提高代码的可读性和可维护性。通过使用命名的常量，代码的其他部分可以直接使用 REMOTE_OPT_PARAM 来表示这个特定的值，而不是使用硬编码的字符 ‘R’ 或数字 82。这样，如果将来需要更改这个值，只需修改常量的定义即可，而不需要对代码中所有引用到这个值的地方进行修改。 这种定义的变量，会被一个叫 CLOptionDescriptor 的类解析，我们先看下这个类它的作用是什么，其实第一眼看到这个类名的时候，就能大概猜出来，这是用来解析命令行参数的。它其实是 Apache Commons CLI 库中的一个类，作用就是解析命令行参数，提供了定义选项的名称、别名、描述、参数属性和行为的方法。这个类具体的作用如下： 描述选项的名称和别名：CLOptionDescriptor 允许您定义选项的名称、短名称和长名称等标识符。通过这些标识符，您可以在命令行中识别并指定特定的选项。 指定选项的描述信息：CLOptionDescriptor 允许您为选项提供文本描述或帮助信息，以帮助用户理解该选项的作用和用法。 指定选项的参数属性：CLOptionDescriptor 可以定义选项是否需要参数以及参数的类型。它支持定义选项是否需要参数、参数的最少和最多出现次数、参数的默认值等属性。 配置选项的行为：CLOptionDescriptor 提供了一些方法来配置选项的行为。例如，您可以定义选项是否为必需选项、是否允许多次使用、是否支持可变参数数量等。 所以，这个类的作用，就是在 CLI 模式下，解析参数用的。比如当我们使用命令 1jmeter -h 就可以看到以下输出： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 _ ____ _ ____ _ _ _____ _ __ __ _____ _____ _____ ____ / \\ | _ \\ / \\ / ___| | | | ____| | | \\/ | ____|_ _| ____| _ \\ / _ \\ | |_) / _ \\| | | |_| | _| _ | | |\\/| | _| | | | _| | |_) | / ___ \\| __/ ___ \\ |___| _ | |___ | |_| | | | | |___ | | | |___| _ &lt;/_/ \\_\\_| /_/ \\_\\____|_| |_|_____| \\___/|_| |_|_____| |_| |_____|_| \\_\\ 5.4.1Copyright (c) 1999-2021 The Apache Software FoundationTo list all command line options, open a command prompt and type:jmeter.bat(Windows)/jmeter.sh(Linux) -?--------------------------------------------------To run Apache JMeter in GUI mode, open a command prompt and type:jmeter.bat(Windows)/jmeter.sh(Linux) [-p property-file]--------------------------------------------------To run Apache JMeter in NON_GUI mode:Open a command prompt (or Unix shell) and type:jmeter.bat(Windows)/jmeter.sh(Linux) -n -t test-file [-p property-file] [-l results-file] [-j log-file]--------------------------------------------------To run Apache JMeter in NON_GUI mode and generate a report at end :Open a command prompt (or Unix shell) and type:jmeter.bat(Windows)/jmeter.sh(Linux) -n -t test-file [-p property-file] [-l results-file] [-j log-file] -e -o [Path to output folder]--------------------------------------------------To generate a Report from existing CSV file:Open a command prompt (or Unix shell) and type:jmeter.bat(Windows)/jmeter.sh(Linux) -g [csv results file] -o [path to output folder (empty or not existing)]--------------------------------------------------To tell Apache JMeter to use a proxy server:Open a command prompt and type:jmeter.bat(Windows)/jmeter.sh(Linux) -H [your.proxy.server] -P [your proxy server port]---------------------------------------------------To run Apache JMeter in server mode:Open a command prompt and type:jmeter-server.bat(Windows)/jmeter-server(Linux)--------------------------------------------------- 那么这些输出是哪里来的呢？很明显不是 CLOptionDescriptor 打印的，因为这个类的作用就是解析长短参数，还有参数提示，并不会给出命令执行的结果，我们翻一下代码就能看到，其实这个命令的结果是被 Jmeter 处理之后返回的这段代码就在 Jmeter.start(String[] args) 方法中，判断了参数列表是不是包含 ‘h’,然后打印了 org&#x2F;apache&#x2F;jmeter&#x2F;help.txt 这个文件的内容，我们也可以打开这个文件，看下内容是不是一样的我们可以看到，打印内容基本一致，但是少了一个 banner 图，那是因为 banner 图是在上面的 displayAsciiArt()方法中打印的，我们也可以顺便看下这段打印 banner 的代码： 1234567891011private void displayAsciiArt() &#123; try (InputStream inputStream = JMeter.class.getResourceAsStream(&quot;jmeter_as_ascii_art.txt&quot;)) &#123; if(inputStream != null) &#123; String text = IOUtils.toString(inputStream, StandardCharsets.UTF_8); System.out.println(text);//NOSONAR &#125; &#125; catch (Exception e1) &#123; //NOSONAR No logging here System.out.println(JMeterUtils.getJMeterCopyright());//NOSONAR System.out.println(&quot;Version &quot; + JMeterUtils.getJMeterVersion());//NOSONAR &#125; &#125; 代码其实很简单，就是读了一个文件，然后输出到控制台，仅此而已。所以，综上所述，Jmeter 这个类，内部的静态变量其实就是在解析命令行参数，最后这些参数会被存储在 CLOptionDescriptor[] options 对象中，这个 option 对象非常重要，因为在 jmeter 真正启动前，会从 option 中获取好几个参数，来决定使用何种启动方式。 Jmeter 支持的命令行参数 短命令 长命令 说明 -h --help 显示帮助信息。 -v --version 显示 JMeter 版本信息。 -n --nongui 以非 GUI （无界面）模式运行 JMeter。 -t &lt;文件名&gt; --testfile &lt;文件名&gt; 指定要执行的 JMX 测试计划文件。 -l &lt;文件名&gt; --logfile &lt;文件名&gt; 指定测试结果的日志文件名。 -j &lt;文件名&gt; --jmeterlogfile &lt;文件名&gt; 指定 JMeter 的日志文件名。 -r --runremote 以远程方式运行测试计划，用于分布式测试。 -R &lt;远程主机列表&gt; --remotestart &lt;远程主机列表&gt; 通过指定远程主机列表，以分布式方式运行测试计划。 -G &lt;属性文件&gt; --globalproperties &lt;属性文件&gt; 指定全局属性文件。 -D &lt;name&gt;=&lt;value&gt; --systemproperty &lt;name&gt;=&lt;value&gt; 设置额外的系统属性。 -S --systemPropertiesFile &lt;文件名&gt; 指定系统属性文件。 -P &lt;name&gt;=&lt;value&gt; --jmeterproperty &lt;name&gt;=&lt;value&gt; 设置 JMeter 属性值。此处参数是小写 -H &lt;代理主机&gt; --proxyHost &lt;代理主机&gt; 指定代理服务器的主机名。 -P &lt;代理端口&gt; --proxyPort &lt;代理端口&gt; 指定代理服务器的端口号。此处参数是大写 -N &lt;非代理的主机列表&gt; --nonProxyHosts &lt;非代理的主机列表&gt; 指定不需要代理的主机。 -X --remoteexit 告知远程服务器在测试结束后退出。 -H --help-report 显示关于报告生成的帮助信息。 -L --loglevel 指定 JMeter 日志的级别。 -q &lt;属性文件&gt; --addprop &lt;属性文件&gt; 指定要加载的其他 JMeter 属性文件。 -s --server 以服务器模式运行 JMeter 使用 JMeter 远程实例。 -f --forceDeleteResultFile 在运行之前强制删除已存在的测试结果文件。 -i --ignorelineendings 忽略测试计划文件中的行结束标记。 -H --useSystemProxy 使用系统代理设置。 后面一章正式讲解 Jmeter.start(String[] args) 方法。","categories":[],"tags":[{"name":"Jmeter源码系列","slug":"Jmeter源码系列","permalink":"https://linvaux.github.io/tags/Jmeter%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/"}]},{"title":"Jmeter源码系列(1)-NewDriver类详解-Jmeter 的启动器","slug":"Jmeter源码系列-1-NewDriver类详解-Jmeter-的启动器","date":"2023-07-07T15:04:18.000Z","updated":"2024-09-21T00:59:08.932Z","comments":true,"path":"posts/69241c26/","permalink":"https://linvaux.github.io/posts/69241c26/","excerpt":"","text":"写在前面的话Jmeter 全称（Apache JMeter）是一个开源的、功能强大的性能测试工具，用于对各种应用程序和协议进行功能、负载、压力和性能测试。它被广泛应用于软件开发和计划阶段，以确保应用程序在各种负载情况下的稳定性和可靠性。本系列将从 Jmeter 代码层面陆续剖析其实现原理，包括但不限于 Jmeter 设计思路，Jmeter 核心对象&#x2F;接口&#x2F;方法。如有错误，敬请指正！ NewDriverNewDriver 是 org.apache.jmeter 包下的一个类，如下是 NewDriver 源码中的类说明 123/** * Main class for JMeter - sets up initial classpath and the loader. */ 从这个说明中，我们可以知道，这个类提供了 2 个主要功能： 初始化 classpath 初始化一个 loader, 这个 loader 其实就是一个动态类加载器 以下内容摘抄自 NewDriver 源码，在源码中会使用注释来说明关键代码的作用，最后也会做总结，让我们开始吧 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public final class NewDriver &#123; /** * 定义一堆常量，会在 static 代码块中使用 */ private static final String CLASSPATH_SEPARATOR = File.pathSeparator; private static final String OS_NAME = System.getProperty(&quot;os.name&quot;); private static final String OS_NAME_LC = OS_NAME.toLowerCase(java.util.Locale.ENGLISH); private static final String JAVA_CLASS_PATH = &quot;java.class.path&quot;; private static final String JMETER_LOGFILE_SYSTEM_PROPERTY = &quot;jmeter.logfile&quot;; private static final String HEADLESS_MODE_PROPERTY = &quot;java.awt.headless&quot;; /** * 动态类加载器，继承自 URLClassLoader，提供了一个静态方法 updateLoader(URL [] urls) 实现了动态加载 jar * 的功能。 */ private static final DynamicClassLoader loader; private static final String JMETER_INSTALLATION_DIRECTORY; private static final List&lt;Exception&gt; EXCEPTIONS_IN_INIT = new ArrayList&lt;&gt;(); static &#123; final List&lt;URL&gt; jars = new ArrayList&lt;&gt;(); /** * 启动时从 jvm 获取 classpath */ final String initiaClasspath = System.getProperty(JAVA_CLASS_PATH); String tmpDir; /** * 按照指定标记符来分割给定的字符串，但是 StringTokenizer 是一个遗留类，出于兼容性原因而保留，建议使用 String 的拆分方法或 java.util.regex 包。 * 顺便说一下，Jmeter 源码中会包含非常多的过时的方法或者写法，有些是因为 Jmeter 本身开发较早，当时的 jdk 版本没有我们常用的新方法， * 有些则是因为当时 jdk 早期版本存在 bug，jmeter 会使用另一种写法来规避这些 bug，当然，现在这些 bug 可能已经修复了，不过 jmeter 的源码中 * 任然会保留这部分注释 */ StringTokenizer tok = new StringTokenizer(initiaClasspath, File.pathSeparator); /** * 对 mac 系统做了单独的判断，我也没有深究为啥要单独处理，不晓得现在还需不需要这么写 */ if (tok.countTokens() == 1|| (tok.countTokens() == 2 &amp;&amp; OS_NAME_LC.startsWith(&quot;mac os x&quot;))) &#123; File jar = new File(tok.nextToken()); try &#123; tmpDir = jar.getCanonicalFile().getParentFile().getParent(); &#125; catch (IOException e) &#123; tmpDir = null; &#125; &#125; else &#123; /** * 从 jvm 获取 jmeter.home 属性，没有的话就默认从环境变量 JMETER_HOME 取值，当然这个值也不一定有，因为不是所有人都会配置 JMETER_HOME 这个环境变量 * 其实从这边开始，大家就会发现，Jmeter 会经常使用 System.getProperty 来获取一些属性，在后面的代码中我们也会经常见到这样的代码 */ tmpDir = System.getProperty(&quot;jmeter.home&quot;, System.getenv(&quot;JMETER_HOME&quot;)); if (tmpDir == null || tmpDir.length() == 0) &#123; File userDir = new File(System.getProperty(&quot;user.dir&quot;)); tmpDir = userDir.getAbsoluteFile().getParent(); &#125; &#125; if (tmpDir == null) &#123; tmpDir = System.getenv(&quot;JMETER_HOME&quot;); &#125; JMETER_INSTALLATION_DIRECTORY = tmpDir; boolean usesUNC = OS_NAME_LC.startsWith(&quot;windows&quot;); StringBuilder classpath = new StringBuilder(); /** * 下面的几个目录大家就很眼熟了，就是 Jmeter 解压后，主目录下的文件夹，里面都是 Jmeter 可能用到的一些 jar 包 */ File[] libDirs = new File[] &#123; new File(JMETER_INSTALLATION_DIRECTORY + File.separator + &quot;lib&quot;), new File(JMETER_INSTALLATION_DIRECTORY + File.separator + &quot;lib&quot; + File.separator + &quot;ext&quot;), new File(JMETER_INSTALLATION_DIRECTORY + File.separator + &quot;lib&quot; + File.separator + &quot;junit&quot;)&#125;; for (File libDir : libDirs) &#123; File[] libJars = libDir.listFiles((dir, name) -&gt; name.endsWith(&quot;.jar&quot;)); if (libJars == null) &#123; new Throwable(&quot;Could not access &quot; + libDir).printStackTrace(); continue; &#125; /** * 不晓得为啥要排个序 */ Arrays.sort(libJars); for (File libJar : libJars) &#123; try &#123; String s = libJar.getPath(); if (usesUNC) &#123; if (s.startsWith(&quot;\\\\\\\\&quot;) &amp;&amp; !s.startsWith(&quot;\\\\\\\\\\\\&quot;)) &#123; s = &quot;\\\\\\\\&quot; + s; &#125; else if (s.startsWith(&quot;//&quot;) &amp;&amp; !s.startsWith(&quot;///&quot;)) &#123; s = &quot;//&quot; + s; &#125; &#125; jars.add(new File(s).toURI().toURL()); classpath.append(CLASSPATH_SEPARATOR); classpath.append(s); &#125; catch (MalformedURLException e) &#123; EXCEPTIONS_IN_INIT.add(new Exception(&quot;Error adding jar:&quot;+libJar.getAbsolutePath(), e)); &#125; &#125; &#125; System.setProperty(JAVA_CLASS_PATH, initiaClasspath + classpath.toString()); /** * 类加载器会加载扫描到的这些 jar 包，为 Jmeter 真正启动做好准备 */ loader = AccessController.doPrivileged( (PrivilegedAction&lt;DynamicClassLoader&gt;) () -&gt; new DynamicClassLoader(jars.toArray(new URL[jars.size()])) ); &#125;&#125; 从上面的代码中，我们可以看到，NewDriver 在实例化时，会执行一个静态代码块，主要作用就是加载 Jmeter 安装目录下的 jar 包。 Main方法介绍下面介绍 NewDriver 的 main 方法，这个方法就是整个 Jmeter 启动的入口方法。 1234567891011121314151617181920212223242526272829303132333435363738394041public static void main(String[] args) &#123; /** * 检查初始化是不是报错了 */ if(!EXCEPTIONS_IN_INIT.isEmpty()) &#123; System.err.println(&quot;Configuration error during init, see exceptions:&quot;+exceptionsToString(EXCEPTIONS_IN_INIT)); &#125; else &#123; /** * 设置当前线程的类加载器，也就是 Jmeter 自己写的那个动态类加载器 */ Thread.currentThread().setContextClassLoader(loader); /** * 配置一些日志属性，不重要 */ setLoggingProperties(args); try &#123; /** * 判断要不要用 GUI 模式启动，默认 true，也可以通过 Jmeter 命令行参数 -n 来指定使用非 GUI 模式启动 */ if(System.getProperty(HEADLESS_MODE_PROPERTY) == null &amp;&amp; shouldBeHeadless(args)) &#123; System.setProperty(HEADLESS_MODE_PROPERTY, &quot;true&quot;); &#125; /** * 获取 Jmeter 类，作用类似于 Class.forName(String clazzName) */ Class&lt;?&gt; initialClass = loader.loadClass(&quot;org.apache.jmeter.JMeter&quot;); /** * 获取 Jmeter 实例 */ Object instance = initialClass.getDeclaredConstructor().newInstance(); /** * 获取 Jmeter.start方法，并调用 */ Method startup = initialClass.getMethod(&quot;start&quot;, new Class[] &#123; new String[0].getClass() &#125;); startup.invoke(instance, new Object[] &#123; args &#125;); &#125; catch(Throwable e)&#123; e.printStackTrace(); System.err.println(&quot;JMeter home directory was detected as: &quot;+JMETER_INSTALLATION_DIRECTORY); &#125; &#125; &#125; main 方法其实很简单直接，就是看下是不是要启动 GUI，然后就是通过反射调用 Jmeter 的 start 方法，来开始测试。综上，NewDriver 其实就是一个启动器，正如其所在源码模块 launcher 一样，他的作用就是为 Jmeter 真正启动做好准备。好了，NewDriver 就介绍完了，下一章将介绍 Jmeter 这个核心类，以及调用其 start(String[] args) 之后会发生什么…","categories":[],"tags":[{"name":"Jmeter源码系列","slug":"Jmeter源码系列","permalink":"https://linvaux.github.io/tags/Jmeter%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/"}]},{"title":"Jdk11获取系统信息","slug":"Jdk11获取系统信息","date":"2023-06-08T14:01:20.000Z","updated":"2024-09-21T00:59:08.931Z","comments":true,"path":"posts/caf2f46/","permalink":"https://linvaux.github.io/posts/caf2f46/","excerpt":"","text":"下面用到的 api 仅在 jdk11 上测试通过，其他 jdk 版本没试过 工具类 SystemInfoUtils.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132import com.demo.constant.SystemInfoConstant;import com.sun.management.OperatingSystemMXBean;import lombok.extern.slf4j.Slf4j;import java.lang.management.ManagementFactory;import java.net.InetAddress;import java.net.NetworkInterface;import java.nio.file.*;import java.text.DecimalFormat;import java.util.ArrayList;import java.util.Enumeration;import java.util.List;import java.util.stream.Collectors;/** * @description: 系统信息工具类 */@Slf4jpublic class SystemInfoUtils &#123; /** * 获取本地IP地址 * @return 本机 ip，过滤了回环地址和 localhost */ public static List&lt;String&gt; getLocalIP() &#123; List&lt;String&gt; ipList = new ArrayList&lt;&gt;(); try &#123; // 获取本地所有网络接口 Enumeration&lt;NetworkInterface&gt; networkInterfaces = NetworkInterface.getNetworkInterfaces(); while (networkInterfaces.hasMoreElements()) &#123; NetworkInterface networkInterface = networkInterfaces.nextElement(); // 排除虚拟接口和未启用的接口 if (networkInterface.isVirtual() || !networkInterface.isUp()) &#123; continue; &#125; Enumeration&lt;InetAddress&gt; inetAddresses = networkInterface.getInetAddresses(); while (inetAddresses.hasMoreElements()) &#123; InetAddress inetAddress = inetAddresses.nextElement(); if (!inetAddress.isLinkLocalAddress()) &#123; ipList.add(inetAddress.getHostAddress()); &#125; &#125; &#125; &#125; catch (Exception e) &#123; log.error(&quot;本机 IP 获取失败, 异常详情: &quot; + ExceptionUtil.getErrorMessage(e)); &#125; return ipList.stream().filter(e -&gt; !SystemInfoConstant.INVALID_IP_LIST.contains(e)).collect(Collectors.toList()); &#125; /** * 获取CPU数量 * @return 逻辑处理器数量，物理核数 * 2 */ public static int getCpuCount() &#123; // 此处有坑，OperatingSystemMXBean 存在于两个包：java.lang.management.OperatingSystemMXBean 和 com.sun.management.OperatingSystemMXBean // 一定要找对包，不然有些方法找不到，太特么坑了 java.lang.management.OperatingSystemMXBean operatingSystemMXBean = ManagementFactory.getOperatingSystemMXBean(); return operatingSystemMXBean.getAvailableProcessors(); &#125; /** * 获取总内存大小 * @return 物理内存大小 */ public static String getTotalPhysicalMemory() &#123; OperatingSystemMXBean osBean = ManagementFactory.getPlatformMXBean(OperatingSystemMXBean.class); long physicalMemorySize = osBean.getTotalPhysicalMemorySize(); double physicalMemoryGB = (double) physicalMemorySize / 1024 / 1024 / 1024; DecimalFormat decimalFormat = new DecimalFormat(&quot;#.##&quot;); return decimalFormat.format(physicalMemoryGB) + &quot;GB&quot;; &#125; /** * 获取磁盘总大小 * @return 磁盘总量 */ public static String getDiskSizeTotal() &#123; String diskSize = null; try &#123; Path rootDir = Paths.get(&quot;/&quot;); FileStore store = Files.getFileStore(rootDir); long totalSpace = store.getTotalSpace(); double totalGB = (double) totalSpace / 1024 / 1024 / 1024; DecimalFormat decimalFormat = new DecimalFormat(&quot;#.##&quot;); diskSize = decimalFormat.format(totalGB + &quot;GB&quot;); &#125; catch (Exception e) &#123; log.error(&quot;磁盘信息获取失败, 异常详情: &#123;&#125;&quot;, ExceptionUtil.getErrorMessage(e)); &#125; return diskSize; &#125; /** * 获取已使用磁盘大小 * @return 磁盘已使用量 */ public static String getDiskSizeUsed() &#123; String diskSize = null; try &#123; Path rootDir = Paths.get(&quot;/&quot;); FileStore store = Files.getFileStore(rootDir); long usableSpace = store.getUsableSpace(); double usableGB = (double) usableSpace / 1024 / 1024 / 1024; DecimalFormat decimalFormat = new DecimalFormat(&quot;#.##&quot;); diskSize = decimalFormat.format(usableGB + &quot;GB&quot;); &#125; catch (Exception e) &#123; log.error(&quot;磁盘信息获取失败, 异常详情: &#123;&#125;&quot;, ExceptionUtil.getErrorMessage(e)); &#125; return diskSize; &#125; /** * 获取可用磁盘大小 * @return 磁盘可使用量 */ public static String getDiskSizeFree() &#123; String diskSize = null; try &#123; Path rootDir = Paths.get(&quot;/&quot;); FileStore store = Files.getFileStore(rootDir); long freeSpace = store.getUnallocatedSpace(); double freeGB = (double) freeSpace / 1024 / 1024 / 1024; DecimalFormat decimalFormat = new DecimalFormat(&quot;#.##&quot;); diskSize = decimalFormat.format(freeGB + &quot;GB&quot;); &#125; catch (Exception e) &#123; log.error(&quot;磁盘信息获取失败, 异常详情: &#123;&#125;&quot;, ExceptionUtil.getErrorMessage(e)); &#125; return diskSize; &#125;&#125; 常量类 SystemInfoConstant.java1234567891011121314151617181920212223242526import java.util.List;/** * @description: 系统信息常量 */public class SystemInfoConstant &#123; /** * ipv4 回环地址 */ public static final String IPV4_LOOP_ADDRESS = &quot;0.0.1.1&quot;; /** * ipv6 回环地址 */ public static final String IPV6_LOOP_ADDRESS = &quot;0:0:0:0:0:0:0:1%lo0&quot;; /** * 本机 IP */ public static final String LOCAL_HOST = &quot;127.0.0.1&quot;; /** * 无效的 ip 地址列表，需要排除 */ public static final List&lt;String&gt; INVALID_IP_LIST = List.of(IPV4_LOOP_ADDRESS, IPV6_LOOP_ADDRESS, LOCAL_HOST); 异常信息获取工具类 ExceptionUtil.java123456789101112131415161718192021222324252627282930import org.springframework.util.StringUtils;import java.io.PrintWriter;import java.io.StringWriter;/** * @description: 异常工具类 */public class ExceptionUtil &#123; /** * 异常信息允许的最大长度，超过这个长度会被截取 */ private static final Integer ERROR_MSG_MAX_LENGTH = 2000; /** * 获取异常的堆栈信息 * * @param e 异常对象 * @return 堆栈信息 */ public static String getErrorMessage(Exception e) &#123; if (StringUtils.hasText(e.getMessage())) &#123; return e.getMessage(); &#125; StringWriter sw = new StringWriter(); e.printStackTrace(new PrintWriter(sw, Boolean.TRUE)); String message = sw.toString(); return message.length() &gt; ERROR_MSG_MAX_LENGTH ? message.substring(0, ERROR_MSG_MAX_LENGTH) : message; &#125;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://linvaux.github.io/tags/Java/"}]},{"title":"Mac使用Jenv实现Jdk多版本管理","slug":"Mac使用Jenv实现Jdk多版本管理","date":"2023-06-06T12:53:58.000Z","updated":"2024-09-21T00:59:08.937Z","comments":true,"path":"posts/5d78b5f5/","permalink":"https://linvaux.github.io/posts/5d78b5f5/","excerpt":"","text":"前言目前在开发过程中，需要同时安装 Jdk8, Jdk11, Jdk17 进行项目开发，为了统一管理Jdk 环境，需要一款类似 conda 的工具来管理多套 Jdk 环境，可选的方案有以下几种： 使用 shell 脚本来动态设置 JAVA_HOME； 使用 scoop 来管理环境； 使用 jenv 来管理环境； 经过使用体验，最后选择了 jenv 来做 jdk 版本管理。 安装在 mac 下面可以使用 brew 来安装 jenv 1brew install jenv 我用的 zsh，因此还需要将 jenv 添加到 zsh 中 123echo &#x27;export PATH=&quot;$HOME/.jenv/bin:$PATH&quot;&#x27; &gt;&gt; ~/.zshrc# 执行 jenv 初始化脚本，类似于 conda init 命令echo &#x27;eval &quot;$(jenv init -)&quot;&#x27; &gt;&gt; ~/.zshrc 配置1.添加在本地已经安装的 jdk123jenv add /Library/Java/JavaVirtualMachines/jdk-17.0.5.jdk/Contents/Home/jenv add /Library/Java/JavaVirtualMachines/jdk1.8.0_301.jdk/Contents/Home/jenv add /Library/Java/JavaVirtualMachines/jdk-11.0.11.jdk/Contents/Home/ 2.列出已经添加的 jdk 版本1jenv versions 3.设置 jdk 的三种方式 jenv local ：该命令将会在当前目录下设置特定的 Java 版本。这意味着只有在该目录下执行程序调用时才会使用该版本的 Java。 jenv global ：该命令将会设置系统全局的 Java 版本。当在终端或其它地方运行 Java 应用程序时，都将使用该版本的 Java。 jenv shell ：该命令将会在当前 Shell 会话中设置特定的 Java 版本。这意味着只有在该 Shell 会话中执行程序调用时才会使用该版本的 Java。 因此，这三个命令的主要区别在于设置 Java 版本的作用域和范围。jenv local 的作用域仅限于当前工作目录，jenv global 的作用域与操作系统全局环境相关，而 jenv shell 的作用域仅限于当前 Shell 会话。因此，根据具体情况选择使用不同的命令。需要注意的是，jenv 只对使用 jenv exec 执行的命令生效，对于直接使用 java 命令执行的程序，jenv 并不会自动切换 Java 版本。因此，需要手动设置系统环境变量或使用别的工具来切换 Java 版本。 4.Jenv 诊断jenv doctor 是 jenv 命令行工具提供的一个诊断工具，用于检查本地系统的 Java 环境是否正确配置。当我们安装 jenv 后，需要将其配置到系统环境变量中，并安装所需的 Java 版本。使用 jenv doctor 命令可以检测配置和 Java 版本是否正确安装，并提供诊断信息和建议以解决检测出的问题。jenv doctor 常见的使用场景有： 检查 jenv 的环境变量是否正确配置。jenv 是一款基于环境变量来管理多个 Java 版本的工具，因此我们需要将其配置到系统环境变量中，并确保环境变量的正确性。 检查 jenv 的安装路径和版本号。检查 jenv 实际安装的位置以及当前所用的版本号，是否符合预期要求。 检查可用的 Java 版本是否正确安装和配置。jenv doctor 会检查本地系统环境中已经安装的 Java 版本，是否安装在了 jenv 管理的目录中，并支持在 jenv 中进行切换。 参考文档 Jenv 官方文档","categories":[],"tags":[{"name":"Mac","slug":"Mac","permalink":"https://linvaux.github.io/tags/Mac/"}]},{"title":"EasyExcel自定义字段导入","slug":"EasyExcel自定义字段导入","date":"2023-04-10T15:10:00.000Z","updated":"2024-09-21T00:59:08.920Z","comments":true,"path":"posts/baf3301c/","permalink":"https://linvaux.github.io/posts/baf3301c/","excerpt":"","text":"1.背景原先的导入功能只支持使用固定模板导入，模板格式如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Getter@Setter@ToStringpublic class TestCaseExcelData &#123; @ExcelProperty(value = &quot;所属功能模块&quot;) private String module; @ExcelProperty(value = &quot;用例编号&quot;) private String code; @NotBlank(message = &quot;必填项不能为空&quot;) @ExcelProperty(value = &quot;*用例名称&quot;) private String name; @NotBlank(message = &quot;必填项不能为空&quot;) @ExcelProperty(value = &quot;*优先级&quot;) private String caseLevel; @NotBlank(message = &quot;必填项不能为空&quot;) @ExcelProperty(value = &quot;*用例类型&quot;) private String caseType; @ExcelProperty(value = &quot;用例标签&quot;) private String tags; @ExcelProperty(value = &quot;前置条件&quot;) private String preSteps; @NotBlank(message = &quot;必填项不能为空&quot;) @ExcelProperty(value = &quot;*操作步骤/场景描述&quot;) private String stepDesc; @NotBlank(message = &quot;必填项不能为空&quot;) @ExcelProperty(value = &quot;*预期结果&quot;) private String expectResult; @ExcelProperty(value = &quot;关联需求类型&quot;) private String requirementType; @ExcelProperty(value = &quot;关联需求ID&quot;) private String requirementId; @ExcelProperty(value = &quot;用例版本&quot;) private String caseVersion;&#125; EasyExcel 导入监听器直接使用AnalysisEventListener 即可实现导入校验，校验规则较为复杂，不在此处展开。现在要求用户配置了自定义字段之后，还可以导入自定义字段，同时保留对固定字段的校验逻辑。因此原有的适用对象的监听器不再适用，需要使用无对象的方式做数据校验。 2.问题 EasyExcel 无对象方式的监听器是继承AnalysisEventListener&lt;Map&lt;Integer, String&gt;&gt;类，在重写了invoke() 方法后发现，入参是 Map&lt;Integer, String&gt; data，这就导致我无法对每一行数据按照原有的方式校验。 用户导入的模板列顺序是不固定的，因此也没法遍历 data 进行原有规则的校验。 3.解决方案3.1 解决思路 既然 invoke() 方法入参是 Map&lt;Integer, String&gt; data 这种数据结构，那能不能把这个 Map 中固定的字段转为一个 TestCaseExcelData 对象来处理？ 如果要转为一个对象，那怎么把 Map 中的数据跟对象的字段做映射？ 3.2 Map 转对象 Map&lt;Integer, String&gt; 是当前行的数据，其中 key 是当前行的列索引，value 是当前单元格的值，如果要转对象，首先得知道这个单元格对应的表头是什么，获取表头的方式很简单，直接在 listener 中定义一个 Map&lt;Integer, String&gt; headMap ,然后重写 invokeHeadMap(Map&lt;Integer, String&gt; headMap, AnalysisContext context) 方法，即可获取到表头。 取到表头之后，就可以在 invoke(Map&lt;Integer, String&gt; data, AnalysisContext context)方法中遍历data，根据此 map 的 key 来获取到当前单元格表头信息。代码如下：1234567@Overridepublic void invoke(Map&lt;Integer, String&gt; data, AnalysisContext context) &#123; data.forEach((index, value) -&gt; &#123; // 获取表头 String headName = headMap.get(index); &#125;); &#125; 取到了当前单元格的对应的表头之后，发现这个表头就是 TestCaseExcelData 类中属性上加的 @ExcelProperty(value &#x3D; “用例版本”) 注解中 value 属性的值，那就简单了，直接通过反射获取这个类所有表头和对应的属性，然后存到一个 Map&lt;Stirng, Field&gt; fieldStringMap 中就好了，这样就能通过表头获取到这个表头字段对应的类属性，为我们后面创建对象奠定了基础。代码如下：12345678Field[] fields = TestCaseExcelData.class.getDeclaredFields();for (Field field : fields) &#123; if (field.isAnnotationPresent(ExcelProperty.class)) &#123; ExcelProperty declaredAnnotation = field.getDeclaredAnnotation(ExcelProperty.class); String headValue = declaredAnnotation.value()[0]; this.fieldStringMap.put(headValue, field); &#125;&#125; 经过上面的几步操作，我们已经得到了如下的几个Map123456// 当前行的数据 &lt;列索引, 单元格值&gt;Map&lt;Integer, String&gt; data;// 表头的数据 &lt;列索引, 单元格值&gt;Map&lt;Integer, String&gt; headMap;// 实体对象表头和对应字段的数据 &lt;表头名称, 表头对应的属性&gt;Map&lt;Stirng, Field&gt; fieldStringMap; 后面的思路经很清晰了，遍历行数据Map&lt;Integer, String&gt; data ，通过 key 来确定当前单元格对应的表头，然后通过表头来获取实体类对应的属性，再通过反射来给这个属性赋值。代码如下：1234567891011121314151617181920212223242526272829303132@Overridepublic void invoke(Map&lt;Integer, String&gt; data, AnalysisContext context) &#123; // 创建实体对象 TestCaseExcelData rawData = new TestCaseExcelData(); try &#123; data.forEach((index, value) -&gt; &#123; // 获取到当前单元格的表头 String headName = headMap.get(index); // 根据表头获取实体类的属性 Field field = fieldStringMap.get(headName); try &#123; // 判断实体类是否有此属性 if (field != null) &#123; field.setAccessible(true); // 通过反射直接赋值 field.set(rawData, value); &#125; &#125; catch (IllegalAccessException e) &#123; throw new RuntimeException(e); &#125; // 解析自定义字段，只有系统配置的字段才会被缓存 List&lt;CustomFieldPO&gt; customFieldPOS = systemCustomFieldMap.get(headName); if (CollectionUtils.isNotEmpty(customFieldPOS)) &#123; customFieldMap.put(customFieldPOS.get(0).getFieldKey(), value); &#125; &#125;); // 固定字段校验 ExcelValidateHelper.validateEntity(rawData); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; &#125; 经过以上操作，我们成功的把一个 Map 转为了一个已知的对象，这样就跟通过对象导入一样了，后面校验的代码也无需再重复编写。 4. 其他最后，附上自定义模板校验表头的代码 12345678910111213141516171819@Overridepublic void invokeHeadMap(Map&lt;Integer, String&gt; headMap, AnalysisContext context) &#123; super.invokeHeadMap(headMap, context); // 限制文件行数不超过5000行 if (context.readSheetHolder().getApproximateTotalRowNumber() &gt; 5000) &#123; throw new ServiceException(CommonException.EXCEL_ROW_EXCEEDED); &#125; // 校验excel模版是否正确 ExcelImportUtil.validateHeadLoosely(headMap, this.dynamicCaseHeader.get(0)); this.headMap = headMap; Field[] fields = TestCaseExcelData.class.getDeclaredFields(); for (Field field : fields) &#123; if (field.isAnnotationPresent(ExcelProperty.class)) &#123; ExcelProperty declaredAnnotation = field.getDeclaredAnnotation(ExcelProperty.class); String headValue = declaredAnnotation.value()[0]; this.fieldStringMap.put(headValue, field); &#125; &#125; &#125; 1234567891011121314151617181920212223242526272829303132/** * 表头宽松校验 * &lt;p&gt;只校验表头是否存在模板中的字段&lt;/p&gt; * &lt;p&gt;不允许存在重复的表头&lt;/p&gt; * &lt;p&gt;导入文件中可以包含多余的列名&lt;/p&gt; * * @param headMap 实际读到的表头 * @param expectedHeadMapFiled 期望的表头 */public static void validateHeadLoosely(Map&lt;Integer, String&gt; headMap, List&lt;String&gt; expectedHeadMapFiled) &#123; try &#123; if (CollectionUtils.isEmpty(expectedHeadMapFiled) || MapUtils.isEmpty(headMap)) &#123; throw new ServiceException(CommonException.EXCEL_TEMPLATE_IS_NOT_CORRECT); &#125; // 移除没有内容的表头 headMap.entrySet().removeIf(entry -&gt; entry.getValue() == null); // 判断是否存在重复列 Collection&lt;String&gt; headValues = headMap.values(); Set&lt;String&gt; headValuesSet = new HashSet&lt;&gt;(headValues); if (headValues.size() != headValuesSet.size()) &#123; throw new ServiceException(CommonException.EXCEL_HEADS_DUPLICATED); &#125; // 判断模板字段是否都包含在表头里 for (String value : expectedHeadMapFiled) &#123; if (!headMap.containsValue(value)) &#123; throw new ServiceException(CommonException.EXCEL_TEMPLATE_IS_NOT_CORRECT); &#125; &#125; &#125; catch (Exception e) &#123; throw new ServiceException(&quot;Excel表头校验失败，异常详情：&quot; + ExceptionUtil.getErrorMessage(e)); &#125; &#125;","categories":[],"tags":[{"name":"EasyExcel","slug":"EasyExcel","permalink":"https://linvaux.github.io/tags/EasyExcel/"}]},{"title":"Springboot业务信息国际化","slug":"Springboot业务信息国际化","date":"2023-03-27T13:43:49.000Z","updated":"2024-09-21T00:59:08.938Z","comments":true,"path":"posts/61b65b3c/","permalink":"https://linvaux.github.io/posts/61b65b3c/","excerpt":"","text":"业务背景用户上传一个 excel 文件，要对 excel 内容做校验，然后返回校验结果。校验通过之后，在执行导入。但是现在平台要做国际化，支持中英双语，目前校验结果是直接中文返回，为了完成国际化需求，需要根据请求头中的 Accept-language 来决定返回何种语言的内容。 当前处理方式 国际化方案使用工具类获取国际化内容1234567891011121314151617181920212223242526272829303132333435363738394041import org.springframework.context.MessageSource;import org.springframework.context.MessageSourceAware;import org.springframework.context.support.MessageSourceAccessor;import org.springframework.stereotype.Component;@Componentpublic class I18nMessageUtil implements MessageSourceAware &#123; private static MessageSourceAccessor accessor; /** * 获取i18n文件中对应的国际化信息 * * @param code i18n文件中code * @param locale 地区信息 * @param args 参数 * @return 国际化信息 */ public static String getMessage(String code, Locale locale, Object... args) &#123; if (locale == null) &#123; return accessor.getMessage(code, args); &#125; return accessor.getMessage(code, args, locale); &#125; /** * 获取i18n文件中对应的国际化信息,如果不传locale信息，则从当前request获取，如果还是没有，则使用默认locale * * @param code i18n文件中code * @param args 参数 * @return 国际化信息 */ public static String getMessage(String code, Object... args) &#123; return accessor.getMessage(code, args); &#125; @Override public void setMessageSource(MessageSource messageSource) &#123; I18nMessageUtil.accessor = new MessageSourceAccessor(messageSource); &#125;&#125; 配置国际化文件12345678910111213141516171819202122232425import org.springframework.context.MessageSource;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.support.ResourceBundleMessageSource;import java.util.HashSet;import java.util.Set;@Configurationpublic class I18nConfig &#123; @Bean public MessageSource messageSource() &#123; ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); Set&lt;String&gt; i18nFolder = new HashSet&lt;&gt;(); // excel 校验的国际化文件 i18nFolder.add(&quot;i18n.excelValidation&quot;); // 默认的国际化文件 i18nFolder.add(&quot;i18n.messages&quot;); messageSource.setBasenames(i18nFolder.toArray(new String[0])); messageSource.setDefaultEncoding(&quot;UTF-8&quot;); messageSource.setUseCodeAsDefaultMessage(true); return messageSource; &#125;&#125; 编写国际化异常信息 替换校验异常信息","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://linvaux.github.io/tags/Java/"}]},{"title":"EasyExcel解决自定义样式太多导致的 The maximum number of Cell Styles was exceeded 异常","slug":"EasyExcel解决自定义样式太多导致的-The-maximum-number-of-Cell-Styles-was-exceeded-异常","date":"2023-03-16T13:38:50.000Z","updated":"2024-09-21T00:59:08.921Z","comments":true,"path":"posts/b610f685/","permalink":"https://linvaux.github.io/posts/b610f685/","excerpt":"","text":"之前使用自定义样式解决了导出excel时，对不同单元格使用不同样式的需求，但是最近发现，导出大量数据时，就会产生如下异常 1java.lang.IllegalStateException: The maximum number of Cell Styles was exceeded. You can define up to 64000 style in a .xlsx Workbook 通过查看easyexcel在github上的issue可以发现，有很多人都出现了类似问题，原因是EasyExcel最多支持创建64000个样式对象。但是我写入的数据远远超过了64000，每次写入数据都会去创建一次样式对象，导致生成excel失败。错误的代码如下： 1234567891011121314151617181920public class CustomCellWriteHandler implements CellWriteHandler &#123; /** * 设置拦截器顺序，需要 &gt; 50000 * * @return 拦截器顺序 */ @Override public int order() &#123; return 60000; &#125; @Override public void afterCellDispose(CellWriteHandlerContext context) &#123; Cell cell = context.getCell(); if (BooleanUtils.isNotTrue(context.getHead())) &#123; Workbook workbook = context.getWriteWorkbookHolder().getWorkbook(); // 此处代码有问题，每次进入条件，都会重复创建一个XSSFCellStyle对象 XSSFCellStyle cellStyle = (XSSFCellStyle) workbook.createCellStyle(); &#125;&#125; 解决此问题方法也比较简单，直接使用成员变量，不再重复创建对象。改造后的代码如下 123456789101112131415161718192021222324252627public class CustomCellWriteHandler implements CellWriteHandler &#123; XSSFCellStyle cellStyle; /** * 设置拦截器顺序，需要 &gt; 50000 * * @return 拦截器顺序 */ @Override public int order() &#123; return 60000; &#125; @Override public void afterCellDispose(CellWriteHandlerContext context) &#123; Cell cell = context.getCell(); if (BooleanUtils.isNotTrue(context.getHead())) &#123; Workbook workbook = context.getWriteWorkbookHolder().getWorkbook(); if (cellStyle == null) &#123; cellStyle = (XSSFCellStyle) workbook.createCellStyle(); &#125; cellStyle.setFillPattern(FillPatternType.SOLID_FOREGROUND); &#125; &#125;&#125; 在创建新样式之前，判断下是不是已经有这个样式了，没有的话再创建，这样就避免了重复创建样式对象导致的异常。","categories":[],"tags":[{"name":"EasyExcel","slug":"EasyExcel","permalink":"https://linvaux.github.io/tags/EasyExcel/"}]},{"title":"EasyExcel自定义单元格样式","slug":"EasyExcel自定义单元格样式","date":"2023-03-12T15:09:03.000Z","updated":"2024-09-21T00:59:08.919Z","comments":true,"path":"posts/42ffd8f/","permalink":"https://linvaux.github.io/posts/42ffd8f/","excerpt":"","text":"之前在开发系统的导出功能时需要对单元格增加不同的样式，过程有点曲折，记录一下以备后续用到 创建java项目，引入以下依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt;&lt;/dependency&gt; excel 导出代码 123456789101112131415try (ExcelWriter excelWriter = EasyExcel.write(filePath).build()) &#123; WriteSheet sheet = EasyExcel.writerSheet(&quot;自定义样式&quot;) // 设置表头 .head(ExportHeaderDTO.class) // 不使用默认样式 .useDefaultStyle(Boolean.FALSE) // 添加自定义单元格样式 .registerWriteHandler(new CustomCellWriteHandler()) // 添加单元格边框样式 .registerWriteHandler(CustomHorizontalCellStyleStrategy.cellBorder()) .build(); excelWriter.write(collect, sheet); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; 自定义样式 CustomCellWriteHandler.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class CustomCellWriteHandler implements CellWriteHandler &#123; /** * 设置拦截器顺序，需要 &gt; 50000 * * @return 拦截器顺序 */ @Override public int order() &#123; return 60000; &#125; @Override public void afterCellDispose(CellWriteHandlerContext context) &#123; Cell cell = context.getCell(); if (BooleanUtils.isNotTrue(context.getHead())) &#123; Workbook workbook = context.getWriteWorkbookHolder().getWorkbook(); XSSFCellStyle cellStyle = (XSSFCellStyle) workbook.createCellStyle(); cellStyle.setFillPattern(FillPatternType.SOLID_FOREGROUND); // 设置边框粗细 cellStyle.setBorderRight(BorderStyle.THIN); cellStyle.setBorderTop(BorderStyle.THIN); cellStyle.setBorderRight(BorderStyle.THIN); cellStyle.setBorderBottom(BorderStyle.THIN); // 设置边框颜色 cellStyle.setTopBorderColor(IndexedColors.BLACK.index); cellStyle.setBottomBorderColor(IndexedColors.BLACK.index); cellStyle.setLeftBorderColor(IndexedColors.BLACK.index); cellStyle.setRightBorderColor(IndexedColors.BLACK.index); cellStyle.setFillPattern(FillPatternType.SOLID_FOREGROUND); // 水平居中 cellStyle.setAlignment(HorizontalAlignment.CENTER); // 垂直居中 cellStyle.setVerticalAlignment(VerticalAlignment.CENTER); Font font = workbook.createFont(); if (cell.getColumnIndex() == 1) &#123; // 设置字体颜色 font.setColor(IndexedColors.DARK_TEAL.index); cellStyle.setFont(font); // 设置单元格颜色 cellStyle.setFillForegroundColor(new XSSFColor(ColorConstant.CustomColor.PINK, CustomIndexedColorMap.fromColors(CTColors.Factory.newInstance()))); cell.setCellStyle(cellStyle); // 这里要把 WriteCellData的样式清空， 不然后面还有一个拦截器 FillStyleCellWriteHandler 默认会将 WriteCellStyle 设置到cell里面去 会导致自己设置的不一样（很关键） context.getFirstCellData().setWriteCellStyle(null); &#125; &#125; &#125;&#125; 边框样式 CustomHorizontalCellStyleStrategy.java 12345678910111213141516171819202122232425public class CustomHorizontalCellStyleStrategy extends HorizontalCellStyleStrategy &#123; @Override public int order() &#123; return 6500; &#125; /** * 设置单元格边框 * @return 样式策略 */ public static HorizontalCellStyleStrategy cellBorder() &#123; WriteCellStyle headWriteCellStyle = new WriteCellStyle(); headWriteCellStyle.setTopBorderColor(IndexedColors.BLACK.index); headWriteCellStyle.setBottomBorderColor(IndexedColors.BLACK.index); headWriteCellStyle.setLeftBorderColor(IndexedColors.BLACK.index); headWriteCellStyle.setRightBorderColor(IndexedColors.BLACK.index); headWriteCellStyle.setFillPatternType(FillPatternType.SOLID_FOREGROUND); WriteCellStyle contentWriteCellStyle = new WriteCellStyle(); contentWriteCellStyle.setBorderRight(BorderStyle.THIN); contentWriteCellStyle.setBorderTop(BorderStyle.THIN); contentWriteCellStyle.setBorderRight(BorderStyle.THIN); contentWriteCellStyle.setBorderBottom(BorderStyle.THIN); return new HorizontalCellStyleStrategy(headWriteCellStyle, contentWriteCellStyle); &#125;&#125;","categories":[],"tags":[{"name":"EasyExcel","slug":"EasyExcel","permalink":"https://linvaux.github.io/tags/EasyExcel/"}]},{"title":"Pytest参数","slug":"Pytest参数","date":"2023-03-12T14:40:14.000Z","updated":"2024-09-21T00:59:08.938Z","comments":true,"path":"posts/4938c154/","permalink":"https://linvaux.github.io/posts/4938c154/","excerpt":"","text":"分类 参数 作用 general -k 支持python的表达式，用于筛选指定标记&#x2F;方法名的用例 -m 根据用例标签来筛选用例，设置标签可以使用 @pytest.mark.&lt;标签名&gt; –markers 打印标签，包括内置的，插件的，还有自定义的 -x 第一个error或failed的test就退出 –fixtures 显示可用的fixture，包括内置和自己写的，如果fixture使用 “_”开头则需要使用-v才能显示此fixture –fixtures-per-test 展示每条用例的fixture –pdb 当用例出现错误或者被键盘中断后，启动pdb调试 –pdbcls&#x3D;modulename:classname 启动自定义pdb debugger，一般用不到这个 –trace 执行测试用例时break，进入debugger –capture&#x3D;method 标准输出&#x2F;标准错误输出&#x2F;标准输入的默认捕获，fd：标准输入，标准错误输出都会捕获；sys：只有向Python的sys.stdout和sys.stderr的写入行为会被捕获，不执行对文件描述符的写入的捕获；no：对print语句内容捕获，等同于 -s -s 显示print语句的内容 –runxfail 强制运行xfail标记的用例 –lf, –last-failed 重新执行上次测试执行失败的用例，如果没有失败的用例，则执行全部用例 –ff, –failed-first 优先跑上次失败的test，tests的顺序会被打乱 –nf, –new-first 优先跑新添加的tests，剩余的按文件mtime顺序 –cache-show&#x3D;[CACHESHOW] 显示缓存，默认 * 显示所有缓存，可以带参数 pytest –cache-show&#x3D;cache&#x2F;nodeids –cache-clear 在执行用例前，清理pytest缓存 –lfnf&#x3D;{all,none}, –last-failed-no-failures&#x3D;{all,none} 没有last-failed缓存数据，或上次没有失败时，执行全部用例 –sw, –stepwise 逐步运行，在失败时退出，下次运行时从失败的用例开始 –stepwise-skip 跳过第一个失败的test，如果再遇到失败就退出 reporting –durations&#x3D;N 显示N个最慢的setup&#x2F;test的耗时，N&#x3D;0时，显示所有耗时 –durations-min&#x3D;N 显示N个最小的setup&#x2F;test的耗时 -v, –verbose 输出详细信息 –no-header 不显示pytest消息头，只展示用例信息 –no-summary 不显示用例执行完的summary info -q, –quiet 静默模式，不输出任何内容 –verbosity&#x3D;VERBOSE 信息显示等级，貌似没啥用 -r chars -r f：显示failed信息；-r E：显示error信息；-r s：显示skipped信息；-r x：显示xfailed信息；-r X：显示xpassed信息；-r p：显示passed信息；-r P：显示 passed with output信息； -r a&#x2F;A：显示 all except passed信息；-r w：显示默认告警信息；-r N：重置list –disable-warnings, –disable-pytest-warnings 禁用pytest告警，如未注册的标记等 -l, –showlocal 用例执行失败时，打印堆栈信息，默认被禁用 –tb&#x3D;style traceback打印模式，一般设置为auto即可 –show-capture&#x3D;{no,stdout,stderr,log,all} 失败的用例如何显示，默认为all –full-trace 不截取traceback，默认会截断 –color&#x3D;color 是否显示彩色，yes：显示颜色；no：不显示颜色；auto：自动 –code-highlight&#x3D;{yes,no} 代码是否高亮显示，一般用不到 –pastebin&#x3D;mode 没什么用的参数，我也不知道干嘛的 –junit-xml&#x3D;path 在给定的path路径下生成junit-xml风格的测试报告 –junit-prefix&#x3D;str 在junit-xml输出中的classnames添加前缀 pytest-warnings -W PYTHONWARNINGS, –pythonwarnings&#x3D;PYTHONWARNINGS 设置报告哪些warnings –maxfail&#x3D;num 出现num个errors或者fails就退出测试 –strict-config 解析配置文件中pytest部分时，遇到warning就抛出error –strict-markers, –strict 发现未知标记时，抛出error， -c file 从指定配置文件加载配置，默认为pytes.ini –continue-on-collection-errors 在收集用例时发生错误，也会继续执行用例 –rootdir&#x3D;ROOTDIR tests根目录，相对路径 collection –collect-only, –co 收集用例，但不执行 –pyargs 把所有参数解释为python包 –ignore&#x3D;path 忽略测试目录，使用英文逗号分割 –ignore-glob&#x3D;path path匹配多个不需要收集的测试目录，使用英文逗号分割 –deselect&#x3D;nodeid_prefix 通过node id prefix反选。可以多个，使用英文逗号分隔 –confcutdir&#x3D;dir 只加载相对于dir目录的conftest.py文件 –noconftest 不加载conftest.py文件 –keep-duplicates 收集重复的test文件，默认只会收集1item，加参数后会收集2items –collect-in-virtualenv 收集本地虚拟环境目录的tests –import-mode&#x3D;{prepend,append,importlib} 包导入模式，一般用不到，参考：https://www.osgeo.cn/pytest/pythonpath.html?highlight=import%20mode –doctest-modules 文档测试，没啥用 –doctest-report&#x3D;{none,cdiff,ndiff,udiff,only_first_failure} 一样，也没啥用 –doctest-glob&#x3D;pat 还是没啥用 –doctest-ignore-import-errors 文档测试时忽略导包错误，继续没什么用 –doctest-continue-on-failure 文档测试时出现失败继续测试，依然没什么用 test session debugging and configuration –basetemp&#x3D;dir test run的base临时目录（如果存在会先删除） -V, –version 输出pytest版本 -h, –help 打印pytest帮助信息 -p name 加载插件，一般不会控制此参数 –trace-config 查看本地安装好的第三方插件 –debug 保存debug信息到’pytestdebug.log’文件 -o OVERRIDE_INI, –override-ini&#x3D;OVERRIDE_INI 覆盖ini文件配置 –assert&#x3D;MODE 断言模式，默认rewrite –setup-only 只加载fixture，不执行测试用例 –setup-show 在执行测试用例时，打印fixture步骤 –setup-plan 展示哪些用例和fixture将要被执行 logging –log-level&#x3D;LEVEL 日志等级，默认 WARNING （具体日志等级参考 logging 模块中的日志等级） –log-format&#x3D;LOG_FORMAT 日志格式（具体日志格式参考 logging 模块中的日志格式） –log-date-format&#x3D;LOG_DATE_FORMA 日志日期格式（具体日志格式参考 logging 模块中的日志格式） –log-cli-level&#x3D;LOG_CLI_LEVEL cli日志等级（具体日志等级参考 logging 模块中的日志等级） –log-cli-format&#x3D;LOG_CLI_FORMAT cli日志格式（具体日志格式参考 logging 模块中的日志格式） –log-cli-date-format&#x3D;LOG_CLI_DATE_FORMAT cli日志日期格式（具体日志格式参考 logging 模块中的日志格式） –log-file&#x3D;LOG_FILE 日志文件路径 –log-file-level&#x3D;LOG_FILE_LEVE 日志文件中的日志等级 –log-file-format&#x3D;LOG_FILE_FORMAT 日志文件中的日志格式 –log-file-date-format&#x3D;LOG_FILE_DATE_FORMAT 日志文件中的日志时间格式 –log-auto-indent&#x3D;LOG_AUTO_INDENT 自动缩进传递给日志模块的多行消息。接受true | on、false | off或整数","categories":[],"tags":[{"name":"Pytest","slug":"Pytest","permalink":"https://linvaux.github.io/tags/Pytest/"}]},{"title":"FileBeat+LogStash实现MySQL慢查询日志解析","slug":"FileBeat-LogStash实现MySQL慢查询日志解析","date":"2020-07-26T13:42:18.000Z","updated":"2024-09-21T00:59:08.922Z","comments":true,"path":"posts/ee883a54/","permalink":"https://linvaux.github.io/posts/ee883a54/","excerpt":"","text":"背景是一个大型营销系统经常出现mysql的慢查询，导致线上服务频繁出现故障，为了查看是哪些sql有问题，并且要支持各种维度的统计查询，所以使用FileBeat+LogStash+ElasticSearch+Kibana实现此需求。本文仅描述如何配置FileBeath和LogStash实现MySQL慢查询日志解析。 FileBeat配置12345678910111213141516171819filebeat.inputs:- type: log enabled: true # 忽略在指定的时间跨度之前被修改的文件 ignore_older: 30000h # mysql慢查询日志目录，支持*通配符匹配多级目录 paths: - /opt/slow-sql/*.log # 文档类型是mysqlslow，这是filebeat内置的一套规则 document_type: mysqlslow multiline: pattern: &quot;^# User@Host: &quot; negate: true match: after tail_files: falseoutput.logstash: # logstash的地址，我是部署在同一台机器上的 hosts: [&quot;127.0.0.1:5044&quot;] LogStash配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556input &#123; # 使用filebeat推送日志 beats &#123; port =&gt; 5044 host =&gt; &quot;0.0.0.0&quot; &#125;&#125;filter &#123; grok &#123; # 有数据库名，有schema match =&gt; &#123;&quot;message&quot; =&gt; &quot;(?m)^# User@Host: %&#123;USER:user&#125;\\[[^\\]]+\\]\\s@\\s*\\[%&#123;IP:clientip&#125;\\]\\s*([\\s\\S]*)#\\s+Schema: (?&lt;schema&gt;\\w+)([\\s\\S]*)\\s+#\\s+Query_time:\\s+%&#123;NUMBER:query_time:float&#125;\\s+Lock_time: %&#123;NUMBER:lock_time:float&#125;\\s+Rows_sent: %&#123;NUMBER:rows_sent:int&#125;\\s+Rows_examined: %&#123;NUMBER:rows_examined:int&#125;\\s*([\\s\\S]*)use\\s(?&lt;dbname&gt;\\w+);([\\s\\S]*)SET timestamp=%&#123;NUMBER:sql_time:int&#125;&quot;&#125; # 无数据库名,有schema match =&gt; &#123;&quot;message&quot; =&gt; &quot;(?m)^# User@Host: %&#123;USER:user&#125;\\[[^\\]]+\\]\\s@\\s*\\[%&#123;IP:clientip&#125;\\]\\s*([\\s\\S]*)#\\s+Schema: (?&lt;schema&gt;\\w+)([\\s\\S]*)\\s+#\\s+Query_time:\\s+%&#123;NUMBER:query_time:float&#125;\\s+Lock_time: %&#123;NUMBER:lock_time:float&#125;\\s+Rows_sent: %&#123;NUMBER:rows_sent:int&#125;\\s+Rows_examined: %&#123;NUMBER:rows_examined:int&#125;\\s*([\\s\\S]*)SET timestamp=%&#123;NUMBER:sql_time:int&#125;&quot;&#125; # 有数据库名，无schema match =&gt; &#123;&quot;message&quot; =&gt; &quot;(?m)^# User@Host: %&#123;USER:user&#125;\\[[^\\]]+\\]\\s@\\s*\\[%&#123;IP:clientip&#125;\\]\\s*([\\s\\S]*)#\\s+Query_time:\\s+%&#123;NUMBER:query_time:float&#125;\\s+Lock_time: %&#123;NUMBER:lock_time:float&#125;\\s+Rows_sent: %&#123;NUMBER:rows_sent:int&#125;\\s+Rows_examined: %&#123;NUMBER:rows_examined:int&#125;\\s*([\\s\\S]*)use\\s(?&lt;dbname&gt;\\w+);([\\s\\S]*)SET timestamp=%&#123;NUMBER:sql_time:int&#125;&quot;&#125; # 无数据库名,无schema match =&gt; &#123;&quot;message&quot; =&gt; &quot;(?m)^# User@Host: %&#123;USER:user&#125;\\[[^\\]]+\\]\\s@\\s*\\[%&#123;IP:clientip&#125;\\]\\s*([\\s\\S]*)#\\s+Query_time:\\s+%&#123;NUMBER:query_time:float&#125;\\s+Lock_time: %&#123;NUMBER:lock_time:float&#125;\\s+Rows_sent: %&#123;NUMBER:rows_sent:int&#125;\\s+Rows_examined: %&#123;NUMBER:rows_examined:int&#125;\\s*([\\s\\S]*)SET timestamp=%&#123;NUMBER:sql_time:int&#125;&quot;&#125; overwrite =&gt; [&quot;message&quot;] &#125; grok&#123; # 匹配 source中的ip match =&gt; &#123;&quot;source&quot; =&gt; &quot;(?m)\\s*%&#123;IP:server_ip&#125;&quot;&#125; &#125; # 时间戳格式化并只保留日期 ruby &#123; code =&gt; &quot; require &#x27;time&#x27; event.set(&#x27;date_tag&#x27;, Time.at(event.get(&#x27;sql_time&#x27;)).to_date.to_s.delete!(&#x27;-&#x27;)) &quot; &#125; # 索引时间戳使用sql生成的时间，不再使用当前时间 date &#123; match =&gt; [&quot;sql_time&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;UNIX&quot;] target =&gt; &quot;@timestamp&quot; locale =&gt; &quot;cn&quot; &#125;&#125;output &#123; # 调试时使用，在控制台打印日志分割结果 stdout &#123; codec =&gt; rubydebug &#123;&#125; &#125; # es配置 elasticsearch &#123; hosts =&gt; &quot;localhost:9200&quot; # 索引名称 index =&gt; &quot;slow-sql-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; 一键安装ELFK123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190#!/bin/bashecho &quot;#-----------------------------------------#@Author: linvaux #@Email: linvaux@outlook.com#@Desc: Auto install ELFK#----------------------------------------&quot;INFO()&#123; echo -e &quot;\\033[0;32m[INFO] $* \\033[0m&quot;&#125;ERROR()&#123; echo -e &quot;\\033[0;31m[ERROR] $* \\033[0m&quot;&#125;WARN()&#123; echo -e &quot;\\033[0;33m[WARN] $* \\033[0m&quot;&#125;# booster the docker-hubbooster()&#123; daemon=&quot;/etc/docker/daemon.json&quot; if [[ -e $&#123;daemon&#125; ]];then INFO Backup $&#123;daemon&#125; success! mv $&#123;daemon&#125; $&#123;daemon&#125;.bak echo &quot;&#123;\\&quot;registry-mirrors\\&quot; : [\\&quot;https://hub-mirror.c.163.com\\&quot;]&#125;&quot; &gt; $&#123;daemon&#125; else echo &quot;&#123;\\&quot;registry-mirrors\\&quot; : [\\&quot;https://hub-mirror.c.163.com\\&quot;]&#125;&quot; &gt; $&#123;daemon&#125; fi INFO Config docker-hub booster success!&#125;check_env()&#123; if [[ -z &quot;$(which docker)&quot; ]] then WARN No docker were found,try to install! INFO Start to install docker source /etc/os-release if [[ &quot;$ID&quot; == &quot;ubuntu&quot; ]] || [[ &quot;$ID&quot; == &quot;debain&quot; ]] then apt update apt install curl wget -y curl -fsSL https://get.docker.com | sh booster systemctl daemon-reload systemctl restart docker if [[ -z &quot;$(which java)&quot; ]];then apt install openjdk-8-jdk -y fi elif [[ &quot;$ID&quot; == &quot;centos&quot; ]] then yum update -y yum install wget curl net-tools -y curl -fsSL https://get.docker.com | sh booster systemctl daemon-reload systemctl restart docker if [[ -z &quot;$(which java)&quot; ]];then yum install java-1.8.0-openjdk -y fi else ERROR Could not support $ID platform! exit 1 fi fi&#125;install_elasticsearch()&#123; INFO Start to install elasticsearch echo &quot;vm.max_map_count=655360&quot; &gt;&gt; /etc/sysctl.conf sysctl -p docker pull docker.elastic.co/elasticsearch/elasticsearch:6.5.4 docker run -d --restart=always -p 9200:9200 -p 9300:9300 --name es -h es -e cluster.name=kiki -e node.name=node1 -e http.cors.enabled=true -e http.cors.allow-origin=&quot;*&quot; -e xpack.security.enabled=false docker.elastic.co/elasticsearch/elasticsearch:6.5.4&#125;install_kibana()&#123; INFO Start to install kibana docker pull kibana:6.5.4; docker run --restart=always -p 5601:5601 --name kibana -e ELASTICSEARCH_URL=http://127.0.0.1:9200 --network=host -d kibana:6.5.4&#125;install_filebeat_and_logstash()&#123; INFO Start to install filebeat and logstash source /etc/os-release if [[ &quot;$ID&quot; == &quot;ubuntu&quot; ]] || [[ &quot;$ID&quot; == &quot;debain&quot; ]] then wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - apt-get install apt-transport-https -y echo &quot;deb https://artifacts.elastic.co/packages/6.x/apt stable main&quot; | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list apt-get update &amp;&amp; apt install filebeat logstash -y if [[ $? -ne 0 ]] then ERROR Install filebeat and logstash failed! exit 1 fi elif [[ &quot;$ID&quot; == &quot;centos&quot; ]] then rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch echo -e &#x27;[elastic-6.x]name=Elastic repository for 6.x packagesbaseurl=https://artifacts.elastic.co/packages/6.x/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md&#x27; &gt; /etc/yum.repos.d/elastic.io.repo yum makecache &amp;&amp; yum install filebeat logstash -y if [[ $? -ne 0 ]] then ERROR Install filebeat and logstash failed! exit 1 fi else ERROR Could not support $ID platform! exit 1 fi&#125;start_filebeat()&#123; INFO Start to call filebeat filebeat_yaml=&quot;/etc/filebeat/filebeat.yml&quot; if [[ -f $&#123;filebeat_yaml&#125; ]];then mv $&#123;filebeat_yaml&#125; $&#123;filebeat_yaml&#125;.bak cp ./filebeat.yml $&#123;filebeat_yaml&#125; systemctl restart filebeat if [[ $? -ne 0 ]] then ERROR Start filebeat failed! exit 1 fi else ERROR $&#123;filebeat_yaml&#125; not found, please check! exit 1 fi&#125;start_logstash()&#123; INFO Start to call logstash logstash_conf_dir=&quot;/etc/logstash/conf.d/&quot; if [[ -e $&#123;logstash_conf_dir&#125; ]];then cp ./slow_sql_by_query.conf $&#123;logstash_conf_dir&#125; systemctl restart logstash if [[ $? -ne 0 ]] then ERROR Start logstash failed! exit 1 fi else ERROR $&#123;logstash_conf_dir&#125; not found, please check! exit 1 fi&#125;run()&#123; if [[ &quot;root&quot; == $(whoami) ]] then INFO Start to run... check_env install_elasticsearch install_kibana install_filebeat_and_logstash # download_log start_logstash start_filebeat # check_index INFO Run success! else ERROR Run as root please! fi&#125;run","categories":[],"tags":[{"name":"LogStash","slug":"LogStash","permalink":"https://linvaux.github.io/tags/LogStash/"}]},{"title":"基于Ubuntu16.04的Python3.7镜像构建","slug":"基于Ubuntu16-04的Python3-7镜像构建","date":"2020-07-25T15:06:21.000Z","updated":"2024-09-21T00:59:08.944Z","comments":true,"path":"posts/cb5702fa/","permalink":"https://linvaux.github.io/posts/cb5702fa/","excerpt":"","text":"Dockerfile12345678910111213141516171819202122232425262728FROM ubuntu:16.04MAINTAINER linvaux &lt;linvaux@outlook.com&gt;WORKDIR /optRUN sed -i &quot;s@http://.*archive.ubuntu.com@http://repo.huaweicloud.com@g&quot; /etc/apt/sources.list &amp;&amp; \\ sed -i &quot;s@http://.*security.ubuntu.com@http://repo.huaweicloud.com@g&quot; /etc/apt/sources.list &amp;&amp; \\ apt-get update &amp;&amp; \\ apt-get upgrade -yRUN apt-get install -y gcc make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-devRUN wget https://mirrors.huaweicloud.com/python/3.7.8/Python-3.7.8.tgz &amp;&amp; \\ tar -vxf Python-3.7.8.tgz &amp;&amp; \\ mv Python-3.7.8 /usr/local/python378 &amp;&amp; \\ cd /usr/local/python378 &amp;&amp; \\ ./configure --prefix=/usr/local/python378 --enable-loadable-sqlite-extensions --with-ssl &amp;&amp;\\ make -j$(nproc) &amp;&amp; \\ make install -j$(nproc) &amp;&amp; \\ ln -s /usr/local/python378/bin/python3.7 /usr/bin/python3 &amp;&amp; \\ ln -s /usr/local/python378/bin/pip3 /usr/bin/pip3 &amp;&amp; \\ mkdir /root/.pip &amp;&amp; \\ echo &quot;[global]&quot; &gt; /root/.pip/pip.conf &amp;&amp; \\ echo &quot;index-url=https://pypi.douban.com/simple/&quot; &gt;&gt; /root/.pip/pip.conf &amp;&amp; \\ echo &quot;[install]&quot; &gt;&gt; /root/.pip/pip.conf &amp;&amp; \\ echo &quot;trusted-host=pypi.douban.com&quot; &gt;&gt; /root/.pip/pip.confRUN rm -rf Python-3.7.8.tgz 构建命令1docker build -t ubuntu-python378 .","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://linvaux.github.io/tags/Docker/"}]},{"title":"基于Centos7的UI自动化环境Dockerfile","slug":"基于Centos7的UI自动化环境Dockerfile","date":"2020-05-25T15:08:06.000Z","updated":"2024-09-21T00:59:08.942Z","comments":true,"path":"posts/cba30645/","permalink":"https://linvaux.github.io/posts/cba30645/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657FROM centos:7MAINTAINER linvaux &lt;linvaux@outlook.com&gt;WORKDIR /opt# 修改源，安装依赖RUN sed -i &quot;s/#baseurl/baseurl/g&quot; /etc/yum.repos.d/CentOS-Base.repo &amp;&amp; \\ sed -i &quot;s/mirrorlist=http/#mirrorlist=http/g&quot; /etc/yum.repos.d/CentOS-Base.repo &amp;&amp; \\ sed -i &quot;s@http://mirror.centos.org@https://repo.huaweicloud.com@g&quot; /etc/yum.repos.d/CentOS-Base.repo &amp;&amp; \\ yum clean all &amp;&amp; \\ yum makecache &amp;&amp; \\ yum update -y &amp;&amp; \\ yum install -y wget git zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel libffi-devel gcc make# 安装JDK1.8RUN wget http://10.177.248.111:8089/ftp/dev_tools/jdk-8u271-linux-x64.tar.gz &amp;&amp; \\ tar -vxf jdk-8u271-linux-x64.tar.gz &amp;&amp; \\ mv jdk1.8.0_271/ /usr/local/ &amp;&amp; \\ echo &#x27;export JAVA_HOME=/usr/local/jdk1.8.0_271&#x27; &gt;&gt; /etc/profile &amp;&amp; \\ echo &#x27;export JRE_HOME=$&#123;JAVA_HOME&#125;/jre&#x27; &gt;&gt; /etc/profile &amp;&amp; \\ echo &#x27;export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib&#x27; &gt;&gt; /etc/profile &amp;&amp; \\ echo &#x27;export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH&#x27; &gt;&gt; /etc/profile echo `java -version`# 安装python3.7RUN wget https://mirrors.huaweicloud.com/python/3.7.8/Python-3.7.8.tgz &amp;&amp; \\ tar -vxf Python-3.7.8.tgz &amp;&amp; \\ mv Python-3.7.8 /usr/local/python378 &amp;&amp; \\ cd /usr/local/python378 &amp;&amp; \\ ./configure --prefix=/usr/local/python378 --enable-loadable-sqlite-extensions --with-ssl &amp;&amp;\\ make -j$(nproc) &amp;&amp; \\ make install -j$(nproc) &amp;&amp; \\ ln -s /usr/local/python378/bin/python3.7 /usr/bin/python3 &amp;&amp; \\ ln -s /usr/local/python378/bin/pip3 /usr/bin/pip3 &amp;&amp; \\ mkdir /root/.pip &amp;&amp; \\ echo &quot;[global]&quot; &gt; /root/.pip/pip.conf &amp;&amp; \\ echo &quot;index-url=https://pypi.douban.com/simple/&quot; &gt;&gt; /root/.pip/pip.conf &amp;&amp; \\ echo &quot;[install]&quot; &gt;&gt; /root/.pip/pip.conf &amp;&amp; \\ echo &quot;trusted-host=pypi.douban.com&quot; &gt;&gt; /root/.pip/pip.conf echo `python3 -V`# 安装chromeRUN echo &#x27;[google-chrome]&#x27; &gt; /etc/yum.repos.d/google-chrome.repo &amp;&amp; \\ echo &#x27;name=google-chrome&#x27; &gt;&gt; /etc/yum.repos.d/google-chrome.repo &amp;&amp; \\ echo &#x27;baseurl=http://dl.google.com/linux/chrome/rpm/stable/$basearch&#x27; &gt;&gt; /etc/yum.repos.d/google-chrome.repo &amp;&amp; \\ echo &#x27;enabled=1&#x27; &gt;&gt; /etc/yum.repos.d/google-chrome.repo &amp;&amp; \\ echo &#x27;gpgcheck=1&#x27; &gt;&gt; /etc/yum.repos.d/google-chrome.repo &amp;&amp; \\ echo &#x27;gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub&#x27; &gt;&gt; /etc/yum.repos.d/google-chrome.repo &amp;&amp; \\ yum -y install google-chrome-stable --nogpgcheck &amp;&amp; \\ echo `google-chrome --version`# 安装chromedriver驱动# 安装allureRUN rm -rf jdk-8u271-linux-x64.tar.gz &amp;&amp; \\ rm -rf Python-3.7.8.tgz &amp;&amp; \\ yum clean all","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://linvaux.github.io/tags/Docker/"}]},{"title":"基于Centos7的Python3.7镜像构建","slug":"基于Centos7的Python3-7镜像构建","date":"2019-11-25T15:07:16.000Z","updated":"2024-09-21T00:59:08.942Z","comments":true,"path":"posts/699082e4/","permalink":"https://linvaux.github.io/posts/699082e4/","excerpt":"","text":"Dockerfile123456789101112131415161718192021222324252627282930FROM centos:7MAINTAINER linvaux &lt;linvaux@outlook.com&gt;WORKDIR /optRUN sed -i &quot;s/#baseurl/baseurl/g&quot; /etc/yum.repos.d/CentOS-Base.repo &amp;&amp; \\ sed -i &quot;s/mirrorlist=http/#mirrorlist=http/g&quot; /etc/yum.repos.d/CentOS-Base.repo &amp;&amp; \\ sed -i &quot;s@http://mirror.centos.org@https://repo.huaweicloud.com@g&quot; /etc/yum.repos.d/CentOS-Base.repo &amp;&amp; \\ yum clean all &amp;&amp; \\ yum makecache &amp;&amp; \\ yum update -yRUN yum install -y wget zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel libffi-devel gcc makeRUN wget https://mirrors.huaweicloud.com/python/3.7.8/Python-3.7.8.tgz &amp;&amp; \\ tar -vxf Python-3.7.8.tgz &amp;&amp; \\ mv Python-3.7.8 /usr/local/python378 &amp;&amp; \\ cd /usr/local/python378 &amp;&amp; \\ ./configure --prefix=/usr/local/python378 --enable-loadable-sqlite-extensions --with-ssl &amp;&amp;\\ make -j$(nproc) &amp;&amp; \\ make install -j$(nproc) &amp;&amp; \\ ln -s /usr/local/python378/bin/python3.7 /usr/bin/python3 &amp;&amp; \\ ln -s /usr/local/python378/bin/pip3 /usr/bin/pip3 &amp;&amp; \\ mkdir /root/.pip &amp;&amp; \\ echo &quot;[global]&quot; &gt; /root/.pip/pip.conf &amp;&amp; \\ echo &quot;index-url=https://pypi.douban.com/simple/&quot; &gt;&gt; /root/.pip/pip.conf &amp;&amp; \\ echo &quot;[install]&quot; &gt;&gt; /root/.pip/pip.conf &amp;&amp; \\ echo &quot;trusted-host=pypi.douban.com&quot; &gt;&gt; /root/.pip/pip.confRUN rm -rf Python-3.7.8.tgz 构建命令1docker build -t centos-python378 .","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://linvaux.github.io/tags/Docker/"}]},{"title":"Centos使用Tomcat安装Jenkins","slug":"Centos使用Tomcat安装Jenkins","date":"2019-07-26T13:47:23.000Z","updated":"2024-09-21T00:59:08.918Z","comments":true,"path":"posts/ab1b5116/","permalink":"https://linvaux.github.io/posts/ab1b5116/","excerpt":"","text":"安装步骤安装JDK1.812yum makecacheyum install -y java-1.8.0-openjdk.x86_64 安装tomcat1234567# 下载tomcat9.0wget https://mirrors.bfsu.edu.cn/apache/tomcat/tomcat-9/v9.0.36/bin/apache-tomcat-9.0.36.tar.gz &amp;&amp; tar -xvf apache-tomcat-9.0.36.tar.gz# 删除webapps下面的项目cd apache-tomcat-9.0.36/webapps/ &amp;&amp; rm -rf *# 下载jenkins.war并重命名为ROOT.warwget https://mirrors.huaweicloud.com/jenkins/war/2.240/jenkins.war -O ROOT.war 修改Tomcat启动脚本，支持Jenkins跨域12345# 修改bin/catalina.sh,在首行添加如下参数export CATALINA_OPTS=&quot;-Djava.awt.headless=true&quot;export JAVA_OPTS=&quot;-Dhudson.model.DirectoryBrowserSupport.CSP= &quot;# 启动tomcat./startup.sh 关闭防火墙12systemctl stop firewalldsystemctl disable firewalld 访问jenkins tomcat默认监听端口是8080，访问 192.168.1.2:8080 如果jenkins启动页面可以正常打开，此时，停止tomcat，并修改jenkins配置。 12bash &lt;tomcat安装目录&gt;/bin/shutdown.shcd ~/.jenkins/ 找到hudson.model.UpdateCenter.xml文件，修改为如下内容 1234567&lt;?xml version=&#x27;1.1&#x27; encoding=&#x27;UTF-8&#x27;?&gt;&lt;sites&gt; &lt;site&gt; &lt;id&gt;default&lt;/id&gt; &lt;url&gt;https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json&lt;/url&gt; &lt;/site&gt;&lt;/sites&gt; 启动tomcat jenkins启动后，需要输入初始化密码，根据页面提示填写密码后，进入插件安装页面，此时，需要再次停止tomcat，然后执行以下命令，更换jenkins更新源之后，再次启动tomcat。 123cd ~/.jenkins/updates;sed -i &#x27;s/http:\\/\\/updates.jenkins-ci.org\\/download/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g&#x27; default.json &amp;&amp; sed -i &#x27;s/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g&#x27; default.json;bash &lt;tomcat安装目录&gt;/bin/startup.sh 此时，jenkins会要求重新输入初始化密码，然后选择安装建议的插件，等待安装完成。 插件安装完成后，需要设置管理员信息，之后进入jenkins工作页面。 jenkins常用插件 chinese （汉化） locale（汉化） blue ocean（流水线工具） Allure Jenkins Plugin (allure报告) Extended Choice Parameter Plug-In (参数化构建扩展) AnsiColor （日志彩色输出） Git Parameter Plug-In（代码分支选择） build failure analyzer (构建失败分析) multijob（组织多job构建） multiple SCMs （设置多个git） simple theme（jenkins主题 http://afonsof.com/jenkins-material-theme/） merge request event (gitlab 代码门禁) SLOCCount Plug-in（clco代码量统计结果展示） Warnings Next Generation Plugin（代码静态扫描结果展示 https://github.com/jenkinsci/warnings-ng-plugin/blob/master/SUPPORTED-FORMATS.md） Jacoco（java代码覆盖率报告） Html publisher（生成html报告） backup（备份&#x2F;恢复jenkins） Gitlab（gitlab支持插件） Gitee（gitee支持插件） Role-based Authorization Strategy (角色权限控制) Active Choices (根据所选参数，自动调出对应参数所依赖的后续参数) Job Configuration History (配置记录管理，支持配置回滚)","categories":[],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://linvaux.github.io/tags/Jenkins/"}]},{"title":"CentOS安装Google-Chrome浏览器","slug":"CentOS安装Google-Chrome浏览器","date":"2019-07-25T15:05:23.000Z","updated":"2024-09-21T00:59:08.917Z","comments":true,"path":"posts/6b30fe48/","permalink":"https://linvaux.github.io/posts/6b30fe48/","excerpt":"","text":"配置yum源 在目录 &#x2F;etc&#x2F;yum.repos.d&#x2F; 下新建文件 google-chrome.repo 1vim /etc/yum.repos.d/google-chrome.repo 添加如下内容 123456[google-chrome]name=google-chromebaseurl=http://dl.google.com/linux/chrome/rpm/stable/$basearchenabled=1gpgcheck=1gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub 安装google chrome浏览器及chromedriver Google官方源安装： 12yum makecacheyum -y install google-chrome-stable Google官方源可能在中国无法使用，导致安装失败或者在国内无法更新，可以添加以下参数来安装： 1yum -y install google-chrome-stable --nogpgcheck 检查chrome版本 1google-chrome --version 下载对应版本的的chromedriver 检查chromedriver版本 1chromedriver --version","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://linvaux.github.io/tags/Docker/"}]}],"categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://linvaux.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"Jmeter源码系列","slug":"Jmeter源码系列","permalink":"https://linvaux.github.io/tags/Jmeter%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/"},{"name":"Jmeter扩展开发","slug":"Jmeter扩展开发","permalink":"https://linvaux.github.io/tags/Jmeter%E6%89%A9%E5%B1%95%E5%BC%80%E5%8F%91/"},{"name":"IDEA","slug":"IDEA","permalink":"https://linvaux.github.io/tags/IDEA/"},{"name":"Java","slug":"Java","permalink":"https://linvaux.github.io/tags/Java/"},{"name":"代码覆盖率","slug":"代码覆盖率","permalink":"https://linvaux.github.io/tags/%E4%BB%A3%E7%A0%81%E8%A6%86%E7%9B%96%E7%8E%87/"},{"name":"自动化测试","slug":"自动化测试","permalink":"https://linvaux.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"},{"name":"Mac","slug":"Mac","permalink":"https://linvaux.github.io/tags/Mac/"},{"name":"EasyExcel","slug":"EasyExcel","permalink":"https://linvaux.github.io/tags/EasyExcel/"},{"name":"Pytest","slug":"Pytest","permalink":"https://linvaux.github.io/tags/Pytest/"},{"name":"LogStash","slug":"LogStash","permalink":"https://linvaux.github.io/tags/LogStash/"},{"name":"Docker","slug":"Docker","permalink":"https://linvaux.github.io/tags/Docker/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://linvaux.github.io/tags/Jenkins/"}]}